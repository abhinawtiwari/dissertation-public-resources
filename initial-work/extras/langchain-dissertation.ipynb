{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "299be956",
   "metadata": {},
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a3be631",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: openai in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (0.27.6)\n",
      "Requirement already satisfied: google-search-results in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (2.4.2)\n",
      "Requirement already satisfied: pypdf in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (3.8.1)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.3.22-py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from wikipedia) (4.11.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from wikipedia) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from pypdf) (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from chromadb) (1.23.2)\n",
      "Collecting hnswlib>=0.7\n",
      "  Using cached hnswlib-0.7.0.tar.gz (33 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.3 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from chromadb) (1.5.0)\n",
      "Collecting fastapi>=0.85.1\n",
      "  Using cached fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
      "Collecting posthog>=2.4.0\n",
      "  Using cached posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
      "Collecting clickhouse-connect>=0.5.7\n",
      "  Downloading clickhouse_connect-0.5.24-cp39-cp39-macosx_11_0_arm64.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.2/229.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic>=1.9 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from chromadb) (1.10.7)\n",
      "Collecting sentence-transformers>=2.2.2\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting uvicorn[standard]>=0.18.3\n",
      "  Using cached uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
      "Collecting typing_extensions>=3.10.0.0\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting duckdb>=0.7.1\n",
      "  Downloading duckdb-0.7.1-cp39-cp39-macosx_11_0_arm64.whl (12.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3>=1.26 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.11)\n",
      "Collecting zstandard\n",
      "  Downloading zstandard-0.21.0-cp39-cp39-macosx_11_0_arm64.whl (364 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.7/364.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.2.1)\n",
      "Requirement already satisfied: certifi in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.9.24)\n",
      "Collecting lz4\n",
      "  Downloading lz4-4.3.2-cp39-cp39-macosx_11_0_arm64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting starlette<0.27.0,>=0.26.1\n",
      "  Using cached starlette-0.26.1-py3-none-any.whl (66 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Collecting monotonic>=1.5\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting torch>=1.6.0\n",
      "  Downloading torch-2.0.1-cp39-none-macosx_11_0_arm64.whl (55.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp39-cp39-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.1.2)\n",
      "Requirement already satisfied: scipy in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.9.1)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.14.1)\n",
      "Requirement already satisfied: click>=7.0 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
      "Collecting h11>=0.8\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Downloading uvloop-0.17.0-cp39-cp39-macosx_10_9_universal2.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting websockets>=10.4\n",
      "  Downloading websockets-11.0.3-cp39-cp39-macosx_11_0_arm64.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13\n",
      "  Using cached watchfiles-0.19.0-cp37-abi3-macosx_11_0_arm64.whl (388 kB)\n",
      "Collecting python-dotenv>=0.13\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting httptools>=0.5.0\n",
      "  Downloading httptools-0.5.0-cp39-cp39-macosx_10_9_universal2.whl (231 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.5/231.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from beautifulsoup4->wikipedia) (2.3.2.post1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (2023.5.0)\n",
      "Requirement already satisfied: filelock in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (21.3)\n",
      "Collecting anyio<5,>=3.4.0\n",
      "  Using cached anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.1.2)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-macosx_12_0_arm64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2023.5.5-cp39-cp39-macosx_11_0_arm64.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.9/288.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from nltk->sentence-transformers>=2.2.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from torchvision->sentence-transformers>=2.2.2->chromadb) (9.2.0)\n",
      "Collecting sniffio>=1.1\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/abhinawtiwari/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (2.1.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: hnswlib, sentence-transformers\n",
      "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp39-cp39-macosx_11_0_arm64.whl size=159958 sha256=e6c1808e87e8601a6af8c8e71f81c205ed4a096368246bc6b805e08eaff1c080\n",
      "  Stored in directory: /Users/abhinawtiwari/Library/Caches/pip/wheels/ba/26/61/fface6c407f56418b3140cd7645917f20ba6b27d4e32b2bd20\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=38e494bb271fb2341220b24a32d91be42fb9d2c8baf92f14d7ac0008bb236fbc\n",
      "  Stored in directory: /Users/abhinawtiwari/Library/Caches/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built hnswlib sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, mpmath, monotonic, duckdb, zstandard, websockets, uvloop, typing_extensions, sympy, sniffio, regex, python-dotenv, networkx, lz4, httptools, hnswlib, h11, backoff, uvicorn, torch, posthog, nltk, clickhouse-connect, anyio, watchfiles, transformers, torchvision, starlette, sentence-transformers, fastapi, chromadb\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "Successfully installed anyio-3.6.2 backoff-2.2.1 chromadb-0.3.22 clickhouse-connect-0.5.24 duckdb-0.7.1 fastapi-0.95.1 h11-0.14.0 hnswlib-0.7.0 httptools-0.5.0 lz4-4.3.2 monotonic-1.6 mpmath-1.3.0 networkx-3.1 nltk-3.8.1 posthog-3.0.1 python-dotenv-1.0.0 regex-2023.5.5 sentence-transformers-2.2.2 sentencepiece-0.1.99 sniffio-1.3.0 starlette-0.26.1 sympy-1.12 tokenizers-0.13.3 torch-2.0.1 torchvision-0.15.2 transformers-4.29.1 typing_extensions-4.5.0 uvicorn-0.22.0 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3 zstandard-0.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wikipedia openai google-search-results pypdf chromadb tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d9d64",
   "metadata": {},
   "source": [
    "# API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797fdd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"525da99597de091fdf975a60468ccbf6d24a6252ecc2ed8dfcab4567099dcd24\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c623f7aa",
   "metadata": {},
   "source": [
    "# Using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "614ee3e2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data Analysis: \n",
      "- SQL \n",
      "- Excel \n",
      "- Tableau \n",
      "- Data Visualization \n",
      "- Data Mining \n",
      "- Statistical Analysis \n",
      "- Predictive Modeling \n",
      "- Machine Learning \n",
      "- Natural Language Processing \n",
      "- Data Wrangling \n",
      "\n",
      "Business and Communication Skills: \n",
      "- Project Management \n",
      "- Business Intelligence \n",
      "- Communication \n",
      "- Analytical Thinking \n",
      "- Problem Solving \n",
      "- Presentation Skills \n",
      "- Interpreting Data \n",
      "- Report Writing\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "text = \"What should I learn for a Data Analyst interview?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e70959a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nतुम कितने वयस्क हो?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"translate English to Hindi: How old are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08de9e75",
   "metadata": {},
   "source": [
    "# Wikipedia search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "317e299a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: Varanasi\\nSummary: Varanasi (Vārāṇasī; [ʋaːˈraːɳəsi]; also Banaras or Benares (Banāras; [bəˈnaːrəs] (listen)),  and Kashi) is a city on the Ganges river in northern India that has a central place in the traditions of pilgrimage, death, and mourning in the Hindu world.  The city has a syncretic tradition of Muslim artisanship that underpins its religious tourism. Located in the middle-Ganges valley in the southeastern part of the state of Uttar Pradesh, Varanasi lies on the left bank of the river.  It is 692 kilometres (430 mi) to the southeast of India's capital New Delhi and 320 kilometres (200 mi) to the east of the state capital, Lucknow. It lies 121 kilometres (75 mi) downstream of Prayagraj, where the confluence with the Yamuna river and mythical Saraswati river is another major Hindu pilgrimage site. \\nVaranasi is one of the world's oldest continually inhabited cities.  Kashi, its ancient name, was associated with a kingdom of the same name of 2,500 years ago. The Lion capital of Ashoka at nearby Sarnath has been interpreted to be a commemoration of the Buddha's first sermon there in the fifth century BCE. In the 8th century, Adi Shankara established the worship of Shiva as an official sect of Varanasi. Since ancient times, the city has been an important centre of Hindu devotion, pilgrimage, mysticism and poetry contributing to its cultural importance. Tulsidas wrote his Awadhi language epic, the Ramcharitmanas, a Bhakti movement reworking of the Sanskrit Ramayana, in Varanasi. Several other major figures of the Bhakti movement were born in Varanasi, including Kabir and Ravidas. \\nIn the 16th century, Rajput nobles in the service of the courts and armies of the Mughal emperor Akbar, sponsored the building or further enhancement of the major Shiva temple in the city; they also built other temples, all displaying an empire-wide architectural style. Under the Treaty of Faizabad, the East India Company acquired Benares in 1775, the city later successively becoming a part of the Benares Division in the Ceded and Conquered Provinces, the North-Western Provinces, and the United Provinces, and after India's independence of Uttar Pradesh.Silk weaving, carpets and crafts and tourism employ a significant number of the local population, as do the Banaras Locomotive Works and Bharat Heavy Electricals. The city is known worldwide for its many ghats, steps leading down the steep river bank to the water, where pilgrims perform rituals. Of particular note are the Dashashwamedh Ghat, the Panchganga Ghat, the Manikarnika Ghat, and the Harishchandra Ghat, the last two being where Hindus cremate their dead. The Hindu genealogy registers at Varanasi are kept here. Among the notable temples in Varanasi are Kashi Vishwanath Temple of Shiva, the Sankat Mochan Hanuman Temple, and the Durga Temple.\\nThe city has long been an educational and musical centre: many prominent Indian philosophers, poets, writers, and musicians live or have lived in the city, and it was the place where the Benares gharana form of Hindustani classical music was developed. In the 20th-century the Hindi-Urdu writer Premchand and the shehnai player Bismillah Khan were associated with the city.  India's oldest Sanskrit college, the Benares Sanskrit College, was founded during East India Company rule in 1791. Later education in Benares was greatly influenced by the rise of Indian nationalism in the late 19th-century.  Annie Besant founded the Central Hindu College in 1898. In 1916, she and Madan Mohan Malviya founded the Banaras Hindu University, India's first modern residential university. Kashi Vidyapith was established in 1921, a response to Mahatma Gandhi's Non-cooperation movement.\\n\\n\\n\\nPage: Varanasi Junction railway station\\nSummary: Varanasi Junction railway station (station code: BSB), also known as Varanasi Cantt railway station, is the main railway station serving the city of Varanasi. The other key railway stations in Varanasi Metro area are Banaras, Varanasi City, Kashi and Pandit Deen Dayal Upadhyaya Junction. The junction station is sandwiched between the cantonment region and Chetganj region of the city. The station is partially controlled by the Lucknow Division of the Northern Railway Zone and the Varanasi Division of the North Eastern Railway Zone of the Indian Railways. Varanasi Junction railway station nearly reaches the frequency of 300 trains daily. Almost, 45 trains originate and terminate at the station. Premium trains of Indian Railways also originate from Varanasi Junction, such as Vande Bharat Express and Mahamana Express\\n\\nPage: Varanasi Lok Sabha constituency\\nSummary: Varanasi Lok Sabha constituency (Hindi: वाराणसी लोकसभा निर्वाचन क्षेत्र) is one of the 80 Lok Sabha (parliamentary) constituencies in Uttar Pradesh, a state in northern India. Narendra Modi has been twice elected from this constituency to become the prime minister of India.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.utilities import WikipediaAPIWrapper \n",
    "wiki = WikipediaAPIWrapper()\n",
    "prompt = \"varanasi\"\n",
    "wiki_research = wiki.run(prompt) \n",
    "wiki_research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897e06d3",
   "metadata": {},
   "source": [
    "# Indexes on Common-Impact-Data-Standard-V1.1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8b0d5d8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='1 \\n© 2020 Fox et al.                        Common Impact Data Standard \\n \\nThe Common Impact Data Standard : \\nAn Ontology for Representing Impact \\n \\nMark Fox1, Kate Ruff2, Anshula Chowdhury3, Bart Gajderowicz1, Tawfiq Abdulai3,  \\nJane Zhang4 \\n \\n \\n \\n1Centre for Social Services Engineering \\nUniversity of Toronto \\ncsse.utoronto.ca \\n2Carleton Centre for Community Innovation \\nCarleton University \\n3Sametrica \\nsametrica.com \\n4Centre for Social Innovation \\nsocialinnovation.org \\n \\n \\nVersion 1.1, released: November 30, 2020 \\n \\nTechnical Report \\nCentre for Social Services Engineering \\nUniversity of Toronto \\ncsse.utoronto.ca \\n \\nThis document can be found at:  \\nhttps://commonapproach.o rg/common-impact-data- standard/documentation \\nand  \\nhttps://zenodo.org/record/4295989  \\n \\nOntology URL: http://ontology.eil.utoron to.ca/cids/cids.owl  \\nNamespace: http://ontology.eil.utoronto.ca/cids/cids#  \\nSuggested Prefix: cids \\nFor further information contact: Mark S. Fox, msf@eil.utoronto.ca \\n \\n \\n Recommended Attribution:  \\nFox et al. (2020) The Common Impact Data Standard V1.1 The Common Approach to Impact Measurement. \\nDOI: 10.5281/zenodo.4295989', metadata={'source': 'Common-Impact-Data-Standard-V1.1.pdf', 'page': 0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader('Common-Impact-Data-Standard-V1.1.pdf')\n",
    "pages = loader.load_and_split()\n",
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4275c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "710abf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' An organization is a subclass of owl:Thing that has properties including name, legal name, and address. It is also defined by the properties in the property column of the cids:Organization class.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'What is an organization?'\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb44eb",
   "metadata": {},
   "source": [
    "# Indexes on CIDS-OntoBeSS-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14070de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' An organization is a group of people working together to achieve a common goal or purpose.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader2 = PyPDFLoader('CIDS-OntoBeSS-v1.pdf')\n",
    "pages = loader2.load_and_split()\n",
    "index2 = VectorstoreIndexCreator().from_loaders([loader2])\n",
    "query = 'What is an organization?'\n",
    "index2.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce60a8b",
   "metadata": {},
   "source": [
    "# Using Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b2dd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m AIAAIC's story about Facebook's Ville de Bitche includes a lot of information.\n",
      "Action: Search\n",
      "Action Input: AIAAIC \"Facebook's Ville de Bitche\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mVille de Bitche is a fortress town of 5,000+ people in the Moselle department of north-eastern France, close to the border with Germany. In March 2021, the ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the title of the story, source URL, and general context.\n",
      "Action: Search\n",
      "Action Input: \"Common Impact Data Standard ontology\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe Common Impact Data Standard is a standardized way to represent a social purpose organization's (SPO) impact model (i.e. their theory of change, logic model, ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know what the Common Impact Data Standard is.\n",
      "Action: Search\n",
      "Action Input: \"AIAAIC Facebook's Ville de Bitche Common Impact Data Standard ontology\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m... urcuit masulipatam rauna polygala rudzenskaite fuera thrace stohr targu grojeckie snuggles achaemenian borgward watkinsville clavicular consenting stohl ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The search query is too broad and not yielding the desired result.\n",
      "Action: Search\n",
      "Action Input: \"AIAAIC Facebook's Ville de Bitche Common Impact Data Standard ontology summary\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mWe use impact models as a general term to describe a family of similar relational maps such as Logic model, Logical Framework Analysis, Theory of. Change, ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the components of the Common Impact Data Standard.\n",
      "Final Answer: The components of the Common Impact Data Standard ontology present in the AIAAIC story about Facebook's Ville de Bitche are: Title of the story, Organization, Impact Model, Program, Service, Activity, Input, Output, Outcome, Stakeholder, Stakeholder Outcome, Impact Report, Impact Risk, Indicator, Indicator Report, Impact Scale, Impact Depth, Impact Duration, and Source URL.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The components of the Common Impact Data Standard ontology present in the AIAAIC story about Facebook's Ville de Bitche are: Title of the story, Organization, Impact Model, Program, Service, Activity, Input, Output, Outcome, Stakeholder, Stakeholder Outcome, Impact Report, Impact Risk, Indicator, Indicator Report, Impact Scale, Impact Depth, Impact Duration, and Source URL.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI, Cohere, HuggingFaceHub\n",
    "\n",
    "gpt3 = OpenAI(model_name='text-davinci-003')\n",
    "\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "tools = load_tools([\"serpapi\"], llm=gpt3)\n",
    "agent = initialize_agent(tools, llm=gpt3, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "# agent.run(\"As per Common Impact Data Standard ontology, find the following: Title of the story, Organization, Impact Model, Program, Service, Activity, Input, Output, Outcome, Stakeholder, Stakeholder Outcome, Impact Report, Impact Risk, Indicator, Indicator Report, Impact Scale, Impact Depth, Impact Duration, Source URL, from this link and news links in the content at that link https://www.aiaaic.org//aiaaic-repository/ai-and-algorithmic-incidents-and-controversies/facebook-ville-de-bitche\")\n",
    "agent.run(\"read the story at https://www.aiaaic.org//aiaaic-repository/ai-and-algorithmic-incidents-and-controversies/facebook-ville-de-bitche, then as per Common Impact Data Standard ontology find the following from the story: Title of the story, Organization, Impact Model, Program, Service, Activity, Input, Output, Outcome, Stakeholder, Stakeholder Outcome, Impact Report, Impact Risk, Indicator, Indicator Report, Impact Scale, Impact Depth, Impact Duration, Source URL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b8161f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m What qualities are important for success?\n",
      "Action: Search\n",
      "Action Input: Qualities of a successful person\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mQualities of Successful People · Passion · Optimism · Persistence · Creativity · Self-Discipline · A Desire to Improve · A Commitment to Learning.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know that success comes from having these qualities.\n",
      "Final Answer: Success comes from having passion, optimism, persistence, creativity, self-discipline, a desire to improve, and a commitment to learning.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success comes from having passion, optimism, persistence, creativity, self-discipline, a desire to improve, and a commitment to learning.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How to succeed in life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b30af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
