{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b4f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import click\n",
    "from typing import List\n",
    "\n",
    "from langchain.document_loaders import TextLoader, PDFMinerLoader, CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "from constants import CHROMA_SETTINGS, SOURCE_DIRECTORY, PERSIST_DIRECTORY\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "\n",
    "def load_single_document(file_path: str) -> Document:\n",
    "    # Loads a single document from a file path\n",
    "    if file_path.endswith(\".txt\"):\n",
    "        loader = TextLoader(file_path, encoding=\"utf8\")\n",
    "    elif file_path.endswith(\".pdf\"):\n",
    "        loader = PDFMinerLoader(file_path)\n",
    "    elif file_path.endswith(\".csv\"):\n",
    "        loader = CSVLoader(file_path)\n",
    "    return loader.load()[0]\n",
    "\n",
    "\n",
    "def load_documents(source_dir: str) -> List[Document]:\n",
    "    # Loads all documents from source documents directory\n",
    "    all_files = os.listdir(source_dir)\n",
    "    return [load_single_document(f\"{source_dir}/{file_path}\") for file_path in all_files if file_path[-4:] in ['.txt', '.pdf', '.csv'] ]\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option('--device_type', default='gpu', help='device to run on, select gpu or cpu')\n",
    "def main(device_type, ):\n",
    "    # load the instructorEmbeddings\n",
    "    if device_type in ['cpu', 'CPU']:\n",
    "        device='cpu'\n",
    "    else:\n",
    "        device='cuda'\n",
    "\n",
    "    #Â Load documents and split in chunks\n",
    "    print(f\"Loading documents from {SOURCE_DIRECTORY}\")\n",
    "    documents = load_documents(SOURCE_DIRECTORY)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    print(f\"Loaded {len(documents)} documents from {SOURCE_DIRECTORY}\")\n",
    "    print(f\"Split into {len(texts)} chunks of text\")\n",
    "\n",
    "    # Create embeddings\n",
    "    embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",\n",
    "                                                model_kwargs={\"device\": device})\n",
    "    \n",
    "    db = Chroma.from_documents(texts, embeddings, persist_directory=PERSIST_DIRECTORY, client_settings=CHROMA_SETTINGS)\n",
    "    db.persist()\n",
    "    db = None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea3d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_documents(SOURCE_DIRECTORY)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",\n",
    "                                                model_kwargs={\"device\": 'cpu'})\n",
    "db = Chroma.from_documents(texts, embeddings, persist_directory=PERSIST_DIRECTORY, client_settings=CHROMA_SETTINGS)\n",
    "db.persist()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
