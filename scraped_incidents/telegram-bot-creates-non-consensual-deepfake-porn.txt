- Telegram bot creates non-consensual deepfake porn
- Occurred: October 2020
- Can you improve this page?Share your insights with us
- Security company Sensity has discovered that an AI bot on encrypted messaging app Telegram is being used to create photo-realistic nude and sexually explicit images of hundreds of thousands of women without their consent.
- The bot, which appears to be popular in Russia and eastern Europe, only requires one photograph to create the images, leading to over 680,000 ordinary women and girls being demeaned and degraded. Some of these appear to be underage girls.
- The images are used and manipulated harassment without the knowledge or consent of the women being targeted, risk being used in all manner of ways, and may lead to harassment, abuse, violence, and loss of jobs.
- The photographs clearly violate Telegram's terms of service, but the messaging app has refused to close the account.
- Operator: Unclear/unknown; Telegram Developer: Anonymous/pseudonymous
- Country: Russia; Global
- Sector: Media/entertainment/sports/arts
- Purpose: Simulate nude images
- Technology: Deepfake - image; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning Issue: Privacy; Impersonation; Copyright; Safety
- Transparency: Governance; Complaints/appeals; Privacy; Marketing
- Telegram website
- Telegram terms of service
- Sensity (2020). The State of Deepfakes
URL: https://www.bbc.co.uk/news/technology-54584127
- Faked nude images of more than 100,000 women have been created from social media pictures and shared online, according to a new report.
- Clothes are digitally removed from pictures of women by Artificial Intelligence (AI), and spread on the messaging app Telegram.
- Some of those targeted "appeared to be underage", the report by intelligence company Sensity said.
- But those running the service said it was simply "entertainment".
- The BBC has tested the software and received poor results.
- Sensity claim the technology used is a "deepfake bot".
- Deepfakes are computer-generated, often realistic images and video, based on a real template. One of its uses has been to create faked pornographic video clips of celebrities.
- But Sensity's chief executive Giorgio Patrini said the shift to using photos of private individuals is relatively new.
- "Having a social media account with public photos is enough for anyone to become a target," he warned.
- The artificial intelligence-powered bot lives inside a Telegram private messaging channel. Users can send the bot a photo of a woman, and it will digitally remove her clothes in minutes, at no cost.
- The BBC tested multiple images, all with the subjects' consent, and none were completely realistic - our results included a photo of a woman with a belly button on her diaphragm.
- A similar app was shut down last year, but it is believed there are cracked versions of the software in circulation.
- The administrator running the service, known only as "P" said: "I don't care that much. This is entertainment that does not carry violence.
- "No one will blackmail anyone with this, since the quality is unrealistic."
- He also said the team looks at what photos are shared, and "when we see minors we block the user for good."
- But the decision on whether to share the photo with others is up to whoever used the bot to create it in the first place, he said.
- Defending its relative level of harm, he added: "There are wars, diseases, many bad things that are harmful in the world." He has also claimed he will soon remove all of the images.
- Telegram has not responded to a request for comment.
- Sensity reported that between July 2019 and 2020, approximately 104,852 women have been targeted and had fake naked images of them shared publicly.
- Its investigation found that some of the images appeared underage, "suggesting that some users were primarily using the bot to generate and share paedophilic content."
- Sensity said the bot has had significant advertising on the Russian social media site VK, and a survey on the platform showed that most users were from Russia and ex-USSR countries.
- But VK said: "It doesn't tolerate such content or links on the platform and blocks communities that distribute them."
- Telegram was officially banned in Russia until earlier this year.
- "Many of these websites or apps do not hide or operate underground, because they are not strictly outlawed," said Sensity's Giorgio Patrini.
- "Until that happens, I am afraid it will only get worse."
- This video can not be played
- Actress Bella Thorne opens up about her experience of deepfake abuse
- The authors of the report say they have shared all their findings with Telegram, VK and relevant law enforcement agencies, but have not had a response.
- Nina Schick, author of the book Deep Fakes and the Infocalypse, said deepfake creators were all over the world, and that legal protections were "playing catch-up" with the technology.
- "It's only a matter of time until that content becomes more sophisticated. The number of deepfake porn videos seems to be doubling every six months," she said.
- "Our legal systems are not fit for purpose on this issue. Society is changing quicker than we can imagine due to these exponential technological advances, and we as a society haven't decided how to regulate this.
- "It's devastating, for victims of fake porn. It can completely upend their life because they feel violated and humiliated."
- Last year the US state of Virginia became one of the first places to outlaw deepfakes
- The current UK law around fake nude images has recently been criticised for being "inconsistent, out-of-date and confusing" in a university report.
- Despite progress on issues like revenge porn and upskirting, "there remain many glaring gaps in the law", says Lucy Hadley of the Women's Aid charity.
- While these statistics show how widespread deep-fake images can be, it is not currently a specific offence.
- The government has instructed the Law Commission to review the law around the issue in England and Wales. Its findings are due in 2021.
- Google makes deepfakes to fight deepfakes
- Deepfake videos could 'spark' violence
- Deepfake porn videos banned by Twitter
- Fake porn videos deleted from internet
- Drones hit Moscow buildings after strikes on Kyiv kill one
- Top China scientist says don’t rule out Covid lab leak
- Malaysia says China ship looted British WW2 wrecks
- After a synagogue shooting, can a community heal?
- The 'exploding' demand for giant heat pumps
- Holmes is going to jail. Will she pay victims too?
- The Thai election upstart who vows to be different
- Teary reunion of Indians after a century-long separation
- Crackdown is 'untenable', Imran Khan tells BBC
- What to expect from newly emboldened Erdogan
- Why famous faces are popping up on UK streets
- The generation clocking the most hours
- Why it's 'imperative' to start using AI
- Jellyfish blooms: Why not just eat them?
- A 5,000-year-old craft under threat
- © 2023 BBC. The BBC is not responsible for the content of external sites. Read about our approach to external linking.

URL: https://www.wired.co.uk/article/deepfake-porn-websites-videos-law
- We may earn a commission if you buy something from any affiliate links on our site. Learn more.
- Matt Burgess
- Hundreds of explicit deepfake videos featuring female celebrities, actresses and musicians are being uploaded to the world’s biggest pornography websites every month, new analysis shows. The non-consensual videos rack up millions of views and porn companies are still failing to remove them from their websites.
- Up to 1,000 deepfake videos have been uploaded to porn sites every month as they became increasingly popular during 2020, figures from deepfake detection company Sensity show. The videos continue to break away from dedicated deepfake pornography communities and into the mainstream.
- Deepfake videos hosted on three of the biggest porn websites, XVideos, Xnxx, and xHamster, have been viewed millions of times. The videos are surrounded by adverts, helping to make money for the sites. XVideos and Xnxx, which are both owned by the same Czech holding company, are the number one and three biggest porn websites in world and rank in the top ten biggest sites across the entire web. They each have, or exceed, as many visitors as Wikipedia, Amazon and Reddit.
- One 30-second video, which appears on all three of the above sites and uses actress Emma Watson’s face, has been viewed more than 23 million times – being watched 13m times on Xnxx. Other deepfake videos, which have hundreds of thousands or millions of views, include celebrities such as Natalie Portman, Billie Eilish, Taylor Swift and Indian actress Anushka Shetty. Many of the celebrities have continuously been the targets of deepfakes since they first emerged in 2018.
- By Matt Kamen
- By Angela Watercutter
- By Chris Stokel-Walker
- By WIRED
- “The attitude of these websites is that they don't really consider this a problem,” says Giorgio Patrini, CEO and chief scientist at Sensity, which was until recently called DeepTrace. Deepfake pornography videos are widely considered to target, harm, and humiliate the women that are placed at their core. Patrini adds that Sensity has increasingly seen deepfakes being made for other people in the public realm, such as Instagram, Twitch and YouTube influencers, and worries the advancement of deepfake tech will inevitably see members of the public targeted.
- “Until there is a strong reason for them [porn websites] to try to take them down and to filter them, I strongly believe nothing is going to happen,” Patrini says. “People will still be free to upload this type of material without any consequences to these websites that are viewed by hundreds of millions of people”.
- Many of the videos are hiding in plain sight – they’re uploaded to be watched, after all. Some videos include “fake” or “deepfake” in their titles and are tagged as being a deepfake. For instance, tag pages on XVideos and Xnxx list hundreds of the videos.
- However, the full scale of the problem on porn websites is unknown. There will probably never be a true picture of how many of these videos are created without people’s permission.
- Despite repeated attempts to contact representatives of XVideos and Xnxx, the owners did not answer requests for comment on their attitudes and policies towards deepfakes.
- Alex Hawkins, VP of xHamster, says the company doesn’t have a specific policy for deepfakes but “treat it like any other non-consensual content.” Hawkins says that the company’s moderation process involves multiple different steps and it will remove videos if people’s images are used without permission.
- “We absolutely understand the concern around deepfakes, so we make it easy for it to be removed,” Hawkins says. “Content uploaded without necessary permission being obtained is in violation of our Terms of Use and will be removed once identified.” Hawkins adds that the dozens of videos appearing as deepfakes on xHamster, which were highlighted by WIRED, have been passed onto its moderation team to be reviewed.
- Deepfake upload figures seen WIRED did not include Pornhub, which is the second biggest porn website and despite banning deepfakes in 2018 still has problems with the videos.
- By Matt Kamen
- By Angela Watercutter
- By Chris Stokel-Walker
- By WIRED
- “There has to be some kind of thinking about what we do about this when women are embarrassed and humiliated and demeaned in this way on the internet, and it really is like a question about privacy and security,” says Nina Schick, a political broadcaster and the author of Deepfakes and the Infocalypse.
- Since the first deepfakes emerged from Reddit in early 2018, the underlying artificial intelligence technology needed to make them has advanced. It’s getting cheaper and easier for people to make deepfake videos and in one recent example a security researcher created video and audio of Tom Hanks using open-source software and spending less than $100.
- The tech advancements have led to increased fears around deepfakes being used to manipulate political conversations. While there have been some early examples of this happening the threat has largely failed to materialise. However, deepfake porn, where the technology was first invented, has flourished. Hollywood actress Kristen Bell said she was “shocked” when she first found out deepfakes were made using her image. “‘Even if it’s labelled as, ‘Oh, this is not actually her’ it’s hard to think about that, I’m being exploited”, she told Vox in June.
- Read more: Deepfakes are already breaking democracy. Just ask any woman
- The amount of deepfakes online is growing exponentially. A report from Sensity released last year found 14,678 deepfake videos online in July 2019 – 96 per cent of these were porn and almost all are focussed on women. By June this year the amount of deepfakes had climbed to 49,081.
- The majority of deepfake porn is found on, and created by, specific communities. The top four deepfake porn websites had received more than 134 million views last year, Sensity’s 2019 analysis shows. One deepfake porn website is full of videos featuring celebrities and contains videos of Indian actresses that have been watched millions of times. Some videos state they were requested, while their creators say they can be paid in Bitcoin.
- “Some of this technology is improving so fast, because there's so much energy and drive, unfortunately, from the creators’ side,” Patrini says. “I think we're going to be seeing it applied very soon with much larger intent to private individuals.” He believes when the technology is easy for anyone to use there will be a “tipping point” when lawmakers will become aware of the problems.
- By Matt Kamen
- By Angela Watercutter
- By Chris Stokel-Walker
- By WIRED
- Clare McGlynn, a professor at the Durham Law School who specialises in pornography regulations and sexual abuse images, agrees. “What this shows is the looming problem that is going to come for non-celebrities,” she says. “This is a serious issue for celebrities and others in the public eye. But my long-standing concern, speaking to individual survivors who are non-celebrities, is the risk of this is what is coming down the line.”
- At the moment, the legal options for people featured in deepfake videos has not kept up with the technology. In fact, it wasn’t ever prepared for the impact of AI-generated porn. “If a pornographic picture or video of you goes up online, your legal options for taking it down vary wildly,” says Aislinn O'Connell, a law lecturer from Royal Holloway University in London.
- People can pursue non-consensual uploads for defamation, under human rights laws, copyright complaints and other forms. However, most of these processes are onerous, resource-intensive and most often don’t apply to deepfakes. “We need more and better solutions now,” O'Connell says.
- Some deepfake laws have been passed in US states but these largely focus on politics and ignore the impact that deepfakes are already having on people’s lives. In the UK the Law Commission is conducting a review into the sharing on intimate images online, which includes deepfakes, but it is expected to take years until any changes can be made. O'Connell proposes that England adopts image rights laws so people can properly protect themselves.
- However, while lawmakers fail to deal with the problem the technology is set to become cheaper and easier for all to use. “I see the evolution of deep fakes in the pornographic space as actually the harbinger of the bigger civil liberties issues that are going to emerge,” Schick says.
- “This technology is out there and it is evolving at a rate that is much faster than society can keep up with,” she adds. “We are not ready for the age of synthetic media where even video becomes something that almost anybody can corrupt”. To fight this, Schick says, multiple people need to be involved – technologists, the public, domain specific experts, policy officials, and lawmakers. Right now, however, that’s not happening.
- Matt Burgess is WIRED's deputy digital editor. He tweets from @mattburgess1
- 🧠 Can’t focus? Here’s how to concentrate when working from home
- 🕺 Across London havoc is being caused by illegal Airbnb nightclubs
- 👟 If you started running during lockdown these are the best running shoes in 2020
- 🔊 Listen to The WIRED Podcast, the week in science, technology and culture, delivered every Friday
- 👉 Follow WIRED on Twitter, Instagram, Facebook and LinkedIn
- By Chris Stokel-Walker
- By Grace Browne
- By Morgan Meaker
- By Matt Burgess
- By Chris Stokel-Walker
- By Parth M.N.
- By Lily Hay Newman
- By Matt Burgess
- © Condé Nast Britain 2023.

URL: https://www.rollingstone.com/culture/culture-features/tiktok-creators-deepfake-pornography-discord-pornhub-1078859/
- By 

	Ej Dickson
- Last summer, a  pornographic video of a prominent TikTok creator started going viral on social media. A screengrab of the video on TikTok made its way to the Instagram account @tiktokroom, along with a comment from the creator whose face was posted in the video. “It’s a deepfake but still, my parents on this app, chill,” the creator said. (Rolling Stone is not naming this creator or any other creator referenced in this story, on the grounds that the videos were posted without their consent.)
- A deepfake is a digitally manipulated video that uses artificial-intelligence technology to swap the face of one person (often, but not always, a celebrity) onto another person’s body, usually without their consent. Much of the media focus on deepfakes has been on their potential to spread disinformation, particularly as it relates to a political campaign or election, as underscored by a doctored clip of Nancy Pelosi that went viral on Facebook last year. Yet the vast majority of deepfakes — 96 percent, according to 2019 research from the AI firm Sensity — are pornographic and used to target women.
- 
- In the past, deepfake technology was primarily used to create nude or sexually explicit images of female celebrities in particular. That’s in part because to actually build models for making deepfakes, you need thousands of photos or several minutes of video footage to do a good job, explains Giorgio Patrini, the founder and CEO of Sensity.
- But the technology has gotten more accessible and less complex, with terrifying results. Last week, Sensity released a report about an AI bot on the encrypted messaging app Telegram being used to create nude or sexually explicit images of hundreds of thousands of women without their consent. Unlike other software used to create deepfake videos, the bot only required the use of one photo to depict the women nude, which has led to non-famous women and girls being increasingly targeted. So too have influencers on platforms like Instagram and TikTok. “It’s video-based as a platform, so it actually provides more material [to make deepfakes],” says Patrini. “These people are more exposed than if they were just uploading pictures.”
- Editor’s picks
	
	






	
	
		
					The 50 Worst Decisions in Music History		
	









	
	
		
					The 200 Greatest Singers of All Time		
	









	
	
		
					The 500 Greatest Songs of All Time		
	









	
	
		
					The 100 Greatest TV Shows of All Time
- Danielle Citron, professor of law at the Boston University School of Law and vice president of Cyber Civil Rights Initiative, says the psychological impact of appearing in a pornographic deepfake video cannot be overestimated, and some have also compared nonconsensual pornography to a form of digital rape. “When you see a deepfake sex video of yourself, it feels viscerally like it’s your body. It’s an appropriation of your sexual identity without your permission. It feels like a terrible autonomy and body violation, and it rents space in your head,” she says. According to Patrini, appearing in a deepfake porn video can have a significant and deleterious financial impact on a creator’s business model, citing an example of a prominent YouTuber who lost a brand partnership after someone posted a deepfake video of her on a porn site.
- To make matters worse, nearly a third of TikTok users are under the age of 14, according to internal company data reviewed by the New York Times, rendering this population extra vulnerable to the threat. As Rolling Stone previously reported, it is not uncommon for underage TikTok creators to find their videos posted in compilation videos on tube sites like Pornhub. Rolling Stone spoke with the mother of a then-17-year-old girl who found that one of her TikTok videos had been posted on Pornhub. “She was mortified. She didn’t want to go back to school,” the mother, who requested not to be named, told me. “She very innocently posted that video. She didn’t want to get involved with Pornhub. It’s not a lesson you should have to learn at 17.” (She says Pornhub took the video down immediately at their request. In an email to Rolling Stone, Pornhub denied that TikTok content was frequently posted on its platform.)
- 
- In our investigation for this story, Rolling Stone found more than two dozen examples of prominent TikTok creators being featured in deepfake porn. Most of them are originally posted on one of a handful of websites devoted exclusively to posting deepfakes, but they are also not difficult to find on social media platforms like Twitter and Reddit, even though both platforms have policies banning deepfakes.
- In a statement, a Twitter spokesperson directed Rolling Stone to its policy prohibiting deepfakes, or any “intimate photos or videos of someone that were produced or distributed without their consent.” As of publication, it has not removed a tweet containing a deepfake pornographic video of two TikTok creators. Reddit, which also has a policy against posting nonconsensual deepfakes, did not immediately respond to request for comment.
- Related
	
	






	
	
		
					TikTok Is Giving a Niche Indie Band’s 2008 Music Millions of New Streams		
	









	
	
		
					How TikTok Teens Are Ending Up on Pornhub
- They are also not difficult to find on Pornhub and other tube sites, even though Pornhub bans deepfakes as well. “They’ve basically just banned people from labeling deepfakes. People could still upload them and use a different name,” says former Sensity researcher Henry Ajder. He estimates that “you probably have somewhere in the low thousands” of deepfakes on Pornhub.
- One of the most popular websites for deepfakes, which Rolling Stone is declining to name, had a Discord server with more than 100 members where users could request their favorite individual TikTok celebrities and influencers to be the subject of a deepfake. Although this website only publicly posts videos featuring creators over the age of 18, one of the most requested celebrities on this server is a popular TikTok creator who just turned 17. “Do [name redacted], by the way she turns 18 in 4 days,” one user recently said, requesting a creator. (The admin made the video and posted it on the website two weeks after she turned 18.)
- When asked about the server, Discord said that it violated its policies regarding nonconsensual nudity and that it had taken it down. “Discord has a zero-tolerance approach to nonconsensual pornography on the service and the company takes immediate action when we become aware of it,” a company spokesperson said. A notice on the deepfake pornography website, however, says it is “working on an alternative” server.
- 
- As for why people create deepfake pornography in the first place, Citron says that some mistakenly believe it is essentially a victimless crime. “The harm is so far away from people that it seems like a game,” she says. “You can appropriate someone’s body and you don’t have to ask them.” The deepfake pornography phenomenon stems from a “culture of impunity,” or the idea that young men are entitled to do as they please with women’s bodies.
- But even though some men may feel entitled to do what they want with influencers’ images, by virtue of the fact that they are public figures, at the end of the day being the subject of deepfake porn, Citron says, “feels like a virtual sexual assault.”
- We want to hear it. Send us a tip using our anonymous form.
- Rolling Stone is a part of Penske Media Corporation. © 2023 Rolling Stone, LLC. All rights reserved.

URL: https://www.buzzfeednews.com/article/janelytvynenko/telegram-deepfake-nude-women-images-bot
- A new AI bot primarily spreading across Russia and Eastern Europe has created fake nude images of more than 680,000 women.
- BuzzFeed News Reporter
- BuzzFeed News Reporter
- Over 680,000 women have no idea their photos were uploaded to a bot on the messaging app Telegram to produce photo-realistic simulated nude images without their knowledge or consent, according to tech researchers.
- The tool allows people to create a deepfake, a computer-generated image, of a victim from a single photo.
- Sensity, a visual threat intelligence company headquartered in Amsterdam, discovered the Telegram network of 101,080 members, 70% of whom appeared to reside in Russia or Eastern Europe.
- “This one’s unique because it’s not just people talking or people sharing content, it’s actually embedded in Telegram, and we have not found something similar,” said Giorgio Patrini, CEO and chief scientist at Sensity.
- About 104,852 images of women have been posted publicly to the app, with 70% of the photos coming from social media or private sources. A small number of these victims appeared to be underage. The rest of the images were likely shared privately, researchers say.
- Unlike the algorithms that make deepfake videos — including nonconsensual sexual videos — the Telegram bot doesn’t need thousands of images to work. It only needs one, “which is really a reason why so many private individuals are attacked, because only one profile picture from Facebook is enough to do this,” said Patrini.
- This harassment appears to be happening without the knowledge or consent of the photographed women, a vast majority of who are private citizens rather than celebrities or influencers.
- “As soon as you share images or videos of yourself and maybe you’re not so conscious about the privacy of this content, who can see it, who can steal it, who can download it without you knowing, that actually opens the possibility of you being attacked,” Patrini said.
- Nina Jankowicz, author of How to Lose the Information War, said this app shows that deepfakes go beyond politics. For Jankowicz, worries about the national security implications of a convincing fake video sidestep the reality that the technology is largely deployed to abuse women.
- “It’s really disturbing how accessible it is,” Jankowicz said. “Frankly, the thing that we’ve seen shared as evidence of the growing deep fake phenomenon, the little silly videos of Joe Biden that President Trump has shared, for instance, that stuff is far less sophisticated than what you’re talking about.”
- Jankowicz said the app has huge implications for women everywhere, especially in more socially conservative countries like Russia. Victims could be at risk of losing their job and livelihood if a convincing but fake nude photo were made public. Some could face partner violence.
- “Essentially, these deepfakes are either being used in order to fulfill some sick fantasy of a shunted lover, or a boyfriend, or just a total creepster," Jankowicz said. "Or they're used as potential blackmail material.”
- The app and the ease of accessibility speak to larger themes of online harassment and abuse women face online — something Jankowicz has experience with firsthand.
- “This is all part and parcel of the broader abuse and harassment that women have to deal with in the online environment, whether that's just trolling or whether it's the gendered and sexualized abuse coming from all sides of the political spectrum,” Jankowicz said. “It’s used as a weapon of trying to push women out of the public sphere. This is just an extension of that.”
- While Patrini and his team didn’t find proof of these images being used for extortion of women, they fear that possibility is fast approaching.
- Deepfake nudes often target celebrities, but this network appears to be more focused on people who are not famous. According to a poll of people using the Telegram channels by the people who run them, 63% of users it said they were interested in women they knew.
- “In the industry, at least, it is a known problem to some extent,” said Patrini, “but I really struggle to believe that at the level of private citizens it’s known by anyone.”
- According to Sensity, “All sensitive data discovered during the investigation detailed in this report has been disclosed with Telegram, [Russian social media site] VK, and relevant law enforcement authorities. We have received no response from Telegram or VK at the time of this report’s publication.”
- Patrini pointed out that so-called “porn bots” go against Telegram’s terms of service.
- The bot has been advertised on VK, with Sensity finding activity on 380 pages on the site.
- “VK doesn’t tolerate such content or links on the platform and blocks communities that distribute them. Also, please note that such communities or links were not promoted using VK advertising tools,” a VK spokesperson told BuzzFeed News after this story was published. ”We will run an additional check and block inappropriate content and communities.”
- This tool, which BuzzFeed News is declining to name, allows people to produce deepfakes on cellphones, remotely generating the images before sending them back to the user. The bot, which only works on images of women, provides watermarked images at no cost, and images without watermarks for a fee of about $1.50. Customers can also earn money by referring others to the service.
- “That’s the phenomenon of this technology becoming a commodity,” Patrini said. “No technical skill required, no specialized hardware, no special infrastructure or accessibility to specific services that are hard to reach.”
- According to Sensity, seven Telegram channels using the bot had attracted a combined 103,585 members by the end of July, a year since the tool was launched, with the most-populous channel having 45,615 people in it.
- Patrini reiterated that while many people fear how deepfake technology could be used in politics, its actual widespread use is the exploitation of women online.
- “This is not a problem of a high system of democracy, at least primarily. This is not a problem only for public figures and celebrities, but it’s going to be a problem for everybody, unfortunately quite soon,” Patrini said. “It’s already today a problem for hundreds of thousands of people.”
- BuzzFeed News Reporter
- Contact Jane Lytvynenko at jane.lytvynenko@buzzfeed.com.
- Got a confidential tip? 👉 Submit it here
- BuzzFeed News Reporter
- Contact Scott Lucas at scott.lucas@buzzfeed.com.

URL: https://www.wired.co.uk/article/porn-bots-in-telegram-deepfake
- We may earn a commission if you buy something from any affiliate links on our site. Learn more.
- Matt Burgess
- Messaging app Telegram is under pressure to crack down on an AI bot that generated tens of thousands of non-consensual images of women on its platform.
- Law enforcement bodies are looking into the activity of a deepfake bot, which is believed to have been used to produce explicit images of underage girls. Data protection regulators in Italy have also opened an investigation into its use, and access to the bot has been restricted on Apple’s iOS.
- The scrutiny of Telegram comes as multiple investigations into the use of the messaging service have discovered private groups sharing non-consensual “revenge porn” photos and videos of women, which are not generated by AI. Reports from America, Italy, South Korea, and Israel have all detailed how Telegram has been used to share abusive images over the last year.
- Researchers claim Telegram has failed to act against the deepfake bot which has automated the creation of non-consensual nude images of women. The bot uses a version of the DeepNude AI tool, which was originally created in 2019, to remove clothes from photos of women and generate their body parts. Anyone can easily use the bot to generate images. More than 100,000 abusive images have been publicly shared by the bot in and several Telegram chat channels associated with it. These channels contained tens of thousands of members each.
- By Matt Kamen
- By Angela Watercutter
- By Chris Stokel-Walker
- By WIRED
- When researchers at security firm Sensity discovered the bot on Telegram at the start of this year they reported it to the messaging app. The hope was the owners of the chat platform would scrub the bot from their platform and put a stop to the way women were being abused with technology. However this hasn’t happened.
- Since Sensity revealed the bot’s existence in October, the groups that used it to share images have hidden it. “It is actually harder now to actually get to the bot,” Giorgio Patrini, CEO and chief scientist at Sensity says. “The groups that were advertising the bots on Telegram have essentially gone silent.”
- A number of groups that used the bot have changed their names so they can avoid being identified. Many of the channels now share other content related to deepfake technology in general and a public gallery of ‘nude’ images created by the bot was wiped by its owner. And some of the channels have vanished completely.
- Although the groups around the bot are not currently posting about it, the bot still exists and continues to work. “The bot has never been taken down by anybody,” Patrini says. “Since we went public the bot is still operational and still is today.” In one instance the bot’s creator said the bot will keep operating under the radar. The creator, whose identity is unknown, did not respond to a request for comment.
- At the end of October, the Telegram bot became inaccessible on iPhone and iPads and showed a message saying it “violates” section 1.1 of Apple’s developer guidelines. Apple’s rules say “overtly sexual or pornographic material” is not allowed in apps accessible through the App Store. That message within Telegram has since been replaced with a generic warning that says the bot cannot be displayed.
- Apple did not respond to questions about Telegram or whether it told the company to put restrictions in place. Apple says that it is unable to block content or display any messaging in apps it doesn’t own, but that it does notify developers if it finds any content that goes against the App Store’s rules. These rules say apps that contain text, photos or videos uploaded by people who download them must also include a way to filter “objectionable” material from being posted. The bot is still available on Android devices and Telegram's Mac application.
- By Matt Kamen
- By Angela Watercutter
- By Chris Stokel-Walker
- By WIRED
- In one Telegram group chat about the bot, its owner says that Telegram has blocked mentions of its name. However, WIRED was unable to confirm this or any action taken by Telegram. Neither Telegram’s spokesperson or the service’s founder, Pavel Durov, responded to requests for comment. The company, which is believed to be based in Dubai but has servers all around the world, has never publicly commented about the harm caused by the Telegram bot or its continued position to allow it to operate.
- Since it was founded in 2013, Telegram has positioned itself as a private space for free speech and its end-to-end encrypted mode has been used by journalists and activists around the world to protect privacy and evade censorship. However, the messaging app has run into trouble with problematic content. In July 2017, Telegram said it would create a team of moderators to remove terrorism-related content after Indonesia threatened it with a ban. Apple also temporarily removed it from its App Store in 2018 after finding inappropriate content on the platform.
- “I think they [Telegram] have a very libertarian perspective towards content moderation and just any sort of governance on their platform,” says Mahsa Alimardani, a researcher at the Oxford Internet Institute. Alimardani, who has worked with activists in Iran, points to Telegram notifying its users about a fake version of the app created by authorities in the country. “It seems that the times that they have actually acted, it's when state authorities have got involved.”
- On October 23, Italy’s data protection body, the Garante per la Protezione dei dati Personali, opened an investigation into Telegram and has asked it to provide data. In a statement, the regulator said the nude images generated by the bot could cause “irreparable damage” to their victims. Since Italian officials opened their investigation, Patrini has conducted more research looking for deepfake bots on Telegram. He says there are a number of Italian-language bots that appear to offer the same functionalities as the one Sensity previously found, however they do not appear to be working.
- Separate research from academics of at the University of Milan and the University of Turin has also found networks of Italian-language Telegram groups, some of which were private and could only be accessed by invitation, sharing non-consensual intimate images of women that don’t involve deepfake technology. Some groups they found had more than 30,000 members and required members to share non-consensual images or be removed from the group. One group focussed on sharing images of women that were taken in public places without their knowledge.
- By Matt Kamen
- By Angela Watercutter
- By Chris Stokel-Walker
- By WIRED
- “Telegram should look inward and hold itself accountable,” says Honza Červenka, a solicitor at law firm McAllister Olivarius, which specialises in non-consensual images and technology. Červenka says that new laws are needed to force tech companies to better protect their users and clampdown on the use of abusive automation technology. “If it continues offering Telegram Bot API to developers, it should institute an official bot store and certify bots the same way that Apple, Google and Microsoft do for their app stores.” However, Červenka adds there is little government or legal pressure being put in place to make Telegram take this kind of step.
- Patrini warns that deepfake technology is quickly advancing and the bot of Telegram is a sign of what is likely to happen in the future. The bot on Telegram was the first time this type of image abuse has been seen at such a large scale and is easy for anyone to use – no technical expertise is needed. It was also one of the first times that members of the public were targeted with deepfake technology. Previously celebrities and public figures were the targets of non-consensual AI porn. But as the technology is increasingly democratised more instances of this type of abuse will be discovered online, he says.
- “This was one investigation but we are finding these sorts of abuses in multiple places on the internet,” Patrini explains. “There are, at a smaller scale, many other places online where images are stolen or leaked and are repurposed, modified, recreated and synthesised, or used for training AI algorithms to create images that use our faces without us knowing.”
- Matt Burgess is WIRED's deputy digital editor. He tweets from @mattburgess1
- 🚗 Drivers claim Uber’s algorithm fired them. Now they’re taking it to court
- 🎮 The next-gen consoles are coming. Here's our Xbox Series X review
- 🌍 How Africa has handled the pandemic so far
- 🔊 Listen to The WIRED Podcast, the week in science, technology and culture, delivered every Friday
- 👉 Follow WIRED on Twitter, Instagram, Facebook and LinkedIn
- By Matt Burgess
- By Matt Burgess
- By David Nield
- By Morgan Meaker
- By Angela Watercutter
- By Matt Burgess
- By Tracy Wen Liu
- By Morgan Meaker
- © Condé Nast Britain 2023.

URL: https://www.washingtonpost.com/technology/2020/10/20/deep-fake-nudes/
- This article was published more than 2 years ago
- An artificial intelligence service freely available on the Web has been used to transform more than 100,000 women’s images into nude photos without the women’s knowledge or consent, triggering fears of a new wave of damaging “deepfakes” that could be used for harassment or blackmail.
- Users of the automated service can anonymously submit a photo of a clothed woman and receive an altered version with the clothing removed. The AI technology, trained on large databases of actual nude photographs, can generate fakes with seemingly lifelike accuracy, matching skin tone and swapping in breasts and genitalia where clothes once were.
- The women’s faces remain clearly visible, and no labels are appended to the images to mark them as fake. Some of the original images show girls younger than 18.
- The service, which allows people to place new orders through an automated “chatbot” on the encrypted messaging app Telegram, was first discovered by researchers at Sensity, an Amsterdam-based cybersecurity start-up that shared its findings with The Washington Post.
- The chatbot and several other affiliated channels have been used by more than 100,000 members worldwide, the researchers found. In an internal poll, the bot’s users said roughly 63 percent of the people they wanted to undress were girls or women they knew from real life.
- Giorgio Patrini, the group’s chief executive, said the chatbot signals a dark shift in how the technology is used, from faking images of celebrities and well-known figures to targeting unsuspecting women far from the public eye.
- “The fact is that now every one of us, just by having a social media account and posting photos of ourselves and our lives publicly, we are under threat,” Patrini said in an interview. “Simply having an online persona makes us vulnerable to this kind of attack.”
- The chatbot’s growth signals just how quickly the technology behind fake imagery has become ubiquitous.
- Ten years ago, creating a similarly convincing fake would have taken advanced photo-editing tools and considerable skill. Even a few years ago, creating a lifelike fake nude using AI technology — such as the “deepfake” porn videos in which female celebrities, journalists and other women have been superimposed into sex scenes — required large amounts of image data and computing resources.
- Fake-porn videos are being weaponized to harass and humiliate women: ‘Everybody is a potential target’
- But with the chatbot, creating a nude rendering of someone’s body is as easy as sending an image from your phone. The service also assembles all of those newly generated fake nudes into photo galleries that are updated daily; more than 25,000 accounts have already subscribed for daily updates.
- The bot’s biggest user base is in Russia, according to internal surveys, though members also originate from the United States and across Europe, Asia and South America.
- New users can request some of their first fake nudes for free but are encouraged to pay for further use. A beginners’ rate offers new users 100 fake photos over seven days at a price of 100 Russian rubles, or about $1.29. “Paid premium” members can request fake nude photos be created without a watermark and hidden from the public channel.
- The chatbot’s administrator, whom The Post interviewed Monday through messages on Telegram, declined to give their name but defended the tool as a harmless form of sexual voyeurism and said its operators take no responsibility for the women targeted by its user base. As an allusion to its boys-will-be-boys posture, the service’s logos feature a smiling man and a woman being ogled by X-ray glasses.
- But technology and legal experts argue that the software is weaponizing women’s own photographs against them, sexualizing women for a faceless group of strangers and presaging a new age of fabricated revenge porn.
- Some tech giants have taken a stand against deepfakes and other “manipulated media.” But because the system’s source code has already been widely shared by online copycats, the experts see no clear way to stop similar software from creating, hosting and sharing fake nude images across the unregulated Web.
- Some of the targeted women are popular entertainers or social media influencers with sizable audiences. But many of those seen in publicly available photos produced by the bot are from everyday workers, college students and other women, often taken from their selfies or social media accounts on sites like TikTok and Instagram.
- Danielle Citron, a Boston University law professor who researches the online erosion of “intimate privacy,” said she has interviewed dozens of women about the experience of having real or manufactured nude images shared online. Many said they felt deep anguish over how their images had been seen and saved by online strangers — and, potentially, their co-workers and classmates.
- “You’ve taken my identity and you’ve turned it into porn . . . That feels so visceral, harmful, wrong,” Citron said. “Your body is being taken and undressed without your permission, and there’s documentary evidence of it. . . . Intellectually, [you] know it hasn’t happened. But when [you] see it, it feels as if it has, and you know others won’t always know” it’s fake.
- “The vulnerability that creates in how you feel about your safety in the world: Once you rip that from somebody, it’s very hard to take back,” she added.
- The bot gives users advice on submitting requests, recommending that the original photos be centered at the women’s breasts and show them in underwear or a swimsuit for best results. But many of the images show women in unrevealing school attire or everyday clothes, like a T-shirt and jeans. At least one woman was pictured in a wedding dress.
- One young woman had multiple photos of her submitted to the service, some of which included a fake bikini top crudely inserted on top of her normal clothes — likely an attempt to improve the bot’s performance.
- The automated service, however, only works on women: Submit an image of a man — or an inanimate object — and it will be transformed to include breasts and female genitalia. (In one submitted image of a cat’s face, its eyes were replaced with what appeared to be nipples.)
- The bot’s administrator, speaking in Russian, told The Post in a private chat on Monday that they didn’t take responsibility for how requesters used the software, which they argued was freely available anyway. “If a person wants to poison another, he’ll do this without us, and he’ll be the one responsible for his actions,” the administrator wrote.
- The Sensity researchers counted more than 104,000 images of women altered to appear nude and shared in public channels. A website for the service suggests that number is far higher, with 687,322 “girls nuded” and 83,364 “men enjoyed.” But the administrator said that number was random and used only for advertising, because they do not keep statistics of processed photos.
- The bot’s rules say it does not allow nudes to be made of underage girls. But the service’s publicly visible collections feature teenage girls, including a popular TikTok personality who is 16 years old.
- The administrator said the system was designed merely to fulfill users’ fantasies and that everyone who would see the images would realize they were fakes.
- “You greatly exaggerate the realness,” the administrator said. “Each photo shows a lot of pixels when zoomed-in. All it allows you to do is to make fantasy a reality, visualize and understand that it’s not real.”
- The administrator also said the service had not “received a single complaint from a girl during the entire period of our work,” and attempted to shift the blame onto victims of the fakes for posting their images online.
- "To work with the neural network, you need a photo in a swimsuit or with a minimum amount of clothing. A girl who puts a photo in a swimsuit on the Internet for everyone to see — for what purpose does (she do) this?” the administrator wrote. “90% of these girls post such photos in order to attract attention, focusing on sexuality.”
- Following questions from a Post reporter, however, the administrator said they had disabled the bot’s chat and gallery features because of a “lot of complaints about the content.” The service for creating new images, and previously generated images, remained online.
- Representatives for Telegram, which offers end-to-end encryption and private chat functions, did not respond Monday to requests for comment.
- How the founder of the Telegram messaging app stood up to the Kremlin — and won
- Britt Paris, an assistant professor at Rutgers University who has researched deepfakes, said manipulators have often characterized their work as experimenting with new technology in a lighthearted way. But that defense, she said, conveniently ignores how misogynistic and devastating the images can be.
- “These amateur communities online always talk about it in terms of: ‘We’re just . . . playing around with images of naked chicks for fun,’ ” Paris said. “But that glosses over this whole problem that, for the people who are targeted with this, it can disrupt their lives in a lot of really damaging ways.”
- The bot was built on open-source “image-to-image translation” software, known as pix2pix, first revealed in 2018 by AI researchers at the University of California at Berkeley. By feeding the system a huge amount of real images, it can recognize visual patterns and, in turn, create its own fakes, transforming photos of landscapes from daytime to night, or into full color from black-and-white.
- The software relies on an AI breakthrough known as generative adversarial networks, or GANs, that has exploded in popularity in recent years for its ability to process mounds of data and generate lifelike videos, images and passages of text.
- Dating apps need women. Advertisers need diversity. AI companies offer a solution: Fake people
- The researchers behind pix2pix celebrated its potential benefits for artists and visual creators. But last year, an anonymous programmer trained the underlying software on thousands of photos of naked women, effectively teaching the system to transform women from clothed to nude.
- After the tech blog Motherboard wrote last year about the app, called DeepNude, the developer responded to the online backlash by taking the free-to-download app offline, saying, “The probability that people will misuse it is too high."
- The deep-learning pioneer Andrew Ng last year called DeepNude “one of the most disgusting applications of AI,” adding: “To the AI Community: You have superpowers, and what you build matters. Please use your powers on worthy projects that move the world forward.”
- But the existence of the chatbot shows how it will be virtually impossible to eradicate the software outright. The original app’s source code has been saved and widely distributed online, including in for-profit websites that offer to generate images in exchange for a small fee.
- Top AI researchers race to detect ‘deepfake’ videos: ‘We are outgunned’
- Hany Farid, a computer scientist at UC-Berkeley who specializes in digital-image forensics and was not involved in the original pix2pix research, said the fake-nude system also highlights how the male homogeneity of AI research has often left women to deal with its darker side.
- AI researchers, he said, have long embraced a naive techno-utopian worldview that is hard to justify anymore, by openly publishing unregulated tools without considering how they could be misused in the real world.
- “It’s just another way people have found to weaponize technology against women. Once this stuff gets online, that’s it. Every potential boyfriend or girlfriend, your employer, your family, may end up seeing it,” Farid said. “It’s awful, and women are getting the brunt of it.
- “Would a lab not dominated by men have been so cavalier and so careless about the risks?” he added. “Would [AI researchers] be so cavalier if that bad [stuff] was happening to them, as opposed to some woman down the street?”
- That problem is already a reality for many women around the world. One woman targeted by the bot, an art student in Russia who asked to remain anonymous because she did not want to get involved with these “stupid people,” had a photo of herself in a tank top taken from her Instagram account and transformed into a fake nude.
- In an interview, she compared the fake to someone smearing her name but said she was grateful that enough people knew her to realize it probably wasn’t real.
- “The scammers who do this kind of filth will not succeed,” she said. “I believe in karma, and what comes around for them won’t be any cleaner than their own actions."
- Isabelle Khurshudyan and Will Englund contributed to this report.

URL: https://www.msn.com/en-us/money/other/deepfake-bots-on-telegram-make-the-work-of-creating-fake-nudes-dangerously-easy/ar-BB1adbFs
- This page doesn’t exist or can’t be found.
- To find something you’ll like, click a category above or use the search box.
- 2023-05-30T09:10:27.2157294+00:00
- fc668515-efdf-4b35-948d-e76ec45a458c

URL: https://www.technologyreview.com/2020/10/20/1010789/ai-deepfake-bot-undresses-women-and-underage-girls/
- A technology similar to DeepNude, the 2019 app that shut down shortly after launch, is now spreading unfettered on Telegram.
- Update 10/28: Since the publication of this article, the deepfake bot on Telegram has been blocked on iOS for violating App Store guidelines, according to the researchers. The main Telegram channel that hosted the bot and an affiliated channel for sharing its creations has also been removed.
- In June of 2019, Vice uncovered the existence of a disturbing app that used AI to “undress” women. Called DeepNude, it allowed users to upload a photo of a clothed woman for $50 and get back a photo of her seemingly naked. In actuality, the software was using generative adversarial networks, the algorithm behind deepfakes, to swap the women’s clothes for highly realistic nude bodies. The more scantily clad the victim, the better. It didn’t work on men.
- Within 24 hours, the Vice article had inspired such a backlash that the creators of the app quickly took it down. The DeepNude Twitter account announced that no other versions would be released, and no one else would get access to the technology.
- But a new investigation from Sensity AI (previously Deeptrace Labs), a cybersecurity company focused on detecting the abuse of manipulated media, has now found very similar technology being used by a publicly available bot on the messaging app Telegram. This time it has an even simpler user interface: anyone can send the bot a photo through the Telegram mobile or web app and receive a nude back within minutes. The service is also completely free, though users can pay a base of 100 rubles (approximately $1.50) for perks such as removing the watermark on the “stripped” photos or skipping the processing queue.
- As of July 2020, the bot had already been used to target and “strip” at least 100,000 women, the majority of whom likely had no idea. “Usually it’s young girls,” says Giorgio Patrini, the CEO and chief scientist of Sensity, who coauthored the report. “Unfortunately, sometimes it’s also quite obvious that some of these people are underage.”
- The deepfake bot, launched on July 11, 2019, is connected to seven Telegram channels with a combined total of over 100,000 members. (This number doesn’t account for duplicate membership across channels, but the main group has more than 45,000 unique members alone.)
- The central channel is dedicated to hosting the bot itself, while the others are used for functions like technical support and image sharing. The image-sharing channels include interfaces that people can use to post and judge their nude creations. The more a photo gets liked, the more its creator is rewarded with tokens to access the bot’s premium features. “The creator will receive an incentive as if he’s playing a game,” Patrini says.
- The community, which is easily discoverable via search and social media, has steadily grown in membership over the last year. A poll of 7,200 users showed that roughly 70% of them are from Russia or other Russian-speaking countries. The victims, however, seem to come from a broader range of countries, including Argentina, Italy, Russia, and the US. The majority of them are private individuals whom the bot’s users say they know in real life or whom they found on Instagram. The researchers were able to identify only a small handful of the women and tried to contact them to understand their experiences. None of the women responded, Patrini says.
- The researchers also reached out to Telegram and to relevant law enforcement agencies, including the FBI. Telegram did not respond to either their note or MIT Technology Review’s follow-up request for comment. Patrini says they also haven’t seen “any tangible effect on these communities” since contacting the authorities.
- Abusers have been using pornographic imagery to harass women for some time. In 2019, a study from the American Psychological Association found that one in 12 women end up being victims of revenge porn at some point in their life. A study from the Australian government, looking at Australia, the UK, and New Zealand, found that ratio to be as high as one in three. Deepfake revenge porn adds a whole new dimension to the harassment, because the victims don’t realize such images exist.
- There are also many cases in which deepfakes have been used to target celebrities and other high-profile individuals. The technology first grew popular in the deep recesses of the internet as a way to face-swap celebrities into porn videos, and it’s been used as part of harassment campaigns to silence female journalists. Patrini says he’s spoken with influencers and YouTubers, as well, who’ve had deepfaked pornographic images of them sent directly to their sponsors, costing them immense emotional and financial strain.
- Patrini suspects these targeted attacks could get a whole lot worse. He and his fellow researchers have already seen the technology advance and spread. For example, they discovered yet another ecosystem of over 380 pages dedicated to the creation and sharing of explicit deepfakes on the Russian social-media platform VK. (After the publication of this article, a spokesperson from VK sent MIT Technology Review a statement: "VK doesn’t tolerate such content or links on the platform and blocks communities that distribute them. We will run an additional check and block inappropriate content and communities.") The researchers also found that the “undressing” algorithm is starting to be applied to videos, such as footage of bikini models walking down a runway. Right now, the algorithm must be applied frame by frame—“it’s very rudimentary at the moment,” Patrini says. “But I’m sure people will perfect it and also put up a license service for that.”
- Unfortunately, there are still few ways to stop this kind of activity—but awareness of the issues is growing. Companies like Facebook and Google, and researchers who produce tools for deepfake creation, have begun to more seriously invest in countermeasures like automated deepfake detection. Last year, the US Congress also introduced a new bill that would create a mechanism for victims to seek legal recourse for reputational damage.
- In the meantime, Patrini says, Sensity will continue to track and report these types of malicious deepfakes, and seek to understand more about the motivations of those who create them and the impacts on victims’ lives. "Indeed, the data we share in this report is only the tip of the iceberg," he says.
- Update: An official statement from the Russian social media platform VK has been added to the article.
- The invasion of Ukraine supercharged the decline of the country’s already struggling tech sector—and undercut its biggest success story, Yandex.
- AI is already being used in the legal field. Is it really ready to be a lawyer?
- Following recent announcements by Google and Twitter, more data deletion policies are coming.
- Google will delete accounts after two years of inactivity, and experts expect more data deletion policies to come
- Discover special offers, top stories,
            upcoming events, and more.
- Thank you for submitting your email!
- It looks like something went wrong.
- We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.
- 
- © 2023 MIT Technology Review

URL: https://www.inputmag.com/culture/bots-on-telegram-are-creating-deepfake-nudes-of-thousands-of-women
- Culture
- 100K
- How many women have been targeted so far.
- Sensity
- Cloud-based messaging platform Telegram is a hotbed for pornographic deepfakes, according to a security investigation carried out by Sensity. The analysis describes the end-to-end encrypted messenger as a "deepfake ecosystem" where bots are able to turn everyday photos of people into "strip naked" content, particularly of women.
- These bots are powered by artificial intelligence, per Sensity, and carry out actions of "stripping" a photo without clothes, often for public shaming and extortion. The firm describes this process as a kind of editing feature which can be easily used by smartphone and traditional computer owners. All they need to do is to retrieve a photo from their personal images gallery and allow the bots to generate the deepfake. These photos can be from anywhere and everywhere on the internet.
- What Sensity found — Here are Sensity's key findings:
- How these bots work — In previous reports, Input has explained how bots are able to generate their own images based on original sources like photos and videos. In the case of Telegram's deepfake bots, these bots rely on previously mentioned generative adversarial networks. They strip the original image of the woman in clothes to a "realistic approximation" of the individual's anatomy.
- This kind of synthesis depends on the bot's ability to effectively guess the individual's body parts and size. Of course, in order for it to work "perfectly," these bots are trained on copious amounts of visual data related to women's bodies.
- This is ugly news for Telegram. The network already has a questionable reputation thanks to white supremacists frequently using the messenger. Now with bots making fake nudes out of unsuspecting people, including minors reportedly, the messaging program is only cementing its image as a deeply compromised platform.

URL: https://www.cnet.com/news/deepfake-bot-on-telegram-is-violating-women-by-forging-nudes-from-regular-pics/
- Your guide to a better future
- Free, easy and requiring just a single still photo, the deepfake bot has produced more than 100,000 fake pornographic images publicly posted online for anyone to see.
- A free, easy-to-use deepfake bot found on the Telegram messenger app has victimized seemingly hundreds of thousands of women by replacing the clothed parts of their bodies in photos with nudity. More than 100,000 of these nonconsensual sexual images have been posted publicly online, but the bot has produced hundreds of thousands more that haven't been traced.
- A website promoting the bot claimed that more than 700,000 images of women have been manipulated to replace their clothing with nudity, as of Thursday, and that more than 100,000 abusers have uploaded images to the bot. Those numbers couldn't be independently verified.
- The victims are mostly private individuals, women whose photos were taken off social media or pulled from a personal stash of pics, according to a research report about the bot Tuesday, which traced more than 100,000 publicly posted images of victims of this bot. Some victims had originally been photographed in bathing suits or underwear. Some were wearing simple T-shirts and shorts. Some were visibly underage. All are women.
- Deepfake porn isn't new. Deepfake technology -- artificial intelligence that makes sophisticated media forgeries -- has been used early and often to fabricate pornography. But this Telegram bot takes the ease and access of this technology to a new level.
- "The innovation here is not necessarily the AI in any form," said Giorgio Patrini, CEO of deepfake-research company Sensity and coauthor of the report. "It's just the fact that it can reach a lot of people, and very easily."
- Computer manipulation of media has existed for decades, and sexual imagery has been weaponized online for as long as the internet could host photos. Whether it's nude photos posted without consent or crudely doctored forgeries, sexual images have been weaponized to extort, threaten, humiliate and harass victims.
- A Sensity diagram of how nonconsensual sexual images are created and shared by the Telegram bot.
- But only in the last few years has deepfake tech intensified the threat of manipulated sexual media, posing frightening implications for what may come.
- "The deepfake phenomenon is even more alarming because it doesn't look Photoshopped. It's much more easy for somebody without the technical knowledge to make one," said Mary Anne Franks, a law professor at the University of Miami and president of the online-abuse nonprofit Cyber Civil Rights Initiative. "It also makes the ability to avoid this kind of abuse much more difficult."
- With this Telegam bot, any woman who's ever posted a selfie of herself from the waist up could be a potential victim. Even women out walking could be victimized if surreptitiously snapped by the wrong stranger.
- And in one of the most disturbing forms of abuse with this bot, photographs of children have been uploaded to the bot's AI, automatically manipulated to sexualize the child and then shared publicly.
- Neither Sensity's report nor this article are disclosing the name of the bot, to avoid amplifying it. CNET viewed galleries of images with the bot's watermark posted online and interacted with the bot itself, stopping short of uploading any photos for it to manipulate.
- Telegram's tenacious commitment to free speech and privacy may make bots like this challenging to stamp out. Telegram has been criticized for hosting terrorist propaganda and coordination, facilitating piracy and copyright infringement, and harboring varieties of predatory pornography. But the service has also taken actions to remove abuse, such as kicking off groups for violent extremists like neo-Nazis and ISIS.
- "There's clearly value in encrypted platforms" like Telegram, said Sam Gregory, a program director with human-rights video organization Witness, who also advised Sensity on its report. "That doesn't mean they shouldn't be thinking about the use of their platform for things that have nothing to do with free expression."
- Sensity reached out to Telegram multiple times over the last six months about its findings. Telegram didn't respond to Sensity's outreach, nor did Telegram respond to CNET's messages seeking comment.
- Deepfake technology is like a high-speed Photoshop conveyor belt on steroids. Using a kind of artificial intelligence known as neural networks, deepfake tech can generate media forgeries that make people appear to be doing or saying things they never did. The term deepfake is used most often with videos, but deepfakes can refer to any so-called "synthetic" media produced by deep machine learning, including pornographic still photos.
- If this bot on Telegram sounds disturbingly familiar, a similar technology called DeepNude leaped to prominence last year, only to become so popular in a single day, after it was exposed in a news article, that its programmer shut it down.
- Like the Telegram bot, DeepNude used artificial intelligence to automatically generate nonconsensual sexual images of women in photos, replacing their photographed clothing with nudity. Both, in effect, appear to "strip" victims of what they're wearing in their pictures.
- DeepNude was a website offering Windows and Linux apps that required some level of technical savvy to operate. In fact, the AI powering the Telegram bot appears to be an open-source version of DeepNude's software. But the new bot is simpler and easier to use than the original desktop app, and it's available to anyone on Telegram. The bot will accept your first photo to manipulate after tapping just a few prompts.
- The bot is also designed to make it easy for abusers to share the manipulated images by posting them in chats and other online forms.
- These nonconsensual sexual images have "been put out there to be found," Patrini said. "They're completely open, without any login, without any passwords, on the internet. Those are actually exposed completely."
- Sensity found 104,852 images of women that were victimized by the bot and then shared publicly, as of the end of July. While each image may not be of a unique individual, Patrini said instances of the same woman being victimized, or the same photo being manipulated repeatedly, were rare.
- The 100,000-plus total number of images is limited to manipulated photos that were publicly posted and that Sensity was able to track down. Sensity doesn't know the scope of material that is not shared, Patrini added. "But definitely we are talking about some multiplier of that 100,000."
- The bot's promotional website suggests that as many as 700,000 images have been manipulated by the bot.
- And the bot is growing in popularity. A year ago, about 1,000 images manipulated by the bot were posted in channels in a month. In July, that number had swelled to at least 24,168 images, according to Sensity.
- And while deepfake pornography has long fixated on victimizing actresses, models and other celebrity women, 70% of this bot's targets were private individuals, according to a self-reported survey of the bot's users in Sensity's report.
- About 100,000 people are members of channels linked to the bot, Sensity found. These members overwhelmingly come from Russia and former-USSR countries, about 70% of those surveyed. Telegram is used globally, but its roots are in Russia, and links to the Telegram bot posted on VK, Russia's dominant social network, are the most common way that abusers have found the bot. Telegram and VK were both founded by Pavel Durov, sometimes referred to as Russia's Mark Zuckerberg.
- In a statement, VK said it doesn't tolerate such content or links on its platform and blocks communities that distribute them.
- The bot is built with a "freemium" business model, providing free users with a basic level of functionality and reserving advanced features for those who pay. It's the kind of user-friendly strategy that has helped legal, legitimate apps and games like Spotify and Fortnite become worldwide phenoms.
- Abusers can use the bot free by sending photos to it one at a time, seemingly up to five a day. But "paid premium" features include sending multiple pics, skipping the line of free users and removing watermarks from the pornographic images they get in return.
- But the bot's business strategy is also ambitious, inspired by strategies from gaming and classic promotional tropes.
- In a gamefied turn, the premium features are paid for with virtual "coins." These coins can be purchased cheap with real currencies, and coin lotteries appear to distribute some for free. They can also be earned, as rewards.
- One of the rewarded behaviors is recruiting new users. And because the app says that its virtual coins can be paid back in rubles, it effectively creates a system that pays abusers money in a government-issued currency for bringing in new abusers.
- Fortunately, the payouts are presumably meager: The value of the bot's coins are cheap, roughly five cents each.
- The bot's designer has also adopted classic promotional tactics. You can get a deeper discount on coins with the more of them you buy. The bot pitches new users with a one-time "beginner rate" special on coins.
- The bot also underscores how a fixation on electoral deepfakes misses wider damage caused by pornographic ones, which are much more common and already devastating victims.
- Researchers created deepfakes that graft candidates' faces onto impersonators' heads, in order to test a system to debunk them.
- "So much of the focus on deepfakes is in an electoral context," Gregory said. A preoccupation with "the perfect deepfake" of a political candidate or world leader is the kind of disinformation that tends to stoke congressional hearings. But that overlooks the harm being caused to regular people, at a larger and rapidly increasing scale, where even a poor-quality deepfake is still deeply harmful.
- "We know that nonconsensual images are used against ordinary people, against journalists ... and to target civic activists," Gregory said.
- Even with a bot like this operating for months, Witness hasn't observed an explosion of that kind of harassment yet. "Which is a good thing," Gregory added. "That doesn't mean we shouldn't be extremely vigilant."
- But even vigilance is unlikely to result in justice for victims, Franks said, who pointed to a historical failure of our legal systems to address weaponized sexual imagery years ago.
- "We wouldn't be in this position, where we have technology capable of releasing this kind of malicious content at such a scale ... if we paid attention before. We need to do better now," she said. "If there's any good to come of this terrible technology, it's that people may take this more seriously."

URL: https://www.telegraph.co.uk/technology/2020/10/21/deep-fake-porn-bot-targets-thousands-women-telegram/
- Amsterdam-based intelligence company Sensity uncovered the free-to-use bot which has been operating since July 2019
- A bot operating on the social media platform Telegram has generated nude images of more than 100,000 real women, according to a new report.
- The Amsterdam-based intelligence company Sensity uncovered the free-to-use bot which has been operating since July 2019.
- Using artificial intelligence, the technology allows users to upload a picture of a woman with her clothes on and after a short wait, the bot will return a manipulated version of the image, made to look as if the subject has been stripped naked.
- The report said these "deepfake" images can be downloaded and therefore shared in private or public channels outside of Telegram, meaning they can be used to extort or publicly shame their target.
- The bot only works on women.
- Deepfake technology is not new. But Sensity's chief executive Giorgio Patrini said the Telegram bot is significant because it's so easy to use.
- "All users need to do here is find these groups, know the keywords, then simply upload one single picture to have the bot do its job," he said.
- Telegram did not immediately reply to The Telegraph's request for comment and the bot is still available on the site.
- "Telegram's Terms of Service fails to mention what kind of content the bots available on Telegram are allowed to upload or prohibited from distributing," said Ksenia Bakina, Legal Officer, Privacy International. "This suggests that the deepfake nudes bot isn't breaking Telegram's Terms of Service and that's part of the reason why Telegram has failed to delete it."
- Experts believe the technology which has been embedded on the network can be traced back to the DeepNude app which also used AI to undress images of women.
- After public outrage, the creator took the app offline in June 2019, saying in a Twitter statement: "The world is not yet ready for DeepNude".
- However Nina Schick, author of Deep Fakes and the Infocalypse, said last year, the developers quietly sold the machine learning system in an anonymous auction for $30,000.
- "It's obvious then that know-how has now leaked and been repurposed," she said.
- She added the bot is so harmful because it can be used against any women - including minors.
- "Any woman can be a target because who doesn't have a digital footprint online either through social media, their friends' or family's social media, or through work," she said.
- The vast majority of the bot's users are from Russia and former USSR countries, with 3pc from English-speaking countries such as the UK and the US.
- Even though the naked images created by the bot are often obviously manipulated, this hasn't affected the demand, said Sensity's Patrini.
- "From the point of view of the victims, that doesn't really matter," he said. "Seeing a photo of yourself naked in the situation where you didn't take photo is quite threatening and quite shocking for the victim in spite of the quality."
- Although there has been much discussion about the potential affect of deepfakes on politics, when Sensity—formerly known as DeepTrace Labs— surveyed 14,000 deepfake videos online last year, the company found 96pc featured pornography; all of it targeting women.

- DeepNude nudification
- Deepsukebe non-consensual nudification
- Page infoType: IncidentPublished: March 2023
