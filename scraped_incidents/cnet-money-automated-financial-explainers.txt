- Released: October 2022
- Can you improve this page?Share your insights with us
- In October 2022, US-based technology news website CNET was discovered by Futurism's The Byte to be using 'automation technology' to publish a series of financial explainer articles, prompting critics to voice concerns about the future of journalism and journalistic jobs.
- 75 articles had been published since the 'CNET Money' programme started early November 2022, with topics ranging from 'What is Compound Interest?' to 'How to cancel you home equity loan'. Each article was by-lined 'CNET Money Staff'.
- During this period, most CNET employees had been kept in the dark about what tools the company was using or how it was using them and that, 'at times, they didn’t know if content published to CNET was AI-generated or written by their human colleagues.'
- 'This is just the beginning,' tweeted Washington Post reporter Nathan Grayson in response to the story, 'and aggregation plus explanation performed by AI will doubtless result in lower-quality work and fewer jobs.'
- Platformer journalist Casey Newton called it 'a grim development for journalism, as more of the work once reserved for entry-level writers building their resumes is swiftly automated away.'
- According to a CNET owner Red Ventures employee, 'All it's doing is forcing writers away from their jobs, delivering a worse product to readers, and putting more money into corporate products off the hard work of others.'
- CNET initially failed to respond to questions about its programme, which it appeared to be trying to keep as low profile as possible. CNET editor-in-chief Connie Guglielmo later confimed the use of AI, said the byline had been changed to 'CNET Money', and the disclosure about the use of AI made more prominent on relevant articles.
- A few days later, Futurism pointed out that an AI explainer on compound interest made a series of 'bone-headed' errors, underlining the difficulty text generators have in distinguishing fact from fiction. Guglielmo had previously committed that every CNET article 'is reviewed, fact-checked and edited by an editor with topical expertise before we hit publish'.
- Every AI-generated article was then updated with a note that reads: 'Editors' note: We are currently reviewing this story for accuracy. If we find errors, we will update and issue corrections,' Vice observed.
- On January 20, The Verge reported that Red Ventures had paused AI-generated content across its properties, including CNET. Red Ventures also confirmed the AI is a proprietary tool that enables editors to generate fully AI-written stories, or a combination of AI-generated text and their own writing or reporting.
- It subsequently came to light that AIs used by Red Ventures appear to include Wordsmith and OpenAI’s GPT series - neither of whch are proprietary to the company.
- Futurism also discovered that CNET's AI had been directly plagiarising the work of Red Ventures competitors, in addition to human writers at Red Ventures-owned websites, including CNET, and that the publisher had had to correct 41 of the 77 stories it's AI tool had 'written'.
- A week after Red Ventures had paused its AI publishing activities, it transpired that its properties Bankrate and CreditCards.com had re-started, only to pull its latest AI-generated articles due to another flood of inaccuracies.
- On January 19, 2023, The Verge published an detailed look at Red Ventures' search engine optimisation (SEO)-driven business model focusing on the monetisation of its media properties through credit card affiliate fees.
- According to The Verge, AI enables Red Ventures to flood Google with content and to collect fees when visitors click through to a credit card or mortgage application. AI lowers the cost of content creation, increasing the profit for each click. Affiliate industry sites estimate the bounty for a credit card signup to be around USD 250 each.
- It later transpired that Red Ventures is also using AI to re-write existing articles in order to attract search engines and maximise revenue, and that errors are also being automatically inserted into these re-writes.
- Connie Guglielmo published a new statement admitting the firm's AI had not been properly used, and setting out what CNET intended to do about it:
- 'In a handful of stories, our plagiarism checker tool either wasn't properly used by the editor or it failed to catch sentences or partial sentences that closely resembled the original language. We're developing additional ways to flag exact or similar matches to other published content identified by the AI tool, including automatic citations and external links for proprietary information such as data points or direct quotes. We're also adding additional steps to flag potential misinformation.'
- In early March, Red Ventures reputedly laid off around 50% of its news and video employees. The company insisted to Variety that the 'decision was not a reflection of the value or performance of our team members, the use of emerging technologies, or our confidence in the CNET Group's future.'
- In May 2022, approximately 100 CNET staffers announced they were unionising in response to a 'lack of transparency and accountability' from management about layoffs and the company’s use of artificial intelligence and its 'blurring of editorial and monetization strategies.'
- Operator: Red Ventures/CNET Developer: Red Ventures/CNET Country: USA; Global Sector: Media/entertainment/sports/arts Purpose: Automate copywriting Technology: Large language model (LLM); NLP/text analysis; Neural network; Deep learning Issue: Accuracy/reliability; Employment - jobs; Ethics Transparency: Governance; Marketing
- Red Ventures website
- CNET Money website
URL: https://futurism.com/the-byte/cnet-publishing-articles-by-ai
- Next time you're on your favorite news site, you might want to double check the byline to see if it was written by an actual human.
- CNET, a massively popular tech news outlet, has been quietly employing the help of "automation technology" — a stylistic euphemism for AI — on a new wave of financial explainer articles, seemingly starting around November of last year.
- In the absence of any formal announcement or coverage, it appears that this was first spotted by online marketer Gael Breton in a tweet on Wednesday.
- The articles are published under the unassuming appellation of "CNET Money Staff," and encompass topics like "Should You Break an Early CD for a Better Rate?" or "What is Zelle and How Does It Work?"
- That byline obviously does not paint the full picture, and so your average reader visiting the site likely would have no idea that what they're reading is AI-generated. It's only when you click on "CNET Money Staff," that the actual "authorship" is revealed.
- "This article was generated using automation technology," reads a dropdown description, "and thoroughly edited and fact-checked by an editor on our editorial staff."
- Since the program began, CNET has put out around 73 AI-generated articles. That's not a whole lot for a site that big, and absent an official announcement of the program, it appears leadership is trying to keep the experiment as lowkey as possible. CNET did not respond to questions about the AI-generated articles.
- Are you a current or former CNET employee who wants to discuss the company's foray into AI-generated articles? Email tips@futurism.com to share your perspective. It's okay if you don't want to be identified by name.
- Because the content seems carefully optimized for search traffic, Google's outlook on AI-generated content will likely make or break the future of the program.
- Though high-ranking Google official John Mueller said last year that AI-generated content with the primary aim of manipulating search rankings is against the company's policies, a Google spokesperson clarified to Futurism that AI-generated content isn't entirely verboten.
- "Our goal for Search is to show helpful, relevant content that’s created for people, rather than to attain search engine rankings," public liaison for Search Danny Sullivan said in a statement provided to Futurism. "Our ranking team focuses on the usefulness of content, rather than how the content is produced. This allows us to create solutions that aim to reduce all types of unhelpful content in Search, whether it’s produced by humans or through automated processes."
- In a sense, AI-generated articles are not new — there's tons littering the internet already, some as low tech as copying a human written article and swapping certain words out with synonyms to obfuscate the plagiarism.
- But AI usage is not limited to those kinds of bottom of the barrel outlets. Even the prestigious news agency The Associated Press has been using AI since 2015 to automatically write thousands and thousands of earnings reports. The AP has even proudly proclaimed itself as "one of the first news organizations to leverage artificial intelligence."
- It's worth noting, however, that the AP's auto-generated material appears to be essentially filling in blanks in predetermined formats, whereas the more sophisticated verbiage of CNET's publications suggests that it's using something more akin to OpenAI's GPT-3.
- Nonetheless, AP's justification for using AI — and a talking point being adopted across the industry — is that it frees up journalists and other staff from having to write tedious recaps. In reality, it's hard to believe that the technology would forever be limited to a cure to tedium and never intrude on "real" writing jobs.
- Now, looking at the entire explainers that CNET has generated using AI, it looks like that goalpost has already shifted — and may never return.
- Updated with comment from Google.
- More on AI: Social Media Users Alarmed by Relentless Ads for AI That Sexts With Lonely People
- DISCLAIMER(S)
- Articles may contain affiliate links which enable us to share in the revenue of any purchases made.
- Registration on or use of this site constitutes acceptance of our Terms of Service.
- © Recurrent Ventures Inc, All Rights Reserved.

URL: https://futurism.com/cnet-ai-errors
- Last week, we reported that the prominent technology news site CNET had been quietly publishing articles generated by an unspecified "AI engine."
- The news sparked outrage. Critics pointed out that the experiment felt like an attempt to eliminate work for entry-level writers, and that the accuracy of current-generation AI text generators is notoriously poor. The fact that CNET never publicly announced the program, and that the disclosure that the posts were bot-written was hidden away behind a human-sounding byline — "CNET Money Staff" — made it feel as though the outlet was trying to camouflage the provocative initiative from scrutiny.
- After the outcry, CNET editor-in-chief Connie Guglielmo acknowledged the AI-written articles in a post that celebrated CNET's reputation for "being transparent."
- Without acknowledging the criticism, Guglielmo wrote that the publication was changing the byline on its AI-generated articles from "CNET Money Staff" to simply "CNET Money," as well as making the disclosure more prominent.
- Furthermore, she promised, every story published under the program had been "reviewed, fact-checked and edited by an editor with topical expertise before we hit publish."
- That may well be the case. But we couldn't help but notice that one of the very same AI-generated articles that Guglielmo highlighted in her post makes a series of boneheaded errors that drag the concept of replacing human writers with AI down to earth.
- Take this section in the article, which is a basic explainer about compound interest (emphasis ours):
- "To calculate compound interest, use the following formula:
- Initial balance (1+ interest rate / number of compounding periods) ^ number of compoundings per period x number of periods
- For example, if you deposit $10,000 into a savings account that earns 3% interest compounding annually, you'll earn $10,300 at the end of the first year."
- It sounds authoritative, but it's wrong. In reality, of course, the person the AI is describing would earn only $300 over the first year. It's true that the total value of their principal plus their interest would total $10,300, but that's very different from earnings — the principal is money that the investor had already accumulated prior to putting it in an interest-bearing account.
- "It is simply not correct, or common practice, to say that you have 'earned' both the principal sum and the interest," Michael Dowling, an associate dean and professor of finance at Dublin College University Business School, told us of the AI-generated article.
- It's a dumb error, and one that many financially literate people would have the common sense not to take at face value. But then again, the article is written at a level so basic that it would only really be of interest to those with extremely low information about personal finance in the first place, so it seems to run the risk of providing wildly unrealistic expectations — claiming you could earn $10,300 in a year on a $10,000 investment — to the exact readers who don't know enough to be skeptical.
- Another error in the article involves the AI's description of how loans work. Here's what it wrote (again, emphasis ours):
- "With mortgages, car loans and personal loans, interest is usually calculated in simple terms.
- For example, if you take out a car loan for $25,000, and your interest rate is 4%, you'll pay a flat $1,000 in interest per year."
- Again, the AI is writing with the panache of a knowledgeable financial advisor. But as a human expert would know, it's making another ignorant mistake.
- What it's bungling this time is that the way mortgages and auto loans are typically structured, the borrower doesn't pay a flat amount of interest per year, or even per monthly payment. Instead, on each successive payment they owe interest only on the remaining balance. That means that toward the beginning of the loan, the borrower pays more interest and less principal, which gradually reverses as the payments continue.
- It's easy to illustrate the error by entering the details from the CNET AI's hypothetical scenario — a $25,000 loan with an interest rate of 4 percent — into an auto loan amortization calculator. The result? Contrary to what the AI claimed, there's never a year when the borrower will pay a full $1,000 in interest, since they start chipping away at the balance on their first payment.
- CNET's AI is "absolutely" wrong in how it described loan payments, Dowling said.
- "That's just simply not the case that it would be $1,000 per year in interest," he said, "as the loan balance is being reduced every year and you only pay interest on the outstanding balance."
- The problem with this description isn't just that it's wrong. It's that the AI is eliding an important reality about many loans: that if you pay them down faster, you end up paying less interest in the future. In other words, it's feeding terrible financial advice directly to people trying to improve their grasp of it.
- The AI made yet another gaffe when it attempted to describe certificates of deposit, better known as CDs, which are financial products that offer interest, but typically discourage withdrawing the funds before a set period has elapsed (once more, emphasis ours):
- "Note that a high-yield savings account or money market account may offer interest that compounds daily, weekly or monthly. But a one-year certificate of deposit only compounds once, after the initial deposit reaches maturity."
- This one is just straight-up false. For instance, here's a one-year CD by Chase Bank that compounds daily. And here's one by Capital One that compounds monthly.
- All three screwups, each of which the AI presented with the easy authority of an actual subject matter expert, highlight a core issue with current-generation AI text generators: while they're legitimately impressive at spitting out glib, true-sounding prose, they have a notoriously difficult time distinguishing fact from fiction.
- For an editor, that's bound to pose an issue. It's one thing to work with a writer who does their best to produce accurate work, but another entirely if they pepper their drafts with casual mistakes and embellishments. BuzzFeed News perfectly illustrated that risk this week, when a reporter there used ChatGPT to generate a story about CNET's secretive use of AI — only to find that she "had to rewrite the prompt a few times to get it to stop inserting factual errors."
- Another issue that may be at play here is well known in the separate AI-inflected field of self-driving cars. Researchers have found that human safety drivers, tasked with sitting behind the wheel of an autonomous vehicle to take over if it malfunctions, tend to quickly lose focus when they don't have to actively work the controls. The same dynamic may be at play when an editor is put in charge of approving a deluge of AI-generated explainers: in the face of endless synthetic writing, maybe it makes sense that human editors start to go on autopilot themselves.
- Everyone makes mistakes, so we're certainly sympathetic. But in these early days of CNET's AI experiment — nevermind in a piece published the same day that the site's editor went public in response to a storm of criticism — you'd expect the editors tasked with monitoring the AI to be on their highest alert.
- If these are the sorts of blunders that slip through during that period of peak scrutiny, what should we expect when there aren't so many eyes on the AI's work? And what about when copycats see that CNET is getting away with the practice and start filling the web with their own AI-generated content, with even fewer scruples?
- It's also worth asking what readers actually want: financial advice from a real human with real financial concerns, or logorrhea from a bot that's been trained to rehash existing financial writing with no financial stake of its own.
- Dowling said that while he's optimistic about the potential of AI in general, he suspects that an algorithm like CNET's lack of personal perspective or "insights that go beyond mere summary" will keep it from producing genuinely interesting work.
- "People already approach finance reading with an advance sense of boredom and reluctance — will ChatGPT just embed those negative features even deeper in finance writing?" he asked.
- After Futurism reached out to CNET about the errors, staff there issued a lengthy correction to the article and edited the text to address all three mistakes.
- Staff at CNET also seemingly identified a fourth error by the AI, which they also described in the correction, regarding the distinction between Annual Percentage Rate (APR) and Annual Percentage Yield (APY).
- A CNET spokesperson provided Futurism with a brief statement about the corrections.
- "We are actively reviewing all our AI-assisted pieces to make sure no further inaccuracies made it through the editing process, as humans make mistakes, too," they said. "We will continue to issue any necessary corrections according to CNET's correction policy."
- Are you a current or former CNET employee who wants to discuss the company's foray into AI-generated articles? Email tips@futurism.com to share your perspective. It's okay if you don't want to be identified by name.
- The spokesperson didn't respond to a question about CNET's confidence in the other articles the AI has published to its site. After we reached out, however, a new message appeared at the top of almost every piece the AI has published, dating back to November.
- "Editors' note: We are currently reviewing this story for accuracy," reads the message. "If we find errors, we will update and issue corrections."
- It's worth pointing out, as Platformer's Casey Newton did this week, that CNET's AI-generated finance articles arguably only exist in the first place because they're trying to manipulate Google's algorithm for profit. Countless better explanations of compound interest already exist; CNET's strategy is simply to publish large volumes of cheaply produced text, carefully optimized to float to the top of search results, in a bid to capture the monetizable eyeballs of the financially curious.
- "Over time, we should expect more consumer websites to feature this kind of 'gray' material: good-enough AI writing, lightly reviewed (but not always) by human editors, will take over as much of digital publishing as readers will tolerate," Newton wrote. "The quiet spread of AI kudzu vines across CNET is a grim development for journalism, as more of the work once reserved for entry-level writers building their resumes is swiftly automated away."
- In other words, it's not just AI that's the issue here. It's that AI is maturing at a moment when the journalism industry has already been hollowed out by a decades-long race to the bottom — a perfect storm for media bosses eager to cut funding for human writers.
- Frank Landymore contributed reporting to this story.
- More on CNET: CNET Is Quietly Publishing Entire Articles Generated by AI
- DISCLAIMER(S)
- Articles may contain affiliate links which enable us to share in the revenue of any purchases made.
- Registration on or use of this site constitutes acceptance of our Terms of Service.
- © Recurrent Ventures Inc, All Rights Reserved.

URL: https://futurism.com/cnet-ai-plagiarism
- The prominent tech news site CNET's attempt to pass off AI-written work keeps getting worse. First, the site was caught quietly publishing the machine learning-generated stories in the first place. Then the AI-generated content was found to be riddled with factual errors. Now, CNET's AI also appears to have been a serial plagiarist — of actual humans' work.
- The site initially addressed widespread backlash to the bot-written articles by assuring readers that a human editor was carefully fact-checking them all prior to publication.
- Afterward, though, Futurism found that a substantial number of errors had been slipping into the AI's published work. CNET, a titan of tech journalism that sold for $1.8 billion back in 2008, responded by issuing a formidable correction and slapping a warning on all the bot's prior work, alerting readers that the posts' content was under factual review. Days later, its parent company Red Ventures announced in a series of internal meetings that it was temporarily pausing the AI-generated articles at CNET and various other properties including Bankrate, at least until the storm of negative press died down.
- Now, a fresh development may make efforts to spin the program back up even more controversial for the embattled newsroom. In addition to those factual errors, a new Futurism investigation found extensive evidence that the CNET AI's work has demonstrated deep structural and phrasing similarities to articles previously published elsewhere, without giving credit. In other words, it looks like the bot directly plagiarized the work of Red Ventures competitors, as well as human writers at Bankrate and even CNET itself.
- Jeff Schatten, a professor at Washington and Lee University who has been examining the rise of AI-enabled misconduct, reviewed numerous examples of the bot's apparent cribbing that we provided. He found that they "clearly" rose to the level of plagiarism.
- We asked Schatten what would happen if a student turned in an essay with a comparable number of similarities to existing documents with no attribution.
- "They would be sent to the student-run ethics council and given the repeated nature of the behavior would almost certainly be expelled from the university," he replied.
- The bot's misbehavior ranges from verbatim copying to moderate edits to significant rephrasings, all without properly crediting the original. In at least some of its articles, it appears that virtually every sentence maps directly onto something previously published elsewhere.
- Take this excerpt, for instance, from a recent article by the CNET AI about overdraft protection:
- How to avoid overdraft and NSF fees
- Overdraft fees and NSF fees don't have to be a common consequence. There are a few steps you can take to avoid them.
- And compare it to this verbiage from a previously published article in Forbes Advisor, a Red Ventures competitor:
- How to Avoid Overdraft and NSF Fees
- Overdraft and NSF fees need not be the norm. There are several tools at your disposal to avoid them.
- Sure, the bot's version altered the capitalization and swapped out a few words for impressively lateral-minded synonyms — "the norm" becomes "a common consequence," for instance, and "several tools" becomes "a few steps" — along with a few minor changes to the syntax. But apart from those semantic tweaks, the two sentences are nearly identical.
- Here's another excerpt from the same article by CNET's AI financial writer:
- Sign up for low-balance alerts
- You may be able to receive low balance alerts from your bank's mobile app, so you know if your account balance is dropping below a certain threshold.
- Now compare it to this section from another previously published article, this one from The Balance, another Red Ventures competitor:
- Sign Up for Low Balance Alerts
- You can sign up for low-balance alerts through most banks to alert you when your account hits a certain amount.
- Again, it seems clear that the AI is simply parsing through and making small modifications to obscure the source.
- Sometimes the similarities are almost comical in their lack of subtlety. Take the first sentence of this article, also published by CNET's AI:
- Gift cards are an easy go-to when buying a present for someone.
- And compare it to the first sentence of this previously published Forbes article:
- Gift cards are an easy-to-please present for just about anyone.
- The kicker on that one? Check out the almost imperceptible difference between those two articles' headlines. Here's the CNET AI's title:
- Can You Buy a Gift Card With a Credit Card?
- And here's what Forbes ran with for a headline:
- Can You Buy Gift Cards With a Credit Card?
- That's right: the only difference is switching "Gift Cards" to a singular.
- Here's another example, from the same AI-generated CNET article about overdraft fees:
- What is overdraft protection?
- Overdraft protection is an optional feature offered by banks to prevent the rejection of a charge on a checking account with insufficient funds.
- Which, it turns out, appears to be a word salad rephrasing of a line from this article on Investopedia, another Red Ventures competitor.
- What Is Overdraft Protection?
- Overdraft protection is an optional service that prevents the rejection of charges to a bank account... that are in excess of the available funds in the account.
- The AI appears to sometimes also borrow language from writers at CNET's sister site Bankrate without giving credit. For example, look at this line from an article published by CNET's AI back in November:
- Becoming an authorized user can help you avoid applying for a card on your own, which is a major benefit if you currently have bad credit or no credit history.
- And compare it to this wording, previously published by a Bankrate writer:
- Becoming an authorized user also lets you avoid having to apply for a card on your own, which is a major benefit if you currently have bad credit or no credit history at all.
- All told, a pattern quickly emerges. Essentially, CNET's AI seems to approach a topic by examining similar articles that have already been published and ripping sentences out of them. As it goes, it makes adjustments — sometimes minor, sometimes major — to the original sentence's syntax, word choice, and structure. Sometimes it mashes two sentences together, or breaks one apart, or assembles chunks into new Frankensentences. Then it seems to repeat the process until it's cooked up an entire article.
- A current Red Ventures employee also reviewed examples of the bot's seemingly lifted work.
- "You ever copy your homework off of somebody," they quipped, "but they told you to kind of rephrase it?"
- "It poses the question of what kind of institutions do CNET and Bankrate want to be seen as," they continued. "They're just taking these articles and rephrasing a couple of things."
- Are you a current or former Red Ventures employee and want to share your thoughts about the company's use of AI? Email us at tips@futurism.com. We can keep you anonymous.
- In short, a close examination of the work produced by CNET's AI makes it seem less like a sophisticated text generator and more like an automated plagiarism machine, casually pumping out pilfered work that would get a human journalist fired.
- Perhaps, at the end of the day, none of this should be terribly surprising. At their core, the way that machine learning systems work is that you feed in an immense pile of "training data," process it with sophisticated algorithms, and end up with a model that can produce similar work on demand.
- Investigators have sometimes found examples of AI plagiarizing its own training data. In 2021, for instance, researchers from Johns Hopkins University, New York University and Microsoft found that text-generating AIs "sometimes copy substantially, in some cases duplicating passages over 1,000 words long from the training set."
- As such, the question of exactly how CNET's disastrous AI was trained may end up taking center stage as the drama continues to unfold. At a CNET company meeting late last week, The Verge reported at the time, the outlet's executive vice president of content and audience refused to tell staff — many of them acclaimed tech journalists who have written extensively about the rise of machine learning — what data had been used to train the AI.
- The legality of using data to train an AI without the consent of the people who created that data is currently being tested by several lawsuits against the makers of prominent image generators, and could become a flashpoint in the commercialization of the tech.
- "If a student presented the equivalent of what CNET has produced for an assignment in my class, and if they did not cite their sources, then I would definitely count it as plagiarism," said Antony Aumann, a philosophy professor at Northern Michigan University who recently made headlines when he discovered that one of his own students had submitted an essay generated using ChatGPT, after reviewing examples of the CNET AI's similar phrasing to other outlets.
- "Now, there is some dispute among academics about exactly what plagiarism is," he continued. "Some scholars consider it a form of stealing; other scholars regard it as a kind of lying. I think of it in the latter way. Plagiarism involves representing something as your own that is in fact not your own. And that appears to be what CNET is doing."
- CNET did not respond to examples of the bot's seemingly cribbed writing, nor to questions about this story.
- In a sense, the relentless ineptitude of the company's braindead AI probably obfuscates many of the thornier themes we're likely to see emerge as the tech continues to spread into the workplace and information ecosystems.
- Schatten, for instance, warned that issues around AI and intellectual property are likely to get more ambiguous and difficult to detect as AI systems continue to improve, or even as publishers start to experiment with more advanced systems that already exist (Red Ventures has declined to say what AI it's using, though the editor-in-chief of CNET has said that it's not ChatGPT.)
- "The CNET example is noteworthy because whatever AI they were using was not drawing from the entirety of the internet and carefully coming up with a new mosaic, but rather just lifting more or less word for word from existing stories," Schatten said. "But the more sophisticated AIs of today, and certainly the AIs of the future, will do a better job of hiding the origins of the material."
- "And especially once AIs are drawing from the writing of other AIs, which themselves are quoting AI (dark, I know) it might become quite difficult to detect," he added.
- In a practical sense, it seems increasingly obvious that CNET and Red Ventures deployed the AI system and started blasting its articles out to the site's colossal audience without ever really scrutinizing its output. It wasn't just that the architects of the program missed obvious factual errors, but that they appear never to have checked whether the system's work might have been poached.
- And to be fair, why would they? As The Verge reported in a fascinating deep dive last week, the company's primary strategy is to post massive quantities of content, carefully engineered to rank highly in Google, and loaded with lucrative affiliate links.
- For Red Ventures, The Verge found, those priorities have transformed the once-venerable CNET into an "AI-powered SEO money machine."
- More on CNET: SEO Spammers Are Absolutely Thrilled Google Isn't Cracking Down on CNET's AI-Generated Articles
- DISCLAIMER(S)
- Articles may contain affiliate links which enable us to share in the revenue of any purchases made.
- Registration on or use of this site constitutes acceptance of our Terms of Service.
- © Recurrent Ventures Inc, All Rights Reserved.

URL: https://futurism.com/cnet-bankrate-pausing-ai-generated-content-backlash
- Last week, it emerged that CNET and its sister site Bankrate had been publishing AI-generated financial explainers.
- The program's lack of a formal announcement — as well as the shoddy quality of the articles it generated and the general sense that it was a pilot program to put entry-level writers out of work — produced outrage.
- Now, after a bruising week of headlines, CNET and Bankrate's owner, Red Ventures, said in a series of internal meetings that it was pausing the AI-generated articles at both outlets, as well as other sites in the company's extensive portfolio.
- But not for long. Company leaders said that after the negative press coverage lets up, they'll be starting the program back up.
- "I just want to reassure everybody: this will pass," CNET’s executive vice president of content and audience Lindsey Turrentine at one of the meetings, according to The Verge. "It’s uncomfortable, we will get through it, the news cycle will move on."
- Turrentine, you may recall, was very concerned about the ethics of journalism back in 2013, when CNET's owner at the time gave the site orders that staff considered unethical.
- "I could have quit right then," she wrote. "Maybe I should have. I decided that the best thing for my team was to get through the day as best we could and to fight the fight from the other side."
- While Red Ventures licks its wounds, company leaders say they'll be conducting an audit of the AI's work and figuring out new ways for editors to catch the bot's multitudinous errors.
- The sense that the company was more concerned with negative press than the quality of its work didn't sit well with employees in attendance.
- "They can say all they want about how this will supplement our jobs, but at the end of the day, we are scared this is going to replace us," they added. "What can we do? Threaten to walk out? They have an algorithm to take our spot."
- Are you a current or former CNET employee who wants to discuss the company's foray into AI-generated articles? Email tips@futurism.com to share your perspective. It's okay if you don't want to be identified by name.
- If Red Ventures leadership sound rattled by the bad press, it's probably because the story of the company's descent into AI-generated content made some serious rounds this week after Futurism's initial report.
- "A news site used AI to write articles," thundered the Washington Post. "It was a journalistic disaster."
- The Verge conducted its own investigation into "CNET’s AI-powered SEO money machine" in the wake of our coverage, with one former employee telling the site that staff at CNET are "more afraid of Red Ventures than they are of AI."
- The story, which was the first example of a high profile publisher getting caught using current-generation AI text generation tools to churn out automated content, also picked up coverage in the New York Times, Vice, Gizmodo, Politico, Slate, Insider, Pew Research, Digiday, and many other outlets.
- But Red Ventures leadership says not to worry — all those publications will stop paying attention soon enough, at which point it can spin the program back up again.
- More on AI: SEO Spammers Are Absolutely Thrilled Google Isn't Cracking Down on CNET's AI-Generated Articles
- DISCLAIMER(S)
- Articles may contain affiliate links which enable us to share in the revenue of any purchases made.
- Registration on or use of this site constitutes acceptance of our Terms of Service.
- © Recurrent Ventures Inc, All Rights Reserved.

URL: https://futurism.com/cnet-bankrate-restarts-ai-articles
- By now, you might've heard about stalwart tech publisher CNET and its parent company Red Ventures, which surreptitiously published AI-written articles for months without telling readers — before they were caught. After we reported that the bot's work was found to be full of errors and plagiarism, Red Ventures announced a pause on the bot-written explainers at CNET as well as its sister sites Bankrate and CreditCards.com (at least until the negative press died down).
- Yet now, barely a week later, it looks like CNET's parent company is up to its old tricks. And once again, the bot's work was so flawed that the company pulled it down after we reached out with questions.
- Since the pause, the AI writer's byline at CNET and CreditCards.com has remained dormant. But Bankrate never quite stopped after the January 20 suspension, with two more AI-generated articles trickling out in the days following the announcement. And today, Bankrate published yet another AI-generated article.
- When we saw it, we were intrigued: Surely, if the pause was already over, Bankrate editors would have scrutinized the story to an extraordinary degree to make sure it was free of mistakes, after the near-universal condemnation of the bot's previous error-plagued work.
- As it turns out, nope. This new one had an idiotic mistake in the very second sentence (emphasis ours):
- There are many different types of mortgages to suit a variety of budgets and financial situations. Among the options is a 5/1 ARM, which is a 30-year mortgage with a fixed rate for five years followed by periodic rate adjustments.
- Wrong. While a 5/1 ARM (adjustable rate mortgage) is a real thing — more on that in a moment — they're offered at a variety of term lengths ranging much lower than 30 years.
- The bigger issue, though, is that the AI-generated article offered this staggeringly irresponsible "pro" of the loans:
- The obvious benefit of a 5/1 ARM is more affordable monthly payments compared with a 30-year fixed mortgage. Interest rates for ARMs in can be a full percentage point lower than comparable 30-year fixed loans.
- Beyond the word salad — "ARMs in can be" — this is a textbook example of how cutting-edge AI frequently functions as a "bullshit generator," in the words of Princeton computer science professor Arvind Narayanan.
- Typos aside, what's crucially at stake here is what the article doesn't say about this type of mortgage. The "5/1" means, essentially, that borrowers get a temptingly low interest rate for the first five years, which is then adjusted — usually jacked up — every year after that. In other words, the issuer gives you a good deal for a little while, and then an increasingly bad deal for a very long time — 25 years, in fact, in the fertile imagination of the company's witless AI system.
- After we asked Red Ventures some questions about the AI-written article, it quickly disappeared from the bot's profile, along with the other two that Bankrate had published since the pause. It didn't respond to any of our questions.
- If this sounds to you like a thinly-veiled attempt to imprison low-information prospective homeowners in crushing debt, you're not alone. Duke University's interdisciplinary American Predatory Lending and the Global Financial Crisis team found that ARMs were "one of many contributing factors to the housing bubble that set the stage for the 2008 financial crisis."
- "They didn’t understand how the documents worked, they didn’t understand how the loans worked," North Carolina Justice Center director Al Ripley told a Duke researcher of homeowners who took on ARMs, "and they were losing their homes because of it."
- The point of Bankrate's article, if it had been written in the service of a financially curious reader, would be to express that these types of mortgages are a good deal for five years, and very likely a terrible deal after that. Did it? Absolutely not. Instead, it makes these terrible loans sound like a great idea.
- If anything, this next "pro" listed by the AI is even worse:
- More house: The lower payment allows you to take on a bigger mortgage and get a larger or better-located house.
- "More house," it says. And while trivially true, it's horrible financial advice for... almost everyone. Yes, this type of predatory loan could allow borrowers to lock down a lower payment for a few years, but they'll end up paying vastly more over the total lifetime of the loan — a point never explicitly addressed anywhere in the article, though it does point readers to affiliate links where they can get mortgages of their own — sending Red Ventures a healthy financial kickback, of course.
- Are you a Bankrate employee? If you know anything about this AI, feel free to email us at tips@futurism.com. We can keep you anonymous.
- Believe it or not, this mess actually gets worse.  The issue isn't just that the company is just letting its dumb-as-rocks AI publish new articles; it's also using similar similar tech to rewrite existing articles, with the aim of fooling search engines into flagging the material as recently updated, a signal that can prompt a company like Google to treat it favorably in its search results.
- But the articles didn't disappear entirely, which appears to be a perfect illustration of how Red Ventures' sites are using AI tech to juke Google's search algorithm.
- "They use AI to rewrite the intros every two weeks or so because Google likes updated content," a former CNET employee told us in a previous story. "Eventually it gets so mangled that about every four months a real editor has to look at it and rewrite it."
- That practice appears to be on full display in today's article. That's because Bankrate didn't fully delete it, instead opting to roll it back to a previous version, also bylined by the AI. In other words, it seems like Bankrate is basically using the AI like a blender to substantially reword sentences for artificial search engine clout.
- In fact, using the AI as an automated rewriting machine appears to be exactly what caused today's mistake. Here's what the article said prior to today's changes:
- A 5/1 ARM is a common type of 30-year adjustable-rate mortgage; this is a loan that adjusts its rate periodically.
- This isn't the most artful description imaginable, but it actually was correct before the AI butchered it — a 5/1 ARM is indeed a subset of available types of 30-year adjustable-rate mortgages. But the AI scrambled it so heavily that it actually inserted an error, as we explained above, by heavily rewriting the syntax in today's version:
- There are many different types of mortgages to suit a variety of budgets and financial situations. Among the options is a 5/1 ARM, which is a 30-year mortgage with a fixed rate for five years followed by periodic rate adjustments.
- Even more interestingly, the first backed-up version of the article available on the Internet Archive shows that originally, it had a human byline. Oddly, the AI doesn't appear to have made a single change to the article before adding its byline sometime in 2022. The Bankrate journalist whose name was originally on the article didn't reply to a request for comment.
- If you think about it, what's on display here is fairly astonishing even by the abysmal standards that Red Ventures' use of AI has set so far.
- It's not just that the AI is publishing error-ridden and plagiaristic search engine bait aimed at pushing low-information readers toward credit cards and loans. It's that the AI also appears to be chewing through previously published content, stealing human bylines, and slowly zombifying their work into decaying misinformation machines.
- Is that the future anyone wants for journalism? Most likely not — but it is the one that Red Ventures has pledged to restart, as soon as the public stops paying attention.
- More on AI: Startup Shocked When 4Chan Immediately Abuses Its Voice-Cloning AI
- DISCLAIMER(S)
- Articles may contain affiliate links which enable us to share in the revenue of any purchases made.
- Registration on or use of this site constitutes acceptance of our Terms of Service.
- © Recurrent Ventures Inc, All Rights Reserved.

URL: https://gizmodo.com/cnet-chatgpt-ai-articles-publish-for-months-1849976921
- CNET reporter Jackson Ryan published an article last month describing how ChatGPT, an AI that can generate human-sounding text, would affect journalists and the news industry: “ChatGPT Is a Stunning AI, but Human Jobs Are Safe (for Now).”
- “It definitely can’t do the job of a journalist,” Ryan wrote of ChatGPT. “To say so diminishes the act of journalism itself.”
- The article said ChatGPT isn’t coming for journalists’ jobs just yet, but the very publication that ran Ryan’s article has been quietly publishing articles written by AI since November, according to Futurism and online marketer Gael Breton. The AI-written CNET articles bear the byline CNET Money Staff which is identified on the outlet’s website as “AI Content published under this author byline is generated using automation technology.”
- CNET responded in a linked statement via email, saying the Money editorial team was trying out the technology “to see if there’s a pragmatic use case for an AI assist on basic explainers around financial services topics.”
- CNET’s Editor in Chief, Connie Guglielmo, said in the statement that the company’s goal had been if the AI engine would be able to assist their “busy staff of reporters and editors with their job to cover topics from a 360-degree perspective.”
- The company questioned if CNET would benefit from AI content to provide available facts, allowing readers to “make better decisions.”
- The first article written by CNET Money Staff was published on November 11 with the headline, “What is a credit card charge-off?”  Since then, the news site has published 73 AI-generated articles, but the outlet says on its website that a team of editors is involved in the content “from ideation to publication. Ensuring that the information we publish and the recommendations we make are accurate, credible, and helpful to you is a defining responsibility for what we do.”
- The outlet says they will continue to publish each article with “editorial integrity” and says, “Accuracy, independence, and authority remain key principles of our editorial guidelines.”
- The most recent versions of consumer-facing artificial intelligence have taken the tech community by storm with their ability to write passable essays, articles, and computer code in seconds, though the quality varies, and ChatGPT has been banned from several high-profile forums. CNET is not the first news outlet to utilize AI technology, as the Associated Press has boasted of being “one of the first news organizations to leverage artificial intelligence,” since 2015, according to its website. “Today, we use machine learning along key points in our value chain, including gathering, producing, and distributing the news,” the site reads. It’s not clear whether the AP uses AI to write the stories themselves.
- Other major news outlets have incorporated AI technology into their work,with the Washington Post announcing it was using AI to provide live updates for the 2020 Presidential election on its podcasts. The goal, the outlet said, was to keep listeners up-to-date during the steady stream of election-based news that would be coming out.
- The question of whether AI is supplanting jobs is yet to be answered. Ryan wrote that ChatGPT’s inability to understand or read emotion makes it useless in the context of journalism. ChatGPT, he says, doesn’t have the ability to describe the feelings seen on a player’s face when they win the World Cup, or talk to Ukrainians about how the Russian Invasion has changed their lives, and would definitely have “no hope of covering Musk’s takeover of Twitter.”
- Guglielmo said in her statement that CNET will “continue to assess these new tools to determine if they’re right for our business.” She added, “For now CNET is doing what we do best – testing a new technology so we can separate the hype from reality.”

URL: https://www.yahoo.com/entertainment/cnet-removes-word-staff-bylines-231609927.html
- CNET on Wednesday slightly modified its byline on certain articles generated via artificial intelligence (AI) software to remove the word “staff,” spurred by a recent report that wrestles with the degree of human editor involvement – and what “staff” even means.
- CNET had published AI-generated explainer articles bylined as “CNET Money Staff” but has since changed those to “CNET Money.”
- An article posted on the Recurrent Ventures-owned Futurism website says CNET began the experiment around last November. The story says CNET’s “automation technology” definition is “a stylistic euphemism for AI.”
- The “CNET Money Staff” has generated more than 70 AI-generated financial articles to date, with such titles such as “Should You Break an Early CD for a Better Rate?”
- Also Read: Ryan Reynolds Experiments with ‘Mildly Terrifying’ ChatGPT to Script a Mint Mobile TV Ad (Video)
- Futurism points out the byline “staff” is misleading because human editor involvement is minimal and, “It’s only when you click on ‘CNET Money Staff,’ that the actual ‘authorship’ is revealed via a disclosure.”
- Although CNET was unavailable to comment, Futurism reported a marketer’s tweet suggested some of the articles are highly trafficked despite Google’s warnings last year discouraging AI-made content.
- AI-assisted content is being incorporated into content production with some online ‘low tech’ publishers even taking a human-produced article and replacing words to mask plagiarism.
- Meanwhile, the wire service The Associated Press has touted using AI since 2015, and uses it to generate earnings reports and sports recaps; however, the AP’s automated content is more basic and based on fill-in-the-blanks than CNET’s publications. Futurism speculates that CNET is deploying OpenAI’s GPT-3.
- CNET rebranded in April 2022, unveiling a “new identity and site design, among other design evolutions and content features that accelerate the brand in its continued expansion beyond tech.”
- The former president has a long history of making offensive and insulting comments about military members, despite never serving himself.
- Rachel Campos-Duffy didn't let the former first lady's repeated comments get in the way of her forecast.
- Scott Strader owns the Lotus beverage brand.
- Evgenia Novozhenina/ReutersU.S. Senator Lindsey Graham’s recent comments during his Friday meeting with the President of Ukraine Volodymyr Zelensky in the war-torn country caused outrage and fury in Moscow, with the head of RT Margarita Simonyan calling for his assassination.In a video clip of the meeting, Graham’s comments were spliced in a way that made it seem that the Senator stated that the fact that Russians “are dying” in the invasion is “the best money we’ve ever spent.” In fact, Graham
- After determining the crash was intentional, NASCAR suspended Bubba Wallace for a similar move last season.
- A sign with a homophobic slur on Memorial Day outside of Rick's Repair Shop in Tallahassee, Florida is causing controversy on social media.
- It’s a story made for a Hollywood film, and in some ways, it already is.
- My granddaughter lives with her partner overseas. My daughter and I visited last summer, and we all went out for a very jolly dinner. When the bill came, I asked the partner if we should split it, with me getting the wine.
- Snorlax / MEGA Blended family! Jennifer Garner took daughter Seraphina and Jennifer Lopez’s child Emme to the happiest place on earth. The 51-year-old actress was all smiles with the teens at Disneyland on Sunday, May 28. Garner, Seraphina, 14, and Emme, 15, were spotted enjoying multiple rides, waving their hands in the air and screaming.
- Symptoms of human metapneumovirus, or HMPV, include cough, fever, nasal congestion, and shortness of breath.

URL: https://news.yahoo.com/cnet-gets-caught-playing-ai-mad-libs-with-its-financial-news-coverage-001026432.html
- With the rapid evolution of AI chatbot systems like Chat-GPT, VALL-E, and BlenderBot 3 and their growing abilities to generate text on par with human writers, robots coming to take your writing job is becoming a viable threat. Over at CNET, it's apparently already happening.
- On Wednesday, The Byte reported that the popular tech site appears to have employed "automation technology" to produce a series of financial explainer posts beginning in November 2022 under the byline of CNET Money Staff. It is only after clicking the byline that the site reveals that "This article was generated using automation technology and thoroughly edited and fact-checked by an editor on our editorial staff."
- Looks like @CNET (DR 92 tech site) just did their coming out about using AI content for SEO articles. pic.twitter.com/CR0IkgUUnq
- — Gael Breton (@GaelBreton) January 11, 2023
- Online marketer Gael Breton first flagged the content Wednesday on Twitter. In all, the tech site produced 73 such posts since last November on subjects such as "Should You Break an Early CD for a Better Rate?" or "What is Zelle and How Does It Work?" Since news of its activities broke at the start of the day, CNET has subsequently taken down the CNET Money Staff bio page as well as removed the "Staff" from numerous posts it had written.
- Using text generators isn't currently a widespread practice throughout the journalistic sphere but outlets like the Associated Press and Washington Post have used them for various low-level copywriting tasks — the latter employing them to write about high school football and the equally unimportant 2016 Rio Olympics. But normally when an outlet makes a fundamental shift to the operations of its newsroom such as this, they typically send out a press release or make an announcement on social, anything. It does not appear that CNET has made any sort public note that this program exists beyond the dropdown explainer window.
- The quality difference between CNET's system and the AP's is a stark one. The AP system is a glorified mail merge, shoving specific pieces of data into preformatted story blanks for daily blotter posts and other highly repetitive journalistic tasks. CNET's system, on the other hand, appears to be far more capable, able to compose feature length explainer posts on complex financial concepts — a far cry from the journalistic Mad Libs the AP engages in. We've reached out to CNET for comment and will update the post when the company responds.
- Update (01/13/2023): CNET has responded to our request for comment with a link to a post by the site's Editor-in-Chief, Connie Gugliemo, regarding the subject.

URL: https://screenrant.com/cnet-money-published-ai-generated-articles/
- Popular online tech news outlet CNET has published over six dozen articles generated by an AI engine, raising questions about the road ahead.
- 2023 is the year that AI really comes for creative human jobs like writing and drawing, or so claim the tech evangelists, but popular consumer tech website CNET has already pushed over six dozen AI-written articles covering finance without even announcing the shift. In 2022, AI-based image generation models exploded in popularity, but it was OpenAI that really sparked the chatter with ChatGPT, a conversational chatbot that is a little too good at writing. From academic essays and romantic tales, to code and rap songs, ChatGPT will do it all. Some have even used it to write a children’s book.
- CNET, a media conglomerate owned by Red Ventures and known for its tech coverage, has actually taken a quiet "lead" in content generation using AI. Online marketing expert Gael Breton was the first to spot it when he came across a Google Search description for one of CNET’s articles claiming it was “generated using automation technology.” The warning message further added that it was “thoroughly edited and fact-checked by an editor.” These AI-generated finance articles were published under the CNET Money byline.
- RELATED: Microsoft's VALL-E AI Can Imitate Your Voice Using A 3-Second Audio Sample
- What is worrying, however, is the fact that nowhere in the article it is explicitly disclosed that those words of financial advice were generated using an AI. It is only when (and if) the reader taps on the CNET Money byline text that they see a drop-down, noting that CNET Money is just an alias for an AI engine, and not some unnamed staffer on the CNET editorial team. So far, CNET has published 73 articles using an undisclosed AI engine, starting in November 2022, with the most recent story coming out on Jan. 9, 2023.
- While some of the articles are basic step-by-step guides, a few of them answer nuanced questions such as “Should you break a CD early for a better rate” and “Does Experian boost your credit score?” One would ideally want to get such counsel from an expert, preferably a human, instead of an AI-generated article that merely scraped the web for relevant content elsewhere. CNET is yet to release an official statement regarding the deployment of an AI engine to dole out financial advice. Skirting the ethical debate here, the more important question is how it challenges the internet search guidelines and whether it will have a real impact on a human journalist’s job.
- As spotted by Search Engine Journal, Google clearly sees AI-generated content as spam because it violates the search webmaster guidelines, and its search team is authorized to take action against such content. Unfortunately, Google lacks the technical tools to detect AI-generated content in search results. There are, however, third-party options out there such as GPT-2 Output Detector, GLTR, and GPT Zero to sniff out AI-generated words. These are not foolproof, by the way. If implemented at scale, the false positives generated by these tools could have serious repercussions for the career and livelihoods of actual people.
- So the question now is, should AI be banned from the writing job market? That’s debatable. Folks are using it to write rough first drafts when their creative juices are not flowing, find hot keywords to generate content, gather reader sentiments more efficiently, and deploy it for SEO optimization. Markets and Markets says AI’s usage in social media marketing and related activities will cross the $2 billion mark in 2023. But can AI replace journalists? Business Insider tried to find out the answer with ChatGPT, and despite the factual errors, the answer is bad news. While CNET claims to have used a (human) editor to fact-check the AI-written articles on its website, it might be only a matter of time before AI comes for creative jobs.
- MORE: AI Streamer Designed To Be Edgy Starts Promoting Holocaust Denial
- Source: Gael Breton/Twitter, CNET, Search Engine Journal, Markets and Markets, Business Insider
- Nadeem has been writing about consumer technology for over three years now, having worked with names such as NDTV and Pocketnow in the past. Aside from covering the latest news, he also has experience testing out the latest phones and laptops. When he's not writing, you can find him failing at Doom eternal.

URL: https://www.vice.com/en/article/bvmep3/cnet-defends-use-of-ai-blogger-after-embarrassing-163-word-correction-humans-make-mistakes-too
- The tech-focused journalism outfit CNET is dealing with the unfortunate consequences of leaning on artificial intelligence too heavily. An article written by an “AI engine” explaining compound interest now includes an addendum at the bottom that lists five errors contained within the original post:
- Correction, 1:55 p.m. PT Jan. 16: An earlier version of this article suggested a saver would earn $10,300 after a year by depositing $10,000 into a savings account that earns 3% interest compounding annually. The article has been corrected to clarify that the saver would earn $300 on top of their $10,000 principal amount. A similar correction was made to the subsequent example, where the article was corrected to clarify that the saver would earn $304.53 on top of their $10,000 principal amount. The earlier version also incorrectly stated that one-year CDs only compound annually. The earlier version also incorrectly stated how much a consumer would pay monthly on a car loan with an interest rate of 4% over five years. The earlier version also incorrectly stated that a savings account with a slightly lower APR, but compounds more frequently, may be a better choice than an account with a slightly higher APY that compounds less frequently. In that example, APY has been corrected to APR.
- CNET began generating explainers using artificial intelligence to generate explainers for the site  in November, the company’s editor-in-chief said on Monday. (Given that the purpose of such stories is essentially to make a play for search-engine traffic, you could fairly describe the whole scheme as assigning robots to write stories for other robots to read.) But the decision didn’t generate much notice until last week, when Frank Landymore at Futurism wrote a story noting that the company had “quietly” instituted the practice. The story gained significant traction online and led to questions about the future role of artificial intelligence in journalism and whether it was too early to lean so heavily on the technology.
- Is your company using artificial intelligence in questionable ways? We want to hear from you. We want to hear from you. From a non-work device, contact our reporter at maxwell.strachan@vice.com or via Signal at 310-614-3752 for extra security.
- CNET editor-in-chief Connie Guglielmo addressed the concerns on Monday in a post in which she described the use of AI to write “basic explainers” as an “experiment” in line with CNET’s history of “testing new technologies  and separating the hype from reality.” She hoped the shift would free up staff to focus their time and energy on creating “even more deeply researched stories, analyses, features, testing and advice work we're known for.”
- In the post, Guglielmo said that each AI-generated article was reviewed by a human editor before publication. In an attempt to make that process more transparent, she said, CNET had altered the bylines on the AI-generated articles to make clear a robot wrote them, as well as clearly list the editor who reviewed the copy, and would continue to review AI’s place on the site.
- Less than an hour after Guglielmo’s post went live, CNET updated the compound interest explainer with a 167-word correction, fixing errors so elementary that a distracted teenager could catch them, like the incorrect idea that someone who puts $10,000 in a savings account that earns compound interest at a 3 percent annual rate would earn $10,300 the first year. Other articles produced by the AI engine also now include a note at the top that reads: “Editors' note: We are currently reviewing this story for accuracy. If we find errors, we will update and issue corrections.”
- Motherboard reached out to CNET to ask whether the site would further alter its approach to AI-created journalism moving forward considering the correction. In a statement sent through a generic press email account with no human name attached, the site seemed to throw the editor assigned to the story under the bus, saying they “are actively reviewing all our AI-assisted pieces to make sure no further inaccuracies made it through the editing process, as humans make mistakes, too.” Several humans have definitely made mistakes here, but the one tasked with the miserable job of babysitting the robot is probably least among them.

URL: https://www.thewrap.com/cnet-removes-staff-byline-ai-generated-stories/amp/
- CNET on Wednesday slightly modified its byline on certain articles generated via artificial intelligence (AI) software to remove the word “staff,” spurred by a recent report that wrestles with the degree of human editor involvement – and what “staff” even means.
- CNET had published AI-generated explainer articles bylined as “CNET Money Staff” but has since changed those to “CNET Money.”
- An article posted on the Recurrent Ventures-owned Futurism website says CNET began the experiment around last November. The story says CNET’s “automation technology” definition is “a stylistic euphemism for AI.”
- The “CNET Money Staff” has generated more than 70 AI-generated financial articles to date, with such titles such as “Should You Break an Early CD for a Better Rate?”
- Futurism points out the byline “staff” is misleading because human editor involvement is minimal and, “It’s only when you click on ‘CNET Money Staff,’ that the actual ‘authorship’ is revealed via a disclosure.”
- Although CNET was unavailable to comment, Futurism reported a marketer’s tweet suggested some of the articles are highly trafficked despite Google’s warnings last year discouraging AI-made content.
- AI-assisted content is being incorporated into content production with some online ‘low tech’ publishers even taking a human-produced article and replacing words to mask plagiarism.
- Meanwhile, the wire service The Associated Press has touted using AI since 2015, and uses it to generate earnings reports and sports recaps; however, the AP’s automated content is more basic and based on fill-in-the-blanks than CNET’s publications. Futurism speculates that CNET is deploying OpenAI’s GPT-3.
- CNET rebranded in April 2022, unveiling a “new identity and site design, among other design evolutions and content features that accelerate the brand in its continued expansion beyond tech.”

URL: https://www.iflscience.com/cnet-has-been-using-ai-to-write-articles-for-months-and-no-one-realised-67057
- Advertisement
- Sign up today to get weekly science coverage direct to your inbox
- © 2023 IFLScience.  All Rights Reserved
- Sign up today to get weekly science coverage direct to your inbox
- © 2023 IFLScience.  All Rights Reserved
- More
- Newsletters in your inbox!
- Subscribe today for our Weekly Newsletter in your inbox!
- Jack Dunhill
- Jack Dunhill
- Social Media Coordinator and Staff Writer
- Jack is a Social Media Coordinator and Staff Writer for IFLScience, with a degree in Medical Genetics specializing in Immunology.
- BookView full profile
- BookRead IFLScience Editorial Policy
- Social Media Coordinator and Staff Writer
- The articles are seriously good, and it's been happening since November. Image Credit: kung_tom/Shutterstock.com
- If you haven’t tried it yet, go and test out OpenAI’s ChatGPT – it's scarily good at writing. It will write a semi-original article (the information will be taken from internet sources but it passes plagiarism checkers just fine), cite sources within the text, and the grammar is almost spot on. The AI is so good, in fact, that CNET has been publishing entire articles written by AI on their platform for months.
- Starting around November 2022, tech and news outlet CNET has been employing “automation technology” to write financial explainer articles, with a small little dropdown note explaining that a human did not write the content. While CNET is not exactly hiding it, it went largely unnoticed until Twitter user Gael Breton pointed it out in a tweet on Wednesday, as Futurism notes.
- “For now, it's a small-scale test as we only see 72 results disclosed as written by AI,” writes Breton in the thread.
- “And it looks like Google is not giving a s**t about it, rewarding several of these pages with great search traffic. Soooo.. Is AI content ok now?” Related StoriesNew York Lawyer Caught Using ChatGPT After Citing Cases That Don't ExistShould We All Be Meditating? Find Out In Issue 11 Of CURIOUS – Out NowGoodbye, WinRAR: Windows Is Finally Adding This Much-Wanted Feature
- It’s a good question – will Google begin cracking down on AI content, or will the top pages consist of content that is rapidly automated and likely well-optimized for SEO? Google has previously said they will be attempting to prevent AI content from flooding their site, but to do so, Google would first have to find a way to identify such content – which would be a mammoth task without the large writing in bold now found on CNET articles.
- The CNET author “CNET Money” is the automated author in question and is responsible for 73 explainer articles around finance, including “Overdraft Fees vs. Nonsufficient Funds Fees: What's the Difference?” and “What Is Zelle and How Does It Work?”. Each article is checked by editorial staff (humans) to make sure there’s no nonsense in there, but the main bulk is drawn up from AI. Check for yourself, it’s seriously impressive.
- AI has the potential to swiftly infiltrate a huge number of writing industries, with almost perfect blog posts and undergraduate essays just one prompt away. Schools in the US are trying to ban their use in academics, though it remains unclear how successful that will be and whether anyone will produce a reliable way to distinguish AI-generated content. One thing’s for sure – this is just the start.
- artificial intelligence,
- AI,
- writing,
- science and society,
- ChatGPT
- Advertisement
- Advertisement
- Advertisement
- Sign up today to get weekly science coverage direct to your inbox
- © 2023 IFLScience.  All Rights Reserved. | RSS

URL: https://www.theverge.com/2023/1/19/23562966/cnet-ai-written-stories-red-ventures-seo-marketing
- By  Mia Sato and  James Vincent
- Every morning around 9AM ET, CNET publishes two stories listing the day’s mortgage rates and refinance rates. The story templates are the same every day. Affiliate links for loans pepper the page. Average rates float up and down day by day, and sentences are rephrased slightly, but the tone — and content — of each article is as consistent as clockwork. They are perfectly suited to being generated by AI.
- The byline on the mortgage stories is Justin Jaffe, the managing editor of CNET Money, but the stories aren’t listed on Jaffe’s actual author page. Instead, they appear on a different author page that only contains his mortgage rate stories. His actual author page lists a much wider scope of stories, along with a proper headshot and bio.
- CNET is the subject of a swirling controversy around the use of AI in publishing, and it’s Jaffe’s team that’s been at the center of it all. Last week, Futurism reported that the website had been quietly publishing articles written using artificial intelligence tools. Over 70 articles have appeared with the byline “CNET Money Staff” since November, but an editorial note about a robot generating those stories was only visible if readers did a little clicking around.
- It wasn’t just readers that were confused about what stories on CNET involve the use of AI. Beyond the small CNET Money team, few people at the outlet know specific details about the AI tools — or the human workflow around them — that outraged readers last week, according to current and former staffers who spoke to The Verge on the condition that they remain anonymous. Under the two-year-old management of a private equity company called Red Ventures, CNET’s editorial staff has often been left wondering: was this story written by AI or a co-worker? Even today, they’re still not sure.
- Daily mortgage rate stories might seem out of place on CNET, slotted between MacBook reviews and tech news. But for CNET parent company Red Ventures, this SEO-friendly content is the point.
- CNET was once a high-flying powerhouse of tech reporting that commanded a $1.8 billion purchase price when it was acquired by CBS in 2008. Since then, it has fallen victim to the same disruptions and business model shifts as the rest of the media industry, resulting in CBS flipping the property to Red Ventures for just $500 million in 2020.
- This type of SEO farming can be massively lucrative
- Red Ventures’ business model is straightforward and explicit: it publishes content designed to rank highly in Google search for “high-intent” queries and then monetizes that traffic with lucrative affiliate links. Specifically, Red Ventures has found a major niche in credit cards and other finance products. In addition to CNET, Red Ventures owns The Points Guy, Bankrate, and CreditCards.com, all of which monetize through credit card affiliate fees. The CNET AI stories at the center of the controversy are straightforward examples of this strategy: “Can You Buy a Gift Card With a Credit Card?” and “What Is Zelle and How Does It Work?” are obviously designed to rank highly in searches for those topics. Like CNET, Bankrate and CreditCards.com have also published AI-written articles about credit cards with ads for opening cards nestled within. Both Bankrate and CreditCards.com directed questions about the use of AI to Lance Davis, the vice president of content at Red Ventures; CNET’s disclosure also included Davis as a point of contact until last week.
- This type of SEO farming can be massively lucrative. Digital marketers have built an entire industry on top of credit card affiliate links, from which they then earn a generous profit. Various affiliate industry sites estimate the bounty for a credit card signup to be around $250 each. A 2021 New York Times story on Red Ventures pegged it even higher, at up to $900 per card.
- Viewed cynically, it makes perfect sense for Red Ventures to deploy AI: it is flooding the Google search algorithm with content, attempting to rank highly for various valuable searches, and then collecting fees when visitors click through to a credit card or mortgage application. AI lowers the cost of content creation, increasing the profit for each click. There is not a private equity company in the world that can resist this temptation.
- The problem is that there’s no real reason to fund actual tech news once you’ve started down that path.
- On CNET senior editor Rae Hodge’s last day, she sent a goodbye email to hundreds of her co-workers imploring them to look more skeptically at their AI co-workers. Her email began with a screenshot of a ChatGPT-generated resignation letter. “I am writing this letter using AI-generated content,” the note reads. “While I may not have personally composed these words, I hope they convey the sincere appreciation I have for my colleagues and the work we have done together.”
- In the email, obtained by The Verge, Hodge goes on to direct colleagues to ask pointed questions of several Red Ventures executives, saying that unattributed AI-written content was being sent to subscribers of a cybersecurity email newsletter. What’s worse, the newsletters had errors in them that “could cause direct harm to readers,” Hodge wrote in the email.
- A former CNET employee says that Red Ventures was using automated technology for content long before the AI byline began cropping up in November. They say a tool called Wordsmith — nicknamed “Mortgotron” internally because of its use in mortgage stories — has been used for at least a year and a half.
- “Sometimes the Money writers write like they’re bots, too.”
- But the siloed nature of the teams across CNET and Red Ventures has made it difficult for journalists at the site to understand the chain of command — in particular, who’s using what tools and when. Those who knew of the AI tool and its uses say that the workflow was so unclear, they sometimes couldn’t distinguish between AI-written stories and articles written by colleagues.
- “It’s used most often in relation to relaying updated mortgage and refinance rates,” said one source who was familiar with the tool. “I was told that it was always effectively a bot writing these stories.”
- Are you a former or current CNET / Red Ventures employee? I’d love to hear from you. Contact me at mia@theverge.com, and I’ll share my Signal.
- But even though some on staff knew automation tools were part of the workflow, the scope of their use was unclear to colleagues whose bylines were appearing on the same site. The former staffer says that by the time stories were published on the site, they didn’t always know if AI tools were involved in the production.
- “Sometimes the Money writers write like they’re bots, too, and they’re regular humans,” a former employee says. “The quality of writing is nearly indistinguishable. That does not make it good.”
- But the robot articles published on CNET don’t need to be “good” — they need to rank highly in Google searches so lots of people open them and click the lucrative affiliate marketing links they contain.
- It was a way to generate content that would take human writers longer — the “dull SEO-friendly topics”
- CNET staff was notified last fall that some articles would be written by AI, but by the time they found out, several stories had already been published on other Red Ventures websites, according to one staffer. Those sites also lack clarity around what exactly AI is being used for. On Bankrate, one article originally published in May was bylined by a human writer; it’s now been updated to list an AI author. The content of the story, though, is the same.
- “I don’t know that it was announced in any kind of grand way,” a CNET staffer told The Verge. “It just sort of showed up.”
- The justification for the tool given to staff, multiple people say, was that it was a way to generate content that would take human writers longer — handling the “dull SEO-friendly topics” or making sure that legal requirements for writing about finance are met. It was sold as a way to free up staff time so they could do more thoughtful work. Instead, several staffers have departed since November, and morale is low at the outlet after several rounds of layoffs, according to former employees.
- Reached for comment, Red Ventures refused to answer any questions about the AI tools it uses, the types of content it generates, or how it disclosed the practices to readers. Instead, an unnamed spokesperson directed The Verge to CNET editor-in-chief Connie Guglielmo’s note defending the use of AI tools at the outlet.
- Using AI in journalism has a much longer history than CNET’s ventures. The Associated Press was one early adopter and announced it would start using Wordsmith in 2014 to produce short articles about companies’ earnings reports. In 2016, it expanded coverage to include sports reporting, and it now partners with another AI writing firm called Data Skrive for this content.
- As with CNET, The Associated Press frames its use of AI as a way to “free journalists to do more journalism and less data processing.” The stories it’s automated are high-volume and formulaic, work that bores journalists but is a necessary backbone for wire services like the AP. The AP labels some stories as automated with a footer noting the use of automated tools to create the story, but a reader may not understand what it means that the story was created “using technology.”
- Red Ventures’ experiments with AI content reflect improvements in the world of AI since 2014. A new breed of AI language models is able to easily generate text that is more coherent and covers a wide array of subjects. Studies have found that humans are unable to consistently distinguish between text written by humans and the latest AI systems, leading to exactly the sort of confusion CNET sources have described. Although Red Ventures has refused to offer more details about the tools it’s using, job descriptions of the company’s staff suggest it is indeed tapping the latest generation of technology and applying it widely.
- The company’s “​​content head for all AI and automated solutions” for educational websites, Kevin Hughes, says on LinkedIn that he uses not only Wordsmith but also OpenAI’s GPT series “to generate programmatic SEO and bespoke AI content across a dozen websites, generating millions of dollars in revenue.” Hughes lists a number of Red Ventures websites that he’s worked on, including bestcolleges.com, nursejournal.org, and cyberdegrees.org.
- With improvements in AI language models over the past few years, experts have warned about potential malicious use cases. Some of the more exotic include automated propaganda and influence peddling, but the more prosaic include mass-produced spam and marketing copy. In 2021, Fabian Langer, the founder of an AI writing startup named AI Writer, told The Verge how his tools were already being used to fill “SEO farms” with content. Said Langer: “For these [SEO] farms, I do not expect that people really read it. As soon as you get the click, you can show your advertisement, and that’s good enough.”
- The cheapness and ease with which these tools can generate content has led some to predict that this writing could slowly take over the web, polluting search results and social media with text designed only to push someone to a specific product or website.
- Red Ventures has shown interest in AI products beyond using them at the news sites it owns. Last year, Red Ventures led a $10.6 million fundraising round for Rephrase.ai, a generative AI company that produces sets of customized videos based on one original clip of a person speaking.
- Internally, there has been unease among CNET staff at their corporate owners’ use of artificial intelligence — though staff was assured the current test is limited in scope. But layoffs and restructuring, coupled with the lack of clarity on the use of new tools, are causing some to worry about what the creep of AI signals for the venerated site so many journalists were drawn to.
- “I don’t lay any blame at CNET’s or its masthead’s feet,” one former staffer says. “This is all due to the machinations of the greater Red Ventures machine, and its desire to squeeze blood from a stone.”
- After multiple rounds of layoffs last year, dozens of people lost their jobs, from audience and copy teams to CNET cars staff. Entire teams were decimated, one former staffer says, and people continue to leave “in droves,” fearing more layoffs are around the corner.
- The departure email sent by Hodge acknowledges the good work done by her CNET co-workers and warns of the road ahead with regards to journalistic integrity and editorial standards.
- “It pains me to leave this outlet with the knowledge that those colleagues’ battle to maintain and strengthen the editorial credibility of CNET will continue to be one fought uphill,” she wrote.
- The vision of a dark future where robots sap up jobs is a common refrain in journalism. But a former staffer says more familiar tactics to boost margins — like the layoffs that have gutted teams at CNET — are top of mind for remaining employees.
- “They do not fear AI more than they fear the numerous layoffs Red Ventures has insisted upon,” a former employee says. “Everyone at CNET is more afraid of Red Ventures than they are of AI.”
- / Sign up for Verge Deals to get deals on products we've tested sent to your inbox daily.
- The Verge is a vox media network
- © 2023 Vox Media, LLC. All Rights Reserved

URL: https://www.theverge.com/2023/1/20/23564311/cnet-pausing-ai-articles-bot-red-ventures
- By  Mia Sato, platforms and communities reporter with five years of experience covering the companies that shape technology and the people who use their tools.
- CNET will pause publication of stories generated using artificial intelligence “for now,” the site’s leadership told employees on a staff call Friday.
- The call, which lasted under an hour, was held a week after CNET came under fire for its use of AI tools on stories and one day after The Verge reported that AI tools had been in use for months, with little transparency to readers or staff. CNET hadn’t formally announced the use of AI until readers noticed a small disclosure.
- “We didn’t do it in secret,” CNET editor-in-chief Connie Guglielmo told the group. “We did it quietly.”
- CNET, owned by private equity firm Red Ventures, is among several websites that have been publishing articles written using AI. Other sites like Bankrate and CreditCards.com would also pause AI stories, executives on the call said.
- Futurism noted that CNET and Bankrate appeared to have stopped running AI stories as early as Wednesday.
- The call was hosted by Guglielmo, Lindsey Turrentine, CNET’s EVP of content and audience, and Lance Davis, Red Ventures’ vice president of content. They answered a handful of questions submitted by staff ahead of time in the AMA-style call.
- Davis, who was listed as the point of contact for CNET’s AI stories until recently, also gave staff a more detailed rundown of the tool that has been utilized for the robot-written articles. Until now, most staff had very little insight into the machine that was generating dozens of stories appearing on CNET.
- Are you a former or current CNET / Red Ventures employee? I’d love to hear from you. Contact me at mia@theverge.com, and I’ll share my Signal.
- The AI, which is as of yet unnamed, is a proprietary tool built by Red Ventures, according to Davis. AI editors are able to choose domains and domain-level sections from which to pull data from and generate stories; editors can also use a combination of AI-generated text and their own writing or reporting.
- Turrentine declined to answer staff questions about the dataset used to train AI in today’s meeting as well as around plagiarism concerns but said more information would be available next week and that some staff would get a preview of the tool.
- Leadership also differentiated between the unnamed internal tool and other automated technology Red Ventures uses on its sites to auto-insert numbers into mortgage rate and refinance rate stories, which The Verge reported had been in use for far longer but that the company didn’t disclose.
- CNET will begin including disclosures on their own stories about AI
- “Some writers — I won’t call them reporters — have conflated these two things and had caused confusion and have somehow said that using a tool to insert numbers into interest rate or stock price stories is somehow part of some, I don’t know, devious enterprise,” Guglielmo said. “I’m sure that’s news to The Wall Street Journal, Bloomberg, The New York Times, Forbes, and everyone else who does that and has been doing it for a very, very long time.”
- Guglielmo said that, going forward, stories on CNET about artificial intelligence will have a disclosure that the outlet uses its own automated technologies. Red Ventures also created an AI working group spanning across multiple departments, though it’s unclear what the council has done so far — leadership noted that the Slack channel had been created.
- “I just want to reassure everybody: this will pass,” Turrentine said of the media coverage in recent weeks. “It’s uncomfortable, we will get through it, the news cycle will move on.”
- Yesterday, The Verge reported that despite CNET’s “experiments” in AI-generated technology, many on staff were largely kept in the dark about what tools the company was using or how it was using them. At times, staffers told The Verge that they didn’t know if content published to CNET was AI-generated or written by their human colleagues. CNET and Red Ventures declined to answer any of The Verge’s questions about the tools used or disclosure policies.
- The stories that used AI are central to Red Ventures’ SEO-winning marketing strategy in which websites publish content with the aim of ranking highly in Google search. The highly trafficked pages are then loaded with ads for things like credit cards and loans — lucrative opportunities for affiliate marketing.
- / Sign up for Verge Deals to get deals on products we've tested sent to your inbox daily.
- The Verge is a vox media network
- © 2023 Vox Media, LLC. All Rights Reserved

- Microsoft replaces journalists with AI
- Chandigarh sanitation worker smartwatch surveillance
- Page infoType: SystemPublished: January 2023Last updated: May 2023
