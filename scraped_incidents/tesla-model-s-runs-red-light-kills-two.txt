- Occurred: December 2019
- Can you improve this page?Share your insights with us
- Tesla owner Kevin George Aziz Riad has been charged with a felony in the US for a December 2019 crash that left people dead whilst his car was on Autopilot.
- According to police, Riad's Tesla Model S was moving at a high speed when it left a freeway and ran a red light before striking a Honda Civic, killing Gilberto Alcazar Lopez and Maria Guadalupe Nieves-Lopez.
- The families of Lopez and Nieves-Lopez have sued Tesla and Riad in separate lawsuits alleging negligence by Riad and accusing Tesla of selling defective vehicles that accelerate suddenly and that lack an effective automatic emergency braking system.
- Riad's preliminary hearing is scheduled for February 2023.
- Operator: Kevin George Aziz Riad Developer: Tesla
- Country: USA
- Sector: Automotive
- Purpose: Automate steering, acceleration, braking
- Technology: Driver assistance system; Self-driving system Issue: Accuracy/reliability; Safety
- Transparency: Black box
- Tesla Autopilot and Full Self-Driving Capability
- Tesla Autopilot Wikipedia profile
- Maria Luz Nieves v Kevin George Aziz Riad, et al
- Tesla Deaths
URL: https://www.reuters.com/legal/tesla-crash-trial-california-hinges-question-man-vs-machine-2022-11-01/
- Nov 1 (Reuters) - A manslaughter trial set to begin in Los Angeles for a fatal crash caused by a Tesla (TSLA.O) operating on Autopilot presents a first-of-its kind test for the legal responsibility of a human driver in a car that was partly driving itself, legal experts say.
- The trial, set to begin Nov. 15, comes as civil cases head to trial next year over accidents involving Tesla’s Autopilot and adds to scrutiny of a system that Tesla co-founder Elon Musk has touted as a step to fully autonomous driving.
- Critics say Tesla's claims and Autopilot have contributed to accidents – and deaths - by making drivers inattentive.
- The U.S. Department of Justice is investigating whether Tesla itself should face criminal charges over its self-driving claims, Reuters reported.
- The Los Angeles trial could shape public – and future jury – perceptions of Tesla and could be a test case for whether the technology has advanced faster than legal standards, legal experts say.
- “Who's at fault, man or machine?" Edward Walters, an adjunct professor at the Georgetown University law school who specializes in the law governing self-driving cars. "The state will have a hard time proving the guilt of the human driver because some parts of the task are being handled by Tesla.”
- After midnight on Dec. 29, 2019, Kevin George Aziz Riad, now 28, exited a freeway in Gardena, California, in a Tesla Model S, ran a red light and crashed into a Honda Civic, police say. The driver and passenger in the Civic, Gilberto Lopez and Maria Guadalupe Nieves-Lopez, died at the scene. They were on their first date, relatives told the Orange County Register.
- The car's Autopilot system, which can control speed, braking and steering, was engaged at the time of the crash.
- Tesla does not face charges in the case, and legal experts say the bar for a criminal case against a company is high.
- Tesla did not respond to Reuters' request for comments. Tesla says on its website that its driver assistance systems "require active driver supervision and do not make the vehicle autonomous."
- The family of Gilberto Lopez is suing Tesla with trial scheduled for July.
- "I can't say that the driver was not at fault, but the Tesla system, Autopilot, and Tesla spokespeople encourage drivers to be less attentive," Donald Slavik, an attorney whose firm is representing Lopez's family in a lawsuit against Tesla, told Reuters.
- Slavik said Tesla understood the risks of its system but failed to manage those. "Tesla knows people are going to use Autopilot and use it in dangerous situations," he said.
- Musk said in September that he believed Tesla had a "moral obligation" to roll out what he calls “Full Self Driving” software, even if it was not perfect and Tesla were sued, because doing so could save lives.
- Prosecutors have said Riad's speeding and failure to brake was reckless. His lawyer, Arthur Barens, said in May that Riad should not be charged with a crime. Both declined to comment further.
- Robert Blecker, a criminal law professor at New York Law School, said the probe by the Justice Department (DOJ) of Tesla's claims could make it harder for California prosecutors at trial.
- "The DOJ probe helps him because his claim is going to be 'I relied on their advertising. Therefore, I was not aware of the risk there,'" Blecker said.
- The legal and regulatory scrutiny of Tesla could shape perception of the company, a risk as it looks to defend itself in coming lawsuits, said Bryant Walker Smith, a law professor at the University of South Carolina, who is also an adviser on new transportation technology.
- "The narrative of Tesla potentially shifts from this innovative tech company doing cool things to this company just mired in legal trouble. That is the risk, and narrative is very important in civil litigation because both sides tell a jury a story," he said.
- Our Standards: The Thomson Reuters Trust Principles.
- Gayatri Joshi
- Elizabeth Duffy
- Zach Warren
- Blake Brittain
- Reuters, the news and media division of Thomson Reuters, is the world’s largest multimedia news provider, reaching billions of people worldwide every day. Reuters provides business, financial, national and international news to professionals via desktop terminals, the world's media organizations, industry events and directly to consumers.
- Build the strongest argument relying on authoritative content, attorney-editor expertise, and industry defining technology.
- The most comprehensive solution to manage all your complex and ever-expanding tax and compliance needs.
- The industry leader for online information for tax, accounting and finance professionals.
- Access unmatched financial data, news and content in a highly-customised workflow experience on desktop, web and mobile.
- Browse an unrivalled portfolio of real-time and historical market data and insights from worldwide sources and experts.
- Screen for heightened risk individual and entities globally to help uncover hidden risks in business relationships and human networks.
- All quotes delayed a minimum of 15 minutes. See here for a complete list of exchanges and delays.
- © 2023 Reuters. All rights reserved

URL: https://nypost.com/2022/01/18/tesla-driver-first-to-be-charged-in-fatal-crash-involving-autopilot/
- Thanks for contacting us. We've received your submission.
- A Tesla driver involved in a fatal wreck in California over two years ago while using Autopilot has been charged with two counts of vehicular manslaughter.
- The charges against limousine service driver Kevin George Aziz Riad, 27, represent the first felony charges in the US for a deadly crash involving a motorist who was using Tesla’s popular partially automated driving system, the Associated Press reported.
- Riad was allegedly behind the wheel of a Tesla Model S that careened off a freeway in the Los Angeles suburb of Gardena, blew a red light and struck a Honda Civic in December 2019.
- Two occupants in the Civic, Gilberto Alcazar Lopez and Maria Guadalupe Nieves-Lopez, were killed.
- Los Angeles County prosecutors filed the charges against Riad in October, though they just came to light last week.
- Other counts have been filed in the US involving automated driving systems, but Riad’s charges are the first connected to Tesla’s widely used Autopilot technology.
- Autopilot can control steering, speed and braking. An estimated 765,000 Tesla vehicles in the US are equipped with the technology.
- Numerous crashes involving Autopilot are being investigated by the NHTSA and the National Transportation Safety Board.
- Since the Autopilot crashes began, Tesla has updated the software to try to make it harder for drivers to abuse it.
- Tesla has warned that Autopilot and a more sophisticated “Full Self-Driving” system cannot drive themselves and that drivers must pay attention and be ready to react at any time.
- With Post wires

URL: https://futurism.com/manslaughter-case-tesla-autopilot
- A provocative manslaughter case is about to kick off in Los Angeles later this month, involving a fatal crash caused by a Tesla vehicle that had the company's controversial Autopilot feature turned on.
- It's the first case of its kind, and one that could set a precedent for future crashes involving cars and driver-assistance software, Reuters reports.
- We won't know the exact defense until the case gets under way, but the crux is that the man who was behind the wheel of the Tesla is facing manslaughter charges — but has pleaded not guilty, setting up potentially novel legal arguments about culpability in a deadly collision when, technically speaking, it wasn't a human driving the car.
- "Who's at fault, man or machine?" asked Edward Walters, an adjunct professor at the Georgetown University, in an interview with Reuters. "The state will have a hard time proving the guilt of the human driver because some parts of the task are being handled by Tesla."
- The upcoming trial is about a fatal collision that took place in 2019. The crash involved Kevin George Aziz Riad, who ran a red light in his Tesla Model S, and collided with a Honda Civic, killing a couple who were reportedly on their first date.
- According to vehicle data, Riad did not apply the brakes but had a hand on the steering wheel. Perhaps most critically, though, the Tesla's Autopilot feature was turned on in the moments leading up to the crash.
- Riad is facing manslaughter charges, with prosecutors arguing his actions were reckless.
- Meanwhile, Riad's lawyers have argued that he shouldn't be charged with a crime, but have so far stopped short of publicly placing blame on Tesla's Autopilot software.
- Tesla is not directly implicated in the upcoming trial and isn't facing charges in the case, according to Reuters.
- A separate trial, however, involving the family of one of the deceased is already scheduled for next year — but this time, Tesla is the defendant.
- "I can't say that the driver was not at fault, but the Tesla system, Autopilot, and Tesla spokespeople encourage drivers to be less attentive," the family's attorney Donald Slavik told Reuters.
- "Tesla knows people are going to use Autopilot and use it in dangerous situations," he added.
- Tesla is already under heavy scrutiny over its Autopilot and so-called Full Self-Driving software, despite conceding that the features "do not make the vehicle autonomous" and that drivers must remain attentive of the road at all times.
- Critics argue that Tesla's marketing is misleading and that it's only leading to more accidents — not making the roads safer, as Tesla CEO Elon Musk has argued in the past.
- In fact, a recent survey found that 42 percent of Tesla Autopilot said they feel "comfortable treating their vehicles as fully self-driving."
- Regulators are certainly already paying attention. The news comes a week after Reuters revealed that the Department of Justice is investigating Tesla over Autopilot.
- Last year, the National Highway Traffic Safety Administration (NHTSA) announced an investigation of accidents in which Teslas have smashed into emergency response vehicles that were pulled over with sirens or flares.
- This month's trial certainly stands the chance of setting a precedent. Was Riad fully at fault or was Tesla's Autopilot at least partially to blame as well?
- The answer now lies in the hands of a jury.
- READ MORE: Tesla crash trial in California hinges on question of 'man vs machine' [Reuters]
- More on Autopilot: Survey: 42% of Tesla Autopilot Drivers Think Their Cars Can Drive Themselves
- DISCLAIMER(S)
- Articles may contain affiliate links which enable us to share in the revenue of any purchases made.
- Registration on or use of this site constitutes acceptance of our Terms of Service.
- © Recurrent Ventures Inc, All Rights Reserved.

URL: https://www.businessinsider.com/driver-who-had-tesla-on-autopilot-in-crash-manslaughter-trial-2022-5
- Jump to
- 
- 
- 
- A Tesla driver who had his car on Autopilot in a crash that killed two people will stand trial on two counts of manslaughter in Los Angeles, Fox Business reported.
- The fatal accident in 2019 occurred when Kevin George Aziz Riad, 27, was driving a Tesla Model S at 74 mph in Gardena, Los Angeles. The Tesla driver, who previously pleaded not guilty, will go on trial for vehicular manslaughter. The case may be the first time a driver is facing a court trial for using semi-automated technology in a fatal crash. Riad's car went through a red light and crashed into a Honda Civic in a collision that killed Gilberto Alcazar Lopez, 40, and Maria Guadalupe Nieves-Lopez, 39, the report said.
- Prosecutors said the Tesla's Autopilot features including autosteer and traffic aware cruise control were being used when the driver crashed into the Honda.
- Six minutes before the collision, no brakes were used, crash data showed. But sensors appeared to show that the driver being tried for manslaughter had a hand on the steering wheel, according to a Tesla engineer who testified.
- The driver will now be tried on two counts of vehicular manslaughter, according to a Fox 11 LA report.  Riad and a female passenger in the Tesla were treated for injuries in hospital. A number of car crashes have been recorded while drivers used Tesla Autopilot functions, and the first self-driving-related death was recorded in 2016.
- The National Highway Traffic Safety Administration is examining a dozen crashes that involved Tesla drivers using Autopilot features amid scrutiny over its advanced driver-assistance functions. Tesla's Autopilot and Full Self-Driving features need "active driver supervision", does not make the car autonomous, and is intended for "fully attentive" drivers, the company says on its website.
- Tesla did not immediately respond to Insider's request for comment.
- Read next

URL: https://www.dailymail.co.uk/news/article-10839133/California-Tesla-driver-27-stand-trial-2019-autopilot-crash-judge-rules.html
- By Keith Griffith For Dailymail.com and Associated Press
- Published:  21:14 EDT, 20 May 2022   |  Updated:  04:20 EDT, 21 May 2022
- 
- 167
- View  comments
- 
- The driver of a Tesla operating on Autopilot must stand trial for a crash that killed two people in a Los Angeles suburb, a judge ruled Thursday.
- There is enough evidence to try Kevin George Aziz Riad, 27, on two counts of vehicular manslaughter in the 2019 crash in Gardena, a Los Angeles County judge said.
- It is believed to be the first felony prosecution in the U.S. against a driver who was using using a partially automated driving system.
- Police said the Tesla Model S left a freeway and ran a red light in Gardena and was doing 74 mph when it smashed into a Honda Civic at an intersection on December 29, 2019.
- The crash killed Gilberto Alcazar Lopez, 40, of Rancho Dominguez and Maria Guadalupe Nieves-Lopez, 39, of Lynwood, who were in the Civic and were on their first date that night, relatives told the Orange County Register.
- Kevin George Aziz Riad, 27, will stand tria on two counts of vehicular manslaughter in the 2019 crash (above) in Gardena, a Los Angeles County judge said Thursday
- Maria Guadalupe Nieves-Lopez, 39, died after she was hit by a speeding Tesla on Autopilot near a freeway exit in Los Angeles in 2019
- Riad and a woman riding in the Tesla were hospitalized with non-life-threatening injuries, according to KTTV.
- Prosecutors said the Tesla's Autosteer and Traffic Aware Cruise Control were active.
- A Tesla engineer testified that sensors indicated Riad had a hand on the steering wheel but crash data showed no brakes were applied in the six minutes before the crash.
- A police officer testified Thursday that several traffic signs warning motorists to slow down were posted near the end of the freeway.
- Tesla has said that Autopilot and a more sophisticated "Full Self-Driving" system cannot drive themselves and that drivers must pay attention and be ready to react at anytime.
- The misuse of Autopilot, which can control steering, speed and braking, has occurred on numerous occasions and is the subject of investigations by two federal agencies.
- Police said the Tesla Model S left a freeway and ran a red light in Gardena and was doing 74 mph when it smashed into a Honda Civic at an intersection on December 29, 2019
- A Tesla engineer testified that sensors indicated Riad had a hand on the steering wheel but crash data showed no brakes were applied
- The charges against Riad come after Tesla was removed from the S&P 500 ESG Index in part due to the company's handling of Autopilot crashes.
- Maria Guadalupe Nieves-Lopez was on a first date when she was killed in the crash
- S&P Dow Jones Indices, which maintains the sustainability index, cited investigations into crashes and Tesla's response in removing the company from the list.
- Tesla CEO Elon Musk slammed the move as 'wacktivism,' claiming that the index 'has been weaponized by phony social justice warriors.'
- The filing of charges in the California crash could serve notice to drivers who use systems like Autopilot that they cannot rely on them to control vehicles.
- The families of Lopez and Nieves-Lopez have sued Tesla and Riad in separate lawsuits.
- They have alleged negligence by Riad and have accused Tesla of selling defective vehicles that can accelerate suddenly and that lack an effective automatic emergency braking system. A joint trial is scheduled for mid-2023.
- Lopez's family, in court documents, alleges that the car 'suddenly and unintentionally accelerated to an excessive, unsafe and uncontrollable speed.'
- The December 29, 2019 accident happened near the intersection of Artesia Boulevard and Vermont Avenue in the Los Angeles suburb of Gardena
- Nieves-Lopez's family further asserts that Riad was an unsafe driver, with multiple moving infractions on his record, and couldn't handle the high-performance Tesla.
- The criminal charges against Riad aren´t the first involving an automated driving system, but they are the first to involve a widely used driver technology.
- Authorities in Arizona filed a charge of negligent homicide in 2020 against a driver Uber had hired to take part in the testing of a fully autonomous vehicle on public roads.
- The Uber vehicle, an SUV with the human backup driver on board, struck and killed a pedestrian.
- Meanwhile, the National Highway Traffic Safety Administration on Wednesday confirmed that it had sent a special crash investigation team to determine whether a Tesla involved in a May 12 crash in Newport Beach that killed three people was operating on a partially automated driving system.
- Autonomous vehicles and driver-assist system have been a source of controversy and concern in recent years.
- In January 2018, an unidentified man allowed his Tesla on Autopilot to wander into a fire truck in Culver City, California.
- No one was hurt, and he told investigators he was enjoying his coffee and bagel right before the crash.
- In March 2018, a woman hired to test an Uber autonomous SUV fatally struck a pedestrian in suburban Phoenix in 2018.
- She was charged with negligent homicide, but prosecutors let Uber off the hook.
- Police say they have proof that the driver's phone was streaming The Voice on Hulu at the time.
- In December 2019, a man exited a freeway ramp at a high speed in Los Angeles, ran a red light, and hit a Honda Civic, killing both its passengers.
- He was charged with two counts of vehicular manslaughter in October 2021.
- In April 2021, two men died after their 2019 Model S crashed into a tree and burst into flames near Spring, Texas.
- An NTSB report released in October revealed that the driver was actually behind the wheel and wearing his seatbelt at the time of the crash.
- In May 2021, Param Sharma, 25, was arrested on misdemeanor charges of reckless driving and disobeying a peace officer after officers noticed his Tesla moving down a California freeway while he sat in the back seat with no one in the driver's seat.
- Dispatchers had gotten calls about a driverless Tesla Model 3 going east on Interstate 80 across the Bay Bridge.
- In all, the National Highway Traffic Safety Administration has sent investigation teams to 27 crashes involving Autopilot since 2016, involving at least 11 deaths.
- The NHTSA and the National Transportation Safety Board do not release names of victims.
- Deaths involving Autopilot:
- June 2016 in Florida
- March 2018 in Arizona
- March 2018 in California
- March 2019 in Florida
- January 2019 in Indiana
- September 2020 in California (two deaths)
- April 2021 in Texas (two deaths)
- May 2021 in California
- August 2021 in New York
- 
- Published by Associated Newspapers Ltd
- Part of the Daily Mail, The Mail on Sunday & Metro Media Group

URL: https://www.nbcnews.com/news/us-news/tesla-driver-charged-vehicular-manslaughter-fatal-autopilot-crash-rcna12724
- Morning Rundown: Biden and McCarthy reach a debt deal, a building collapse in Iowa and ‘Succession’ finale
- 
- Profile
- Sections
- tv
- Featured
- More From NBC
- Follow NBC News
- A man whose Tesla was said to be on Autopilot when it allegedly crashed into a car and killed two people has been charged with vehicular manslaughter.
- Kevin George Aziz Riad, 27, is likely the first motorist to be accused of a felony in the United States after a fatal accident while using a partially automated driving system.
- According to authorities, his 2016 Tesla Model S collided with a Honda Civic in Gardena, California, on Dec. 29, 2019, killing Gilberto Alcazar Lopez and Maria Guadalupe Nieves-Lopez.
- A civil case which names Riad and Tesla Motors Inc as defendants alleges that the car was traveling at an “excessively high rate of speed” when it crashed.
- Riad and a woman in the Tesla were hospitalized with non-life-threatening injuries.
- Riad, a limousine service driver, was charged in October with two counts of vehicular manslaughter with gross negligence, but they came to light only last week, according to The Associated Press. His attorney and Tesla did not immediately respond to a request for comment on Wednesday.
- Riad has pleaded not guilty to the charges and is out on bail while the case is pending. His preliminary hearing is scheduled for Feb. 23.
- The criminal charges aren’t the first involving an automated driving system, but they are the first to involve a widely-used driver technology. Authorities in Arizona filed a charge of negligent homicide in 2020 against a driver Uber had hired to take part in the testing of a fully autonomous vehicle on public roads. The Uber vehicle, an SUV with the human backup driver on board, struck and killed a pedestrian.
- By contrast, Autopilot and other driver-assist systems are widely used on roads across the world. An estimated 765,000 Tesla vehicles are equipped with it in the United States alone.
- Minyvonne Burke is a senior breaking news reporter for NBC News.
- Andrew Blankstein is an investigative reporter for NBC News. He covers the Western U.S., specializing in crime, courts and homeland security.
- © 2023 NBC UNIVERSAL

URL: https://www.nyu.edu/about/news-publications/news/2022/march/when-a-tesla-on-autopilot-kills-someone--who-is-responsible--.html
- Connecting talented and ambitious people in the world's greatest cities, our mission is to be a top quality institution.
- Join our more than 40,000 students studying in hundreds of programs on six continents all around the globe.
- Our world-class students, faculty, and scholars expect high achievement in pursuit of engaging the world's diverse challenges.
- An institution without walls, we draw spirit from our cities and their famous cultural institutions and professional opportunities.
- Being at the forefront of their disciplines, our faculty shape the understanding of an enormous range of academic fields.
- Connecting talented and ambitious people in the world's greatest cities, our mission is to be a top quality institution.
- Join our more than 40,000 students studying in hundreds of programs on six continents all around the globe.
- Our world-class students, faculty, and scholars expect high achievement in pursuit of engaging the world's diverse challenges.
- An institution without walls, we draw spirit from our cities and their famous cultural institutions and professional opportunities.
- Being at the forefront of their disciplines, our faculty shape the understanding of an enormous range of academic fields.
- Source: Getty Images
- In late 2019, Kevin George Aziz Riad’s car sped off a California freeway, ran a red light, and crashed into another car, killing the two people inside. Riad’s car, a Tesla Model S, was on Autopilot.
- Earlier this year, Los Angeles County prosecutors filed two charges of vehicular manslaughter against Riad, now 27, and the case marks the first felony prosecution in the U.S. of a fatal car crash involving a driver-assist system. It is also the first criminal prosecution of a crash involving Tesla’s Autopilot function, which is found on over 750,000 cars in the U.S. Meanwhile, the crash victims' family is pursuing civil suits against both Riad and Tesla.
- Tesla is careful to distinguish between its Autopilot function and a driverless car, comparing its driver-assist system to the technology airplane pilots use when conditions are clear. “Tesla Autopilot relieves drivers of the most tedious and potentially dangerous aspects of road travel,” states Tesla online. “We're building Autopilot to give you more confidence behind the wheel, increase your safety on the road, and make highway driving more enjoyable … The driver is still responsible for, and ultimately in control of, the car.”
- The electric vehicle manufacturer clearly places the onus of safety on the driver, but research suggests that humans are susceptible to automation bias, an over-reliance on automated aids and decision support systems. Now it’s up to the courts to decide who is culpable when the use of those systems results in fatal errors.
- Currently, Riad is out on bail and pleading not guilty to manslaughter charges. NYU News spoke with Mark Geistfeld—NYU Law Sheila Lubetsky Birnbaum Professor of Civil Litigation and the author of the California Law Review paper “A Roadmap for Autonomous Vehicles: State Tort Liability, Automobile Insurance, and Federal Safety Regulation"—about the significance of these criminal charges and what they might mean for the future of  consumer trust in new tech.
- Can you shed some light on the legal precedent the criminal prosecution of Kevin George Aziz Riad sets? What message does it send to consumers and manufacturers of similar technology?
- First, the criminal charges are surprising, based on what we know—the criminal charging documents, as usual, provide no details. Typically, if you weren’t paying attention, ran a red light and hit somebody—as tragic as it is—you wouldn’t get a criminal charge out of that behavior in the vast majority of cases. You really don’t see many criminal prosecutions for motor vehicle crashes outside of drunk-driving cases.
- If the driver was found guilty of manslaughter, this case could really be the most disruptive, the most novel, the most groundbreaking precedent. It's a strong departure from the past, if in fact the criminal prosecution is simply based on his relying on autopilot when he should have taken over. If that’s what is going on, you might see a lot more criminal prosecutions moving forward than we do today.
- Tort liability, or civil charges, by contrast, is very commonplace. That’s when the defendant would pay damages for injuries caused. The majority of tort suits in state courts across the country are from motor vehicle crashes in which one driver is alleged to have negligently caused the crash, which clearly occurred in this case because the driver went through a red light.
- If this case somehow signals that criminal liability is more possible simply by relying on the technology, then that could become a profound shift in the nature of legal liabilities moving forward.
- What obligation does an advanced tech company such as Tesla -  have in informing drivers, whether directly or through advertising and marketing messages, that they are liable for all damages, regardless of whether the car is on autopilot?
- They clearly have an obligation to warn the person sitting in the driver's seat to take over the vehicle—that it's not capable of doing everything on its own. You see that warning in Tesla vehicles, and almost all vehicles have that type of warning. For example, when you use a map function while driving, many cars will offer a warning: “This will distract you, pay attention to the road.”
- Manufacturers also have an obligation to keep in mind the sense of complacency that comes with driving technology while designing the car. Tesla or any other manufacturers can’t just say, “Hey, pay attention, that’s your responsibility.” They actually have to try to put something into the design to make sure that drivers are staying attentive. So different manufacturers are taking different approaches to this problem—some cars will pull over if your hands are not on the steering wheel, and other cars have cameras that will start beeping if you’re not paying attention.
- Under current law, if the driver gets in a crash and there was an adequate warning, and the design itself is adequate enough to keep the driver attentive, the car manufacturer is not going to be liable. But there’s one possible exception here: there is a formulation of the liability rule that is pretty widely adopted across the country, including in California, where this case will take place. Under this rule, the inquiry is based on what consumers expect the manufacturer to do. And consumer expectations can be strongly influenced by marketing and advertising and so on.
- For example, if Tesla were to advertise that Autopilot never gets in a crash, and then a consumer does get in a crash, Tesla would be liable for having frustrated those expectations.
- In this case, the driver was charged based on the idea that he was over-reliant on his car's autopilot. What does this say about our basic assumptions about whether humans or tech are more trustworthy?
- There’s an important distinction between overreliance and complacency. I think complacency is just a natural human reaction to the lack of stimulus—in this case, the lack of responsibility for executing all of the driving tasks. You can get bored and lulled into a sense of complacency, but I don’t think that behavior is being overly reliant on technology.
- The idea of overreliance comes into play with the potential nature of the wrongdoing here. Maybe the driver in this case will defend himself by saying he reasonably thought the car had everything under control, was fully capable of solving this problem, and so he didn’t have to worry about reacting if things turned out otherwise. Now at that point, he would be placing his faith in the technology instead of in his own ability to stop the vehicle and get out of the problem in a safe way. If there is blind faith in the technology rather than in  taking over when you could have done so, and if you are liable as a consequence, that becomes a very profound, interesting kind of message that the law is sending.
- Do you think this shift in liability will hurt business for companies like Tesla?
- The big issue that autonomous vehicle manufacturers like Tesla face right now is gaining consumer trust when they’re introducing a new technology to the market. The need for trust in the early stages of these products is massively important. And all the manufacturers are worried about that problem because they know that if there are some horrific crashes, consumers are going to lose trust in the product. Ultimately the technology will end up taking over; it's just a question of whether it's sooner rather than later. And time is money in this context—so if you just get slower adoption because consumers are very concerned about the safety performance of the technology, that's going to hurt the industry. They obviously want to avoid that outcome. This technology is still going to take over—it’s just a question of how long it takes for that to happen. There are just so many advantages to using autonomous vehicles, including in the safety dimension.
- Of its Autopilot and Full Self-Driving Capability, Tesla says: "While these features are designed to become more capable over time, the currently enabled features do not make the vehicle autonomous." What liability issues do you foresee if/when these vehicles do become autonomous?
- It’s a complicated question, and that is the issue that everybody is interested in. Once these vehicles become fully autonomous, then there’s just the car. The human in the car isn’t even an element in the situation. So the big question is: once those vehicles crash, who pays? You’d think the manufacturer would be liable—and that’s going to increase the cost of these vehicles and make them a lot harder to distribute. There are a lot of people who think that in the event of a crash, the manufacturer should be liable all of the time. I am strongly skeptical about that conclusion, because I think it's a much closer call than most people make it out to be.
- Ultimately, these issues depend on how federal regulators like the National Highway Traffic Safety Administration regulate the vehicle. They will have to set a safety performance standard which the manufacturer has to satisfy before it can commercially distribute the product as fully autonomous. The question is where the regulators set that standard at, and I don’t think it’s easy to get right. At that point there will be a good debate to be had: Did they get it right or not? We’re still a few years out. I think we’ll all be having these conversations in 2025.

URL: https://www.cbsnews.com/sanfrancisco/news/california-prosecutors-file-felony-charges-against-tesla-autopilot-driver/
- Watch CBS News
- January 18, 2022 / 10:52 AM
          / CBS San Francisco
- FREMONT (CBS SF/AP) — California prosecutors recently made history when they filed two counts of vehicular manslaughter against the driver of a Tesla who ran a red light, slammed into another car and killed two people while driving on autopilot in 2019.
- The defendant appears to be the first person to be charged with a felony in the United States for a fatal crash involving a motorist who was using a partially automated driving system. Los Angeles County prosecutors filed the charges in October, but they came to light only last week.
- The driver, Kevin George Aziz Riad, 27, has pleaded not guilty. Riad, a limousine service driver, is free on bail while the case is pending.
- The misuse of Autopilot, which can control steering, speed and braking, has occurred on numerous occasions and is the subject of investigations by two federal agencies. The filing of charges in the California crash could serve notice to drivers who use systems like Autopilot that they cannot rely on them to control vehicles.
- The criminal charges aren't the first involving an automated driving system, but they are the first to involve a widely used driver technology. Authorities in Arizona filed a charge of negligent homicide in 2020 against a driver Uber had hired to take part in the testing of a fully autonomous vehicle on public roads. The Uber vehicle, an SUV with the human backup driver on board, struck and killed a pedestrian.
- By contrast, Autopilot and other driver-assist systems are widely used on roads across the world. An estimated 765,000 Tesla vehicles are equipped with it in the United States alone.
- In the Tesla crash, police said a Model S was moving at a high speed when it left a freeway and ran a red light in the Los Angeles suburb of Gardena and struck a Honda Civic at an intersection on Dec. 29, 2019. Two people who were in the Civic, Gilberto Alcazar Lopez and Maria Guadalupe Nieves-Lopez died at the scene. Riad and a woman in the Tesla were hospitalized with non-life threatening injuries.
- Criminal charging documents do not mention Autopilot. But the National Highway Traffic Safety Administration, which sent investigators to the crash, confirmed last week that Autopilot was in use in the Tesla at the time of the crash.
- Riad's defense attorney did not respond to requests for comment last week, and the Los Angeles County District Attorney's Office declined to discuss the case. Riad's preliminary hearing is scheduled for Feb. 23.
- NHTSA and the National Transportation Safety Board have been reviewing the widespread misuse of Autopilot by drivers, whose overconfidence and inattention have been blamed for multiple crashes, including fatal ones. In one crash report, the NTSB referred to its misuse as "automation complacency."
- The agency said that in a 2018 crash in Culver City, in which a Tesla hit a firetruck, the design of the Autopilot system had "permitted the driver to disengage from the driving task." No one was hurt in that crash.
- Last May, a California man was arrested after officers noticed his Tesla moving down a freeway with the man in the back seat and no one behind the steering wheel.
- Teslas that have had Autopilot in use also have hit a highway barrier or tractor-trailers that were crossing roads. NHTSA has sent investigation teams to 26 crashes involving Autopilot since 2016, involving at least 11 deaths.
- Messages have been left seeking comment from Tesla, which has disbanded its media relations department. Since the Autopilot crashes began, Tesla has updated the software to try to make it harder for drivers to abuse it. It's also tried to improve Autopilot's ability to detect emergency vehicles.
- The company has said that Autopilot and a more sophisticated "Full Self-Driving" system cannot drive themselves and that drivers must pay attention and be ready to react at any time. "Full Self-Driving" is being tested by hundreds of Tesla owners on public roads in the U.S.
- Bryant Walker Smith, a law professor at the University of South Carolina who studies automated vehicles, said this is the first U.S. case to his knowledge in which serious criminal charges were filed in a fatal crash involving a partially automated driver-assist system. Tesla, he said, could be "criminally, civilly or morally culpable" if it is found to have put a dangerous technology on the road.
- Donald Slavik, a Colorado lawyer who has served as a consultant in automotive technology lawsuits, including many against Tesla, said he, too, is unaware of any previous felony charges being filed against a U.S. driver who was using partially automated driver technology involved in a fatal crash.
The families of Lopez and Nieves-Lopez have sued Tesla and Riad in separate lawsuits.
They have alleged negligence by Riad and have accused Tesla of selling defective vehicles that can accelerate suddenly and that lack an effective automatic emergency braking system. A joint trial is scheduled for mid-2023.
- Lopez's family, in court documents, alleges that the car "suddenly and unintentionally accelerated to an excessive, unsafe and uncontrollable speed." Nieves-Lopez's family further asserts that Riad was an unsafe driver, with multiple moving infractions on his record, and couldn't handle the high-performance Tesla.
- Separately, NHTSA is investigating a dozen crashes in which a Tesla on Autopilot ran into several parked emergency vehicles. In the crashes under investigation, at least 17 people were injured and one person was killed.
- Asked about the manslaughter charges against Riad, the agency issued a statement saying there is no vehicle on sale that can drive itself. And whether or not a car is using a partially automated system, the agency said, "every vehicle requires the human driver to be in control at all times."
- NHTSA added that all state laws hold human drivers responsible for the operation of their vehicles. Though automated systems can help drivers avoid crashes, the agency said, the technology must be used responsibly.
- Rafaela Vasquez, the driver in the Uber autonomous test vehicle, was charged in 2020 with negligent homicide after the SUV fatally struck a pedestrian in suburban Phoenix in 2018. Vasquez has pleaded not guilty. Arizona prosecutors declined to file criminal charges against Uber.
- © Copyright 2022 The Associated Press. All Rights Reserved. This material may not be published, broadcast, rewritten or redistributed.
- First published on January 18, 2022 / 10:52 AM
- © 2022 CBS Broadcasting Inc. All Rights Reserved.
- ©2023 CBS Broadcasting Inc. All Rights Reserved.

URL: https://abc7.com/tesla-gardena-crash-driver/11873142/
- WATCH LIVE
- The driver of a Tesla operating on autopilot must stand trial for a crash that killed two people in Gardena, a judge ruled.
- GARDENA, Calif. (KABC) -- The driver of a Tesla operating on autopilot must stand trial for a crash that killed two people in Gardena, a judge ruled Thursday.
- There is enough evidence to try Kevin George Aziz Riad , 27, on two counts of vehicular manslaughter, a Los Angeles County judge said.
- A judge ruled Thursday that a trial can proceed against a Tesla Model S driver in a 2019 crash that left two people dead in Gardena.
- It is believed to be the first felony prosecution in the U.S. against a driver using a partially automated driving system.
- Police said the Tesla Model S left a freeway and ran a red light and was doing 74 mph when it smashed into a Honda Civic at an intersection on Dec. 29, 2019.
- Federal traffic safety agency investigating Tesla crash that killed 3 in Newport Beach
- 
- The crash killed Gilberto Alcazar Lopez, 40, of Rancho Dominguez and Maria Guadalupe Nieves-Lopez, 39, of Lynwood, who were in the Civic and were on their first date that night, relatives told the Orange County Register.
- Riad and a woman in the Tesla were hospitalized with non-life-threatening injuries.
- Prosecutors said the Tesla's Autosteer and Traffic Aware Cruise Control were active. A Tesla engineer testified that sensors indicated Riad had a hand on the steering wheel but crash data showed no brakes were applied in the six minutes before the crash.
- A police officer testified Thursday that several traffic signs warning motorists to slow down were posted near the end of the freeway.
- Tesla has said that Autopilot and a more sophisticated "Full Self-Driving" system cannot drive themselves and that drivers must pay attention and be ready to react at anytime.
- The misuse of Autopilot, which can control steering, speed and braking, has occurred on numerous occasions and is the subject of investigations by two federal agencies. The filing of charges in the California crash could serve notice to drivers who use systems like Autopilot that they cannot rely on them to control vehicles.
- WATCH: Dodgers fan damages Tesla in Echo Park
- 
- The criminal charges aren't the first involving an automated driving system, but they are the first to involve a widely used driver technology. Authorities in Arizona filed a charge of negligent homicide in 2020 against a driver Uber had hired to take part in the testing of a fully autonomous vehicle on public roads. The Uber vehicle, an SUV with the human backup driver on board, struck and killed a pedestrian.
- Meanwhile, the National Highway Traffic Safety Administration on Wednesday confirmed that it had sent a special crash investigation team to determine whether a Tesla involved in a May 12 crash in Newport Beach that killed three people was operating on a partially automated driving system.
- The Associated Press contributed to this report.
- State Farm will no longer insure new homes in California, company says
- LAUSD superintendent talks school programs, safety, enrollment, AI
- Driver arrested after plowing down beach, narrowly missing families

URL: https://www.theverge.com/2022/1/18/22889768/tesla-autopilot-criminal-charges-la-fatal-crash
- By  Andrew J. Hawkins, transportation editor with 10+ years of experience who covers EVs, public transportation, and aviation. His work has appeared in The New York Daily News and City & State.
- California prosecutors filed two felony charges against the owner of Tesla Model S for a deadly crash in 2019 that involved the vehicle’s Autopilot system, marking the first time that a Tesla owner has been criminally charged in the US in a case involving the automaker’s advanced driver assist system. The charges were first reported by the AP.
- According to the LA County District Attorney, the incident took place in Gardena, a suburb of LA, on December 29, 2019. Kevin George Aziz Riad, 27, was exiting a highway in his black Model S when he ran through a red light, slamming into a Honda Civic and killing two people.
- Riad, a limousine service driver, will now face two charges of vehicular manslaughter, according to charges filed with the California Superior Court. He is currently free on bail while the case is pending, according to the AP.
- Autopilot has come under increased scrutiny from federal regulators
- Autopilot, which can control steering and braking functions as well as perform automatic lane changes while on certain highways, has come under increased scrutiny from federal regulators. Last year, the National Highway Traffic Safety Administration opened an investigation into over a dozen incidents involving Tesla vehicles using Autopilot that have crashed into stationary emergency vehicles. Autopilot has contributed to a number of fatal crashes in the past, and the families of deceased drivers have sued Tesla for wrongful death.
- Tesla warns that drivers need to keep their eyes on the road and hands on the wheel at all times, though the automaker has declined to include a more robust driver-monitoring system (like infrared eye tracking, for example) to ensure its customers are following safety protocols. Autopilot is considered a Level 2 “partially automated” system by the Society of Automotive Engineers’ standards, which requires that drivers keep their hands on the wheel and eyes on the road.
- Some Tesla drivers have been caught misusing Autopilot, and some have even publicized the results themselves. Drivers have been found sleeping in the passenger seat or backseat of their vehicles while speeding down a crowded highway. A Canadian man was charged with reckless driving after being pulled over for sleeping while traveling at speeds of 93mph.
- The criminal charges document does not mention Autopilot. But NHTSA, which dispatched a team to investigate the crash in 2019, confirmed that the driver assist feature was active at the time of the incident. The agency plans on publishing its findings from the investigation soon.
- “NHTSA reminds the public that no commercially available motor vehicle today can drive itself,” a spokesperson said. “Whether a L2 automated driving system is engaged or not, every available vehicle requires the human driver to be in control at all times, and all State laws hold the human driver responsible for the operation of their vehicles.”
- / Sign up for Verge Deals to get deals on products we've tested sent to your inbox daily.
- The Verge is a vox media network
- © 2023 Vox Media, LLC. All Rights Reserved

URL: https://jalopnik.com/tesla-driver-on-trial-for-autopilot-crash-that-killed-t-1848955333
- A judge in California has ruled that the driver of a Tesla Model S on Autopilot involved in the deaths of two motorists must stand trail for manslaughter. This is the first felony prosecution in the U.S. against a driver using a partially-automated system, according to the Associated Press.
- It’s also the first case involving Autopilot, one of the most widely-available semi-autonomous systems on the market.
- State prosecutors believe there’s enough evidence to try Kevin George Aziz Riad, 27, on two felony counts of vehicular manslaughter, each carrying a prison sentence of up to six years in California. The prosecutors initially charged Riad in January of 2022, but it was unclear at that time whether the case would proceed to trial.
- The case dates back to December 29, 2019,  when Riad’s Tesla Model S exited a freeway in Gardena and ran a red light. The Tesla was doing 74 miles per hour through the intersection when it crashed into a Honda Civic.
- The Civic’s occupants, Gilberto Alcazar Lopez, 40, and Maria Guadalupe Nieves-Lopez, 39, died at the scene of the crash. Their relatives later told reporters the two were on their first date that night. Riad and an unidentified woman in the Tesla were hospitalized with non-life threatening injuries.
- State prosecutors said that two of Tesla’s automated systems were active at the time of the collision: Autosteer and Traffic Aware Cruise Control. A Tesla engineer testified that sensors in the Tesla Model S showed Riad had his hand on the steering wheel for several minutes up to the moment of impact — a safety measure required by Tesla to ensure the driver is engaged while Autopilot is active.
- Crash data showed that, while Riad had a hand on the wheel, he had not applied the brakes in the six minutes before the crash. A police officer testified that Riad drove past several traffic signs warning drivers to slow down as they exited the freeway.
- Tesla’s official reply in such cases is that Autopilot and its “Full Self-Driving” systems can’t drive themselves, so drivers have to be prepared to retake control of their cars at any time. But this admonition doesn’t fully come across in the way that Tesla’s CEO, Elon Musk, talks about so-called FSD.
- And the debate over fault and liability when partially-automated cars injure or kill people is still ongoing. It has prompted Congress and NHTSA to look into autonomous vehicle systems in the U.S., while lawmakers abroad try to agree on regulations, too.

URL: https://www.theguardian.com/technology/2022/nov/14/tesla-autopilot-landmark-case-man-v-machine
- Tesla’s autopilot faces criticism it contributes to accidents and deaths – but has technology advanced faster than legal standards?
- Tesla will play a major role in a manslaughter trial this week over a fatal crash caused by a vehicle operating on autopilot, in what could be a defining case for the self-driving car industry.
- At the trial’s heart is the question of who is legally responsible for a vehicle that can drive – or partially drive – itself.
- Kevin George Aziz Riad is on trial for his role in a 2019 crash. Police say Riad exited a freeway in southern California in a Tesla Model S, ran a red light and crashed into a Honda Civic, killing Gilberto Lopez and Maria Guadalupe Nieves-Lopez. Tesla’s autopilot system, which can control speed, braking and steering, was engaged at the time of the crash that killed the couple, who were on their first date.
- Tesla does not face charges in the case, but trial could shape public perceptions of the company and act as a test case for whether the technology has advanced faster than legal standards, experts say.
- “Who’s at fault, man or machine?” Edward Walters, an adjunct professor at the Georgetown University law school who specializes in the law governing self-driving cars. “The state will have a hard time proving the guilt of the human driver because some parts of the task are being handled by Tesla.”
- Riad’s lawyer has said that his client should not have been charged with a crime while prosecutors have argued Riad’s speeding and failure to brake were reckless.
- The trial comes as the electric carmaker faces growing scrutiny and criticism that its autopilot has made drivers inattentive and contributed to accidents and deaths. Elon Musk, the company cofounder, has said that Tesla is significantly more safe when used with its autopilot system, and has touted it as a step to fully autonomous driving.
- In September, Musk said he believed the company had a “moral obligation” to roll out what he describes as “full self-driving” software, even if it was not perfect and Tesla faced lawsuits, because doing so could save lives.
- But Tesla’s system has faced ongoing scrutiny and has been implicated in numerous collisions, some of them fatal. US federal regulators are currently investigating more than a dozen Tesla crashes into parked first responder vehicles over a period of four years, resulting in multiple injuries and one death.
- The US justice department is investigating whether Tesla itself should face criminal charges over its self-driving claims, Reuters reported, which experts have said could pose a challenge to prosecutors in the California trial.
- “The DoJ probe helps [Riad] because his claim is going to be ‘I relied on their advertising. Therefore, I was not aware of the risk there,’” said Robert Blecker, a criminal law professor at New York Law School.
- In addition to the criminal trial related to the crash, the family of Gilberto Lopez is suing Tesla in a trial scheduled for July.
- “I can’t say that the driver was not at fault, but the Tesla system, autopilot and Tesla spokespeople encourage drivers to be less attentive,” Donald Slavik, an attorney whose firm is representing Lopez’s family in a lawsuit against Tesla, told Reuters.
- Tesla understood the risks of its system but failed to manage those, Slavik said. “Tesla knows people are going to use autopilot and use it in dangerous situations,” he said.
- The ongoing legal and regulatory scrutiny of Tesla could shape perception of the company, which poses a risk as it looks to defend itself in coming lawsuits, said Bryant Walker Smith, a law professor at the University of South Carolina, who is also an adviser on new transportation technology.
- “The narrative of Tesla potentially shifts from this innovative tech company doing cool things to this company just mired in legal trouble. That is the risk, and narrative is very important in civil litigation because both sides tell a jury a story,” he said.

- Tesla Model Y crashes into parked police car
- Tesla Autopilot, FSD misleading marketing
- Page infoType: IncidentPublished: March 2023
