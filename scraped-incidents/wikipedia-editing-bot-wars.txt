- Wikipedia editing bot wars
- Occurred: February 2017
- Can you improve this page?Share your insights with us
- A research study discovered that bots used to try and keep Wikipedia accurate and relevant could be highly antagonistic, undoing each other's edits and engaging in 'fights' that could last for years.
- Oxford Internet Institute and the Alan Turing Institute researchers studied how bots interacted with each other in 13 language editions of the website from 2001 to 2010, leading to sometimes unpredictable consequences.
- They found that the actions of Wikipedia's bots varied according to their cultural environments, with Portuguese bots the most challenging, and German ones the most civilised. They also found that bots triggered edits later than human editors, and engaged in protracted conflicts. Some conflicts only ended when a bot was taken out of action.
- In many cases, the researchers reckoned, the bots came into conflict because they followed slightly different rules to one another, leading to questions about how they are designed and the effectiveness of Wikipedia's bot policy, which did not cover how bots interacted with each other.
- Operator: WikipediaDeveloper: Wikipedia
- Country: USA; Global
- Sector: Media/entertainment/sports/arts
- Purpose: Edit content
- Technology: Bot/intelligent agent Issue: Accuracy/reliability
- Transparency:
- Wikipedia website
- Wikipedia bot policy
- Tsvetkova M., García-Gavilanes R., Floridi L., Yasseri T. (2017). Even good bots fight: The case of Wikipedia
URL: https://www.theregister.com/2017/02/23/wiki_bots_love_online_conflict/

URL: https://www.theguardian.com/technology/2017/feb/23/wikipedia-bot-editing-war-study
- Over time, the encyclopedia’s software robots can become locked in combat, undoing each other’s edits and changing links, say researchers
- For many it is no more than the first port of call when a niggling question raises its head. Found on its pages are answers to mysteries from the fate of male anglerfish, the joys of dorodango, and the improbable death of Aeschylus.
- But beneath the surface of Wikipedia lies a murky world of enduring conflict. A new study from computer scientists has found that the online encyclopedia is a battleground where silent wars have raged for years.
- Since Wikipedia launched in 2001, its millions of articles have been ranged over by software robots, or simply “bots”, that are built to mend errors, add links to other pages, and perform other basic housekeeping tasks.
- In the early days, the bots were so rare they worked in isolation. But over time, the number deployed on the encyclopedia exploded with unexpected consequences. The more the bots came into contact with one another, the more they became locked in combat, undoing each other’s edits and changing the links they had added to other pages. Some conflicts only ended when one or other bot was taken out of action.
- “The fights between bots can be far more persistent than the ones we see between people,” said Taha Yasseri, who worked on the study at the Oxford Internet Institute. “Humans usually cool down after a few days, but the bots might continue for years.”
- The findings emerged from a study that looked at bot-on-bot conflict in the first ten years of Wikipedia’s existence. The researchers at Oxford and the Alan Turing Institute in London examined the editing histories of pages in 13 different language editions and recorded when bots undid other bots’ changes.
- They did not expect to find much. The bots are simple computer programs that are written to make the encyclopedia better. They are not intended to work against each other. “We had very low expectations to see anything interesting. When you think about them they are very boring,” said Yasseri. “The very fact that we saw a lot of conflict among bots was a big surprise to us. They are good bots, they are based on good intentions, and they are based on same open source technology.”
- While some conflicts mirrored those found in society, such as the best names to use for contested territories, others were more intriguing. Describing their research in a paper entitled Even Good Bots Fight in the journal Plos One, the scientists reveal that among the most contested articles were pages on former president of Pakistan Pervez Musharraf, the Arabic language, Niels Bohr and Arnold Schwarzenegger.
- One of the most intense battles played out between Xqbot and Darknessbot which fought over 3,629 different articles between 2009 and 2010. Over the period, Xqbot undid more than 2,000 edits made by Darknessbot, with Darknessbot retaliating by undoing more than 1,700 of Xqbot’s changes. The two clashed over pages on all sorts of topics, from Alexander of Greece and Banqiao district in Taiwan to Aston Villa football club.
- Another bot named after Tachikoma, the artificial intelligence in the Japanese science fiction series Ghost in the Shell, had a two year running battle with Russbot. The two undid more than a thousand edits by the other on more than 3,000 articles ranging from Hillary Clinton’s 2008 presidential campaign to the demography of the UK.
- The study found striking differences in the bot wars that played out on the various language editions of Wikipedia. German editions had the fewest bot fights, with bots undoing other’s edits on average only 24 times in a decade. But the story was different on the Portuguese Wikipedia, where bots undid the work of other bots on average 185 times in ten years. The English version saw bots meddling with each other’s changes on average 105 times a decade.
- The findings show that even simple algorithms that are let loose on the internet can interact in unpredictable ways. In many cases, the bots came into conflict because they followed slightly different rules to one another.
- Yasseri believes the work serves as an early warning to companies developing bots and more powerful artificial intelligence (AI) tools. An AI that works well in the lab might behave unpredictably in the wild. “Take self-driving cars. A very simple thing that’s often overlooked is that these will be used in different cultures and environments,” said Yasseri. “An automated car will behave differently on the German autobahn to how it will on the roads in Italy. The regulations are different, the laws are different, and the driving culture is very different,” he said.
- As more decisions, options and services come to depend on bots working properly together, harmonious cooperation will become increasingly important. As the authors note in their latest study: “We know very little about the life and evolution of our digital minions.”
- Earlier this month, researchers at Google’s DeepMind set AIs against one another to see if they would cooperate or fight. When the AIs were released on an apple-collecting game, the scientists found that the AIs cooperated while apples were plentiful, but as soon as supplies got short, they turned nasty. It is not the first time that AIs have run into trouble. In 2011, scientists in the US recorded a conversation between two chatbots. They bickered from the start and ended up arguing about God.
- Hod Lipson, director of the Creative Machines Lab at Columbia University in New York, said the work was a “fascinating example of the complex and unpredictable behaviours that emerge when AI systems interact with each other.”
- “Often people are concerned about what AI systems will ultimately do to people,” he said. “But what this and similar work suggests is that what AI systems might do to each other might be far more interesting. And this isn’t just limited to software systems – it’s true also for physically embodied AI. Imagine ACLU drones watching over police drones, and vice versa. It’s going to be interesting.”

URL: https://www.huffingtonpost.com.au/2017/02/27/automated-wikipedia-edit-bots-have-been-fighting-each-other-for_a_21722577/
- Associate Editor, HuffPost Australia
- It turns out Wikipedia's automated edit 'bots' have been waging a cyber-war between each other for over a decade by changing each other's corrections -- and it's getting worse.
- Researchers at the University of Oxford in the United Kingdom released a report on Thursday that shows that bot software studied between 2001 and 2010 -- which is designed to "undo vandalism, enforce bans, check spelling, create inter-language links... [and] identify copyright violations," has been reverting changes made by other Wikipedia-created-bots far more often than those made by humans.
- "We find that, although Wikipedia bots are intended to support the encyclopedia, they often undo each other's edits and these sterile 'fights' may sometimes continue for years," the study reads.
- "Unlike humans on Wikipedia, bots' interactions tend to occur over longer periods of time and to be more reciprocated."
- The research covers bots from all 13 language versions of Wikipedia from the first ten years of the website's operation. It found that, since 2001, the frequency of bots reverting changes made by another bot has been consistently increasing -- although it does depend on the language.
- "Over the ten-year period, bots on English Wikipedia reverted another bot on average 105 times," the report reads.
- "Bots on German Wikipedia revert each other to a much lesser extent than other bots (24 times on average). Bots on Portuguese Wikipedia, in contrast, fight the most, with an average of 185 bot-bot reverts per bot."
- @NoraReed You have no idea how happy reading this has made me. I used to be an editor on wikipedia but gave up because of the bots.
- — Rachel Wülfe (@AberdorkUnited) February 26, 2017
- Researchers also found that, compared to humans who make edits on Wikipedia pages, bots tend to take a lot longer to revert another bot's changes and are more likely to match the change a previous bot has applied.
- In other words, if one bot edits a post, another bot will be likely to change it back to exactly what it was before -- even if it takes them a while.
- Think of it as an online form of bickering between two robots that has actually lasted for more than 10 years.
- So which particular bots have been responsible for the disagreements?
- According to the findings, bots can be split into two groups -- benevolent and malevolent. Benevolent bots are the good-guys of Wikipedia who help users find what they need and make their online visit easier. Malevolent bots are the ones that counteract incorrect human edits or website violations.
- Although as it turns out, on Wikipedia even the good guys create problems.
- "We found that most of the disagreement occurs between bots that specialise in creating and modifying links between different language editions of the encyclopedia," researchers said.
- "The same bots are responsible for the majority of reverts in all the language editions we study. For example, some of the bots that revert the most other bots include Xqbot, EmausBot, SieBot, and VolkovBot, all bots specialising in fixing inter-wiki links.
- "In the case of Wikipedia, we see that benevolent bots that are designed to collaborate may end up in continuous disagreement. This is both inefficient as a waste of resources, and inefficacious."
- Time to ban bots from Wikipedia I guess... https://t.co/C5u91pbwfr
- — S Collis (@NomisSilloc) February 26, 2017
- Of the worst cases, Xqbot and Darknessbot managed to clash on 3629 different Wikipedia articles within a year, while the Japanese Tachikoma bot knocked heads with Russbot on more than 3000 articles over two years, according to the Guardian.
- The results of the report work as a stark reminder that even the simplest of website algorithms can react unpredictably -- and before you know it, you're ten years into an endless spell check battle.
- Looks like it could be back to the drawing board for Wikipedia.
- Associate Editor, HuffPost Australia

URL: https://www.wired.com/2017/03/internet-bots-fight-theyre-human/
- To revist this article, visit My Profile, then View saved stories.
- To revist this article, visit My Profile, then View saved stories.
- Matt Simon
- No one saw the crisis coming: a coordinated vandalistic effort to insert Squidward references into articles totally unrelated to Squidward. In 2006, Wikipedia was really starting to get going, and really couldn’t afford to have any SpongeBob SquarePants-related high jinks sullying the site's growing reputation. It was an embarrassment. Someone had to stop Squidward.
- The Wikipedia community knew it couldn’t possibly mobilize human editors to face down the trolls—the onslaught was too great, the work too tedious. So instead an admin cobbled together a bot that automatically flagged errant insertions of the Cephalopod Who Shall Not Be Named. And it worked. Wikipedia beat back the Squidward threat, and in so doing fell into a powerful alliance with the bots. Today, hundreds of algorithmic assistants fight all manner of vandals, fix typos, and even create articles on their own. Wikipedia would be a mess without them.
- But a funny thing happens when you lock a bunch of bots in a virtual room: Sometimes they don’t get along. Sometimes a pair of bots will descend into a slapfight, overwriting each other’s decisions thousands of times for years on end. According to a new study in PLOS ONE, it happens a lot. Why? Because no matter how cold and calculating bots may seem, they tend to act all too human. And these are the internet's nice, not-at-all racist bots. Imagine AI-powered personal digital assistants in the same room yelling at each other all day. Google Home versus Alexa, anyone?
- On Wikipedia, bots handle the excruciatingly dull and monotonous work that would drive an army of human editors mad---if an army of editors could even keep up with all the work. A bot does not tire. It does not get angry—well, at least not at humans. It’s programmed for a task, and it sees to that task with a consistency and devotion humans can’t match.
- While disagreements between human Wikipedia editors tend to fizzle, fights between bots can drag on for months or years. The study found that bots are far more likely to argue than human editors on the English version of Wikipedia: Bots each overrode another bot an average of 105 times over the course of a decade, compared to an average of three times for human editors. Bots get carried away because they simply don't know any better---they're just bits of code, after all.
- But that doesn't mean they aren't trustworthy. Bots are handling relatively simple tasks like spellchecking, not making larger editorial decisions. Indeed, it's only because of the bots' work that human editors can concentrate on those big-picture problems at all. Still, when they disagree, they don't rationally debate like humans might. They're servants to their code. And their sheer reach---continuously scanning more than 5 million articles in the English Wikipedia alone---means they find plenty of problems to correct and potentially disagree on.
- And bots do far more than their fair share of work. The number of human editors on the English Wikipedia may dwarf the number of bots—some 30,000 active meatspace editors versus about 300 active editors made purely out of code---but the bots are insanely productive contributors. “They're not even quite visible if you put them on a map among other editors,” says the University of Oxford’s Taha Yasseri, a co-author of the study. “But they do a lot. The proportion of all the edits done by robots in different languages would vary from 10 percent, up to 40 even 50 percent in certain language editions.” Yet Wikipedia hasn’t descended into a bloody bot battlefield. That’s because humans closely monitor the bots, which do far more good than harm.
- But bots inevitably collide, Yasseri contends. For example, the study found that over the course of three years, two bots that monitor for double redirects on Wikipedia had themselves quite the tiff. (A redirect happens when, for instance, a search for "UK" forwards you to the article for "United Kingdom." A double redirect is a redirect that forwards to another redirect, a big Wikipedia no-no.) Across some 1,800 articles, Scepbot reverted RussBot’s edits a total of 1,031 times, while RussBot returned the favor 906 times. This happens because of discrepancies in naming conventions---RussBot, for instance, made "Ricotta al forno" redirect to "Ricotta cheese," when previously it redirected to "Ricotta." Then Scepbot came in and reverted that change.
- For its part, Wikipedia disputes that these bots aren't really "fighting."
- WIRED Staff
- Angela Watercutter
- Jennifer M. Wood
- Chris Stokel-Walker
- "If, for example, Scepbot had performed the original double-redirect cleanup and RussBot performed the second double-redirect cleanup, then it would appear that they are 'reverting' each other," says Aaron Halfaker, principal research scientist at the Wikimedia Foundation. "But in reality, the bots are collaborating together to keep the redirect graph of the wiki clean."
- 'We're perfectly aware of which bots are running right now.'
- Aaron Halfaker, Wikimedia Foundation
- Still, Halfaker acknowledges that bots reverting each other can look like conflict. “Say for example you might have an editor that wants to make sure that all the English language lists on Wikipedia use the Oxford comma, and another editor believes that we should not use the Oxford comma.” (Full disclosure: This writer believes the Oxford comma is essential and that anyone who doesn’t use it is a barbarian.) But Wikipedia has a bot approval process to catch these sorts of things. “We're perfectly aware of which bots are running right now,” he says.
- Also, Wikipedians are at all times monitoring their bots. “People often imagine them as fully autonomous Terminator AI that are kind of floating through the Wikipedia ether and making all these autonomous decisions,” says R. Stuart Geiger, a UC Berkeley data scientist who’s worked with Wikipedia bots. “But for the most part a lot of these bots are relatively simple scripts that a human writes.”
- A human. Always a human. A bot expresses human ingenuity and human mistakes. The bot and its creator are, in an intimate sense, a hybrid organism. “Whenever you read about a bot in Wikipedia, think of that as a human,” says Geiger. “A human who's got a computer that they never turn off, and they've got a power tool running on that computer that they can tweak the knobs, they can fiddle the words, they can say they want to replace X with Y.”
- On the all-too-human front, Yasseri’s study also found cultural differences among the bot communities of different Wikipedia languages. “That was really interesting, because this is the same technology being used just in different environments, and being used by different people,” says Yasseri. “Why should that lead to a big difference?” Bots in the German Wikipedia, for instance, argue relatively infrequently, while Portuguese took the prize for most contentious.
- Those differences may seem trivial, but such insight has profound implications as AI burrows deeper and deeper into human society. Imagine how a self-driving car that’s adapted to the insanity of the German Autobahn might interact with a self-driving car that’s adapted to the relative calm of Portugal’s roadways. The AI inside each has to make nice or risk killing the occupants. So the different ways bots interact on different versions of Wikipedia could foretell how AI-powered machines get along---or don’t---in the near future.
- And imagine that AI elsewhere on the internet like Twitter makes its way into machines. Bots that spew fake news, that imitate Donald Trump, that harass Trump supporters. Unlike the benevolent bots of Wikipedia, these fool humans into thinking they're actually people. If you think Wikipedia bots squabbling is problematic, imagine machines with heads full of malevolent AI doing battle.
- For now, though, the many bots of Wikipedia collaborate, clash, and keep Squidward in his place.
- David Nield
- Paresh Dave
- Demetrios Ioannou
- Vittoria Elliott
- Grace Browne
- Lauren Goode
- Justin Ling
- Chris Stokel-Walker
- More From WIRED
- Contact
- © 2023 Condé Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices

URL: https://gizmodo.com/bots-on-wikipedia-wage-edit-wars-between-themselves-tha-1792680922
- Revision wars on Wikipedia amongst human editors is an all-too-common occurrence, but new research from the UK shows that similar online battles are being waged between the site’s software robots.
- As a new study published in PLOS ONE reveals, Wikipedia’s bots don’t always get along, frequently undoing each other’s edits. These online algorithms, each equipped with their own instructions and goals, engage in sterile “fights” over content that can persist for years. The new research shows how relatively “dumb” bots can produce complex interactions and behaviors, and how developers need to stay on top of their digital creations. This has implications not just for the quality of Wikipedia pages, but for the development of AI in general—particularly any autonomous agents set loose on the web.
- Incomprehensible computer behaviors have evolved out of high-frequency stock trading, and humans…
- There are currently 41,517,866 pages in the English version of Wikipedia. That’s a ton of content—far more than the site’s human editors are able to handle. To help maintain this gargantuan open-source encyclopedia, thousands of software bots sift through the site, performing such menial and repetitive tasks as deleting vandalism, enforcing bans, correcting bad spelling, creating links, and automatically importing content.
- Overall, bots represent just 0.1 percent of Wikipedia editors, but they stand behind a significant proportion of sites’s edits. Unfortunately, the software developers who create the bots don’t really understand or account for how bots interact with each other. Like the nature of Wikipedia itself, the creation of bots is a decentralized process, with individual contributors developing their own scripts. An approvals group exists, but its members are going strictly by Wikipedia’s bot policy, which doesn’t take bot-on-bot interactions into consideration.
- Indeed, every once in a while, a bot makes a certain to change to a page that another bot tries to undo. Each bot is designed and dispatched to perform a specific task, but sometimes, tasks can run into conflict with those of another bot. Unlike human editors, the bots can’t negotiate with each other, and like the good automatons that they are, they simply do as they’re programmed. Once these bots have been unleashed into the abyss that is Wikipedia, their human developers are largely oblivious to the ensuing bot interactions.
- To understand the degree to which bot fights disrupt Wikipedia, computer scientists from the Oxford Internet Institute and the Alan Turing Institute studied how these algorithms interacted across 13 different language editions of the website over a ten year period (2001 to 2010). By tracking the edits made to each page, and ensuring that no human editors were involved, the researchers were able to observe how the bots interacted with each other, and how their encounters often led to unpredictable consequences.
- Interestingly, the actions of the site’s bots varied according to their distinct cultural environments.
- “This has implications not only for how we design artificial agents but also for how we study them,” said the study’s lead author Milena Tsvetkova in a statement. “We need more research into the sociology of bots.”
- Overall, bots undid each other’s work a lot. The bots on the Portuguese version of Wikipedia were the most antagonistic, reverting the work of other bots 185 times over the ten year period, on average. At the English site, the researchers recorded an average of 105 revisions made by a bot on another bot’s work over the same period (that’s about three times the rate of human edits). The German bots were the most civil, making an average of just 24 reversion edits over a decade. These disparities in editing coordination may be due to different language editions having slightly different naming rules and conventions.
- The bots also behaved differently than human editors, triggering edits much later than human editors, and engaging in protracted conflicts. Humans, because they’re prompted about changes to a page by auto-alerts, tend to make any fixes within minutes, and then move on to the next thing. But the Wikipedia bots typically made their first revision about a month after the initial revision, then persisting in a back-and-forth for years at a time. These edit wars aren’t catastrophic, but given the constant stream of changes, it could confuse people who read the site.
- Bots are slower than humans  (and clearly more persistent!) with respect to revisions, because they “crawl” over web articles in search of edits (rather than receiving alerts), and they’re often restricted in terms of the number of edits allowed over an allotted period of time. But the fact that bots are able to continue these battles for so long is a strong indication that human programmers are failing to catch potential editing problems early enough.
- Importantly, many of these bot-on-bot conflicts stopped at the beginning of 2013, when Wikipedia make some changes to the way that inter-language links work on the site. That said, the researchers say this episode in Wikipedia’s history shows that a system of simple bots can produce complex dynamics and unintended consequences. Looking further ahead, it’s a potential portent of things to come as new and more complex “botosopheres” emerge around the web. It’s a worrying sign that conflict can emerge so easily and quickly within digital ecosystems.
- What will happen in the days after the birth of the first true artificial intelligence? If things…
- In particular, the observation that a single piece of technology can yield different outcomes depending on the cultural environment has implications for artificial intelligence research. Understanding what affects bot-on-bot interactions, the researchers say, will be crucial for any autonomous process, from managing social media to tracking cyber-security to developing self-driving vehicles.
- “An automated vehicle will drive differently on a German autobahn to how it will through the Tuscan hills of Italy,” noted study co-author Taha Yasseri. “Similarly, the local online infrastructure that bots inhabit will have some bearing on how they behave and their performance.”
- Yasseri says that bots on Wikipedia are designed by humans from different countries, which can lead to online clashes. “We see differences in the technology used in the different Wikipedia language editions and the different cultures of the communities of Wikipedia editors involved create complicated interactions,” he says. “This complexity is a fundamental feature that needs to be considered in any conversation related to automation and artificial intelligence.”
- As already mentioned, Wikipedia does enforce a bot policy. Bots, Wikipedia says:
- are potentially capable of editing far faster than humans can; and have a lower level of scrutiny on each edit than a human editor; and may cause severe disruption if they malfunction or are misused.
- To prevent potential problems, developers must make sure that Wikipedia’s bots only perform tasks for which there is consensus, and that they adhere to the site’s policies and guidelines, among other restrictions. But as this new study shows, bots also need to be programmed to work amongst themselves.
- [PLOS ONE]

URL: https://www.mentalfloss.com/article/92612/wikipedia-bots-wage-editing-wars-last-years
- Since it launched in 2001, Wikipedia has attracted passionate contributors disputing everything from the height of André the Giant to the spelling of "Brazil." According to a new study published in PLOS One [PDF], artificially intelligent bots make up the site’s most relentless editors. Editing battles between software bots have raged on for years, and sometimes they only end when one party is taken out of commission, The Guardian reports.
- For the study, computer scientists from the Oxford Internet Institute and the Alan Turing Institute in London examined bot interactions during Wikipedia’s first decade online. Editing bots have been a vital part of the site’s maintenance since its inception. Every day thousands of bots remove vandalism, correct spelling errors, add links, and complete other general tasks beyond what humans can do alone, and sometimes they cross paths.
- When two algorithms contradict one another, they can go on undoing each other's edits for years. Between 2009 and 2010, Xqbot and Darknessbot duked it out over 3629 separate articles. A different battle between the bot Tachikoma and Russbot lasted two years. In that time they changed over 1000 revisions the other had made. Subjects of contention between the two included Hillary Clinton’s 2008 presidential campaign and the UK's demographics. The pages that sparked the most bot-on-bot conflict overall were those for former Pakistan president Pervez Musharraf, Nobel Prize-winning physicist Niels Bohr, Arnold Schwarzenegger, and the Arabic language.
- Language also played a large role in the automated edit wars. Portuguese bots were the most combative, reverting the edits of their peers an average of 185 times in 10 years. German bots, on the other hand, only picked editorial fights an average of 24 times over the decade. Bots don’t give in as easily as human editors do, and they also engage in slower battles. People receive instant alerts when someone reverts their edits, while it usually takes bots about a month to see a change that has been made.
- Programming AI systems to interact with each other is becoming increasingly important. In January, we got a fascinating peek at what a conversation between two Google Home devices looks like. They were much more civil than the Wikipedia bots—they discussed God, their existence, and eventually made plans to get married.
- [h/t The Guardian]
- © 2023 Minute Media - All Rights Reserved

URL: https://www.skeptical-science.com/science/wikipedia-bot-wars/
- Skeptical Science
- Promoting Science and Critical Thinking
- 
- There have been a few media stories about editing bots battling it out on Wikipedia and so I wondered what the alpha source for this was. It turns out that it all stems from a paper published within the Open Access Journal Plus One.
- Even good bots fight: The case of Wikipedia
- The published paper describes it all in great detail and so it is worth digging into.
- First, start be reading the following general introduction. It comes from the paper and takes you step-by-step into the world of bots. If you have no idea what a bot actually is, then investing a few minutes reading their description might help demystify it all for you …
- A bot, or software agent, is a computer program that is persistent, autonomous, and reactive [2,3]. Bots are defined by programming code that runs continuously and can be activated by itself. They make and execute decisions without human intervention and perceive and adapt to the context they operate in. Internet bots, also known as web bots, are bots that run over the Internet. They appeared and proliferated soon after the creation of the World Wide Web [4]. Already in 1993, Martijn Koster published “Guidelines to robot writers,” which contained suggestions about developing web crawlers [5], a kind of bot. Eggdrop, one of the first known Internet Relay Chat bots, started greeting chat newcomers also in 1993 [6]. In 1996, Fah-Chun Cheong published a 413-page book, claiming to have a current listing of all bots available on the Internet at that point in time. Since then, Internet bots have proliferated and diversified well beyond our ability to record them in an exhaustive list [7,8]. As a result, bots have been responsible for an increasingly larger proportion of activities on the Web. For example, one study found that 25% of all messages on Yahoo! chat over a period of three months in 2007 were sent by spam bots [9]. Another study discovered that 32% of all tweets made by the most active Twitter users in 2009 were generated by bots [10], meaning that bots were responsible for an estimated 24% of all tweets [11]. Further, researchers estimated that bots comprise between 4% and 7% of the avatars on the virtual world Second Life in 2009 [12]. A media analytics company found that 54% of the online ads shown in thousands of ad campaigns in 2012 and 2013 were viewed by bots, rather than humans [13]. According to an online security company, bots accounted for 48.5% of website visits in 2015 [14]. Also in 2015, 100,000 accounts on the multi-player online game World of Warcraft (about 1% of all accounts) were banned for using bots [15]. And in the same year, a database leak revealed that more than 70,000 “female” bots sent more than 20 million messages on the cheater dating site Ashley Madison [16].
- As the population of bots active on the Internet 24/7 is growing fast, their interactions are equally intensifying. An increasing number of decisions, options, choices, and services depend now on bots working properly, efficaciously, and successfully. Yet, we know very little about the life and evolution of our digital minions. In particular, predicting how bots’ interactions will evolve and play out even when they rely on very simple algorithms is already challenging. Furthermore, as Alan and Sruthi demonstrated, even if bots are designed to collaborate, conflict may occur inadvertently. Clearly, it is crucial to understand what could affect bot-bot interactions in order to design cooperative bots that can manage disagreement, avoid unproductive conflict, and fulfill their tasks in ways that are socially and ethically acceptable.
- There are many types of Internet bots (see Table 1). These bots form an increasingly complex system of social interactions. Do bots interact with each other in ways that are comparable to how we humans interact with each other? Bots are predictable automatons that do not have the capacity for emotions, meaning-making, creativity, and sociality [17]. Despite recent advances in the field of Artificial Intelligence, the idea that bots can have morality and culture is still far from reality. Today, it is natural to expect interactions between bots to be relatively predictable and uneventful, lacking the spontaneity and complexity of human social interactions. However, even in such simple contexts, our research shows that there may be more similarities between bots and humans than one may expect. Focusing on one particular human-bot community, we find that conflict emerges even among benevolent bots that are designed to benefit their environment and not fight each other, and that bot interactions may differ when they occur in environments influenced by different human cultures.
- Benevolent bots are designed to support human users or cooperate with them. Malevolent bots are designed to exploit human users and compete negatively with them. We have classified high-frequency trading algorithms as malevolent because they exploit markets in ways that increase volatility and precipitate flash crashes.
- As you might now anticipate, the goal is to design bits of code that trawls through pages fixing stuff and adding links where appropriate in an automated manner. They describe the precise scope of their study as follows …
- We study bots on Wikipedia, the largest free online encyclopedia. Bots on Wikipedia are computer scripts that automatically handle repetitive and mundane tasks to develop, improve, and maintain the encyclopedia. They are easy to identify because they operate from dedicated user accounts that have been flagged and officially approved. Approval requires that the bot follows Wikipedia’s bot policy.
- Bots are important contributors to Wikipedia. For example, in 2014, bots completed about 15% of the edits on all language editions of the encyclopedia [18]. In general, Wikipedia bots complete a variety of activities. They identify and undo vandalism, enforce bans, check spelling, create inter-language links, import content automatically, mine data, identify copyright violations, greet newcomers, and so on [19]. Our analysis here focuses on editing bots, which modify articles directly. We analyze the interactions between bots and investigate the extent to which they resemble interactions between humans. In particular, we focus on whether bots disagree with each other, how the dynamics of disagreement differ for bots versus humans, and whether there are differences between bots operating in different language editions of Wikipedia.
- Knowing the above now makes it easy to see what the study is all about.
- Once they had the above raw information, it was then possible to filter out human editors and so they proceeded to analyse bot interactions.
- One Point to note: The data they analysed was for edits within all 13 different language editions of Wikipedia in the first ten years after the encyclopedia was launched (2001–2010), so it does not cover what has been happening on-line since then.
- Bot authors, with the best best intentions, crafted bots to perform a specific task and then set them running. What then happened was a completely unintended consequence that had not been foreseen by the bot authors.
- Key Lesson: a system of simple bots may produce complex dynamics with unintended consequences.
- People build artificial intelligent systems in complete isolation. Once released into the wild, interaction with other systems is inevitable.
- One example is the self-driving car.
- You might want to avoid being a pioneer, because there may be unintended consequences …
- “Take self-driving cars. A very simple thing that’s often overlooked is that these will be used in different cultures and environments. An automated car will behave differently on the German autobahn to how it will on the roads in Italy. The regulations are different, the laws are different, and the driving culture is very different,”  – Taha Yasseri, one of the study authors
- “The fights between bots can be far more persistent than the ones we see between people. Humans usually cool down after a few days, but the bots might continue for years.
- We had very low expectations to see anything interesting. When you think about them they are very boring. The very fact that we saw a lot of conflict among bots was a big surprise to us” – Taha Yasseri, one of the study authors
- Enter your email address to subscribe to this blog and receive notifications of new posts by email.
- Email Address
- Subscribe

- Microsoft Tay chatbot
- BlenderBot conversational chatbot
- Page infoType: IncidentPublished: April 2023
