- UCLA facial recognition surveillance
- Occurred: February 2020
- Can you improve this page?Share your insights with us
- University of California, Los Angeles (UCLA) has abandoned plans to install facial recognition after a backlash from students and others concerned about its potential for discrimination, surveillance, and impact on privacy.
- UCLA had announced (pdf) in September 2018 that it was planning to introduce facial recognition in order to improve campus safety and centralise campus security camera systems and give university police access to footage during emergencies.
- The move resulted in a backlash from students and a campaign by digital rights advocacy group Fight for the Future, which used Amazon's facial recognition software Rekognition on UCLA sportspeople amnd faculty to demonstrate the technology's capacity for delivering false matches.
- Backing down from the plan, UCLA  Administrative Vice Chancellor Michael Beck said, 'the potential benefits are limited and are vastly outweighed by the concerns of the campus community.' UCLA would have been the first university in the US to adopt facial recognition.
- Operator: UCLA Developer: Unclear/unknownCountry: USASector: EducationPurpose: Strengthen security; Increase safety Technology: Facial recognition Issue: Bias/disrimination - race, ethnicity; Effectiveness/value; Privacy; Surveillance Transparency: Governance
- UCLA Policy 133: Security Camera Systems DRAFT for Public Review (pdf)
- Fight for the Future (2020). Backlash forces UCLA to abandon plans for facial recognition surveillance on campus
- Fight for the Future (2020). Letter from 40+ civil society organizations: ban facial recognition on college campuses
- Daily Bruin Editorial Board (2020). Implementing facial recognition tech would be a violation of students’ privacy
URL: https://www.vice.com/en_us/article/z3by79/ucla-abandons-plans-to-use-facial-recognition-after-backlash
- Ahead of a national day of action led by digital rights group Fight for the Future, UCLA has abandoned its plans to become the first university in the United States to adopt facial recognition technology.
- In a statement shared with Fight for the Future's Deputy Director Evan Greer, UCLA’s Administrative Vice Chancellor Michael Beck said the university "determined that the potential benefits are limited and are vastly outweighed by the concerns of the campus community."
- Since last year, UCLA has been considering using the university's security cameras to implement a facial recognition surveillance system. These plans have been dogged by student criticism, culminating in an editorial in the Daily Bruin, UCLA’s student newspaper, that argued the system would "present a major breach of students' privacy" while creating "a more hostile campus environment" by "collecting invasive amounts of data on [UCLA's] population of over 45,000 students and 50,000 employees.”
- In an attempt to highlight the risks of using facial recognition on UCLA's campus, Fight for the Future used Amazon's facial recognition software, Rekognition, to scan public photos of UCLA's athletes and faculty, then compare the photos to a mugshot database. Over 400 photos were scanned, 58 of which were false positives for mugshot images—the software often gave back matches with "100% confidence" for individuals "who had almost nothing in common beyond their race"
- These results square with what we have witnessed time and time again—that predictive algorithms are fundamentally riddled with racial and gender bias. Whether it’s the federal government’s own National Institute of Standards and Technology examining facial recognition algorithms, independent researchers looking at healthcare algorithms, or lawmakers raising the alarm about discrimination via housing algorithms, the outcomes are so bad that even members of Congress are proposing to ban the technology.
- "UCLA thought they could get away with this. They even claimed our campaign was misinformation. When we made it clear we weren't going to back down, they folded like a tent,” Greer told Motherboard. “Let this be a lesson to other school administrators: if you try to experiment on your campus with racist, invasive surveillance technology, we will come for you. And we don't lose."

URL: https://dailybruin.com/2018/10/12/student-leaders-spy-breaches-of-privacy-in-new-ucla-security-camera-policy/
- At the town hall, students brought up concerns including funding, privacy violations, access to resources and the timing of the policy’s announcement. (Amy Dixon/Photo editor)
- Students expressed concerns at a Wednesday town hall that a new security camera policy would increase breaches of privacy.
- UCLA Policy 133, which was announced Sept. 11, outlines new procedures for security cameras on campus. The policy aims to improve campus safety by centralizing security camera data storage, providing UCPD with access to camera data in emergencies and establishing maintenance standards for cameras, said Ricardo Vazquez, a UCLA spokesperson.
- Vazquez added there are already more than 2,500 cameras across the campus, but only about 12 were visible to UCPD.
- Oscar Macias, a fourth-year Latin American studies and sociology student who organized the event, said he has worked with students from heavily policed neighborhoods and understands that more cameras on campus may not be beneficial.
- “Students should be educated about the gray areas within policy that might cause problems for certain student populations,” Macias said.
- At the town hall, students brought up concerns including funding, privacy violations, access to resources and the timing of the policy’s announcement.
- Richard White, a fourth-year political science student, said he was concerned students would end up paying for security camera updates.
- “UCLA hardly ever foots the bill for anything that they institutionalize on this campus,” White said. “A lot of it – most of it – comes out of students’ pockets.”
- Vazquez said it was unclear how costs might expand due to the policy.
- “It is unclear how costs for students would be impacted,” Vazquez said. “Although as camera use expands, that will add cost to whichever department deploys the cameras, but those costs would have occurred regardless of the policy.”
- Vazquez did not further specify how camera use would expand.
- Alexander Yessayantz, who graduated in 2018, said he thinks mass surveillance in private areas is unnecessary and could be misused.
- “Once you build the cameras, even if the policies right now are very reassuring, they’re totally subject to change over time, but the infrastructure will still be there,” Yessayantz said. “The physical cameras will still be there and they can be misused.”
- Macias and other students at the event said they were concerned the policy would deter students from seeking out resources offered at the Student Activities Center, including resources for LGBTQ or undocumented students. They said these students or their families could be outed or put in danger for their sexuality or legal status if they were identified on camera.
- White added he felt it was disrespectful that UCLA announced the policy to students before classes were in session because new students and working students do not have time to thoroughly read through policy.
- Paula Gonzales, a third-year sociology student, said she thinks students should be making decisions about policies that affect them.
- Nidirah Stephens, the Academic Affairs commissioner for the Undergraduate Students Association Council, said the policy was originally created in response to hate crimes against former council members. Last year, a Jewish door ornament and pride flag were vandalized in Kerckhoff Hall.
- After listening to student comments, Stephens said she thought the town hall was productive because it showed how the policy could diverge from its original intentions.
- “We were able to understand the overreach that happened with this policy, that was almost independent of the intention of what it was supposed to be,” Stephens said. “And I think unless there’s terms and stipulations to which the students … can agree, then it shouldn’t happen.”
- Salvador Martinez, a third-year applied mathematics student who moderated the town hall, said he understood the good intentions behind the bill, but added cameras were not making people feel safer.
- “I do understand the good intentions behind the policy itself to make students on campus feel safer,” Martinez said. “But at the end of the day, we can really tell, just by the town hall, there was somewhat tension, somewhat fear of these cameras being turned into a police state, Big Brother initiative.”
- Kayla Thomas, a fourth-year molecular, cell and developmental biology student, said she thinks hate crimes could be better prevented through institutional support rather than surveillance.
- “Why doesn’t the institution institutionalize events put on by people of color, put on by LGBT students and empowering those students who are often victims of these crimes?” Thomas said. “And only then when UCLA proudly represents those students and shows the world that we are watching out for those students and empowering then hate crimes, I feel, will decrease.”
- Mick Deluca, the assistant vice chancellor of campus life, attended the town hall and said student voices are important.
- “I think a student’s voice is critical to the campus and how we make decisions and I’m here tonight just to listen,” Deluca said.
- Macias said he hoped student input from the town hall will affect the way administrators view the policy.
- “Hopefully they’ll take into consideration concerns students have,” Macias said. “It’s a draft, so there’s time to modify anything students might have concerns about.”
- The public comment period for the bill ends Monday.
- When asked if UCLA administration should consider the student input from the town hall, Stephens offered two words.
- “They better.”
- 1bedroom1bath with adjoining patio, furnished, all utilities paid including private security, UCLA adjacent, extreme privacy. Available May 1st. $1300/mo. Male preferred. 310-488-9061
- Spacious 2 and 3 bed Apts. 414-424 Landfair Ave Starting at $3595 Call Shakira 310-270-0199
- 1 & 2 BEDROOM APARTMENTS FOR RENT! Starting at $2,400, parking, close to UCLA/UCLA Medical Center (0.5 miles), Westwood Village, laundry facility, swimming pool. Pre-leasing NOW. Call 310.208.3797. liveatstrathmoreveteran.com
- Part time retail in Culver City. $16/hour. Please email [email protected] for more information
- Mothers Helper/Nanny wanted 3-7pm daily. Flexible days/times. Westholme and Wilshire. [email protected]
- Marketing Consultant for hire. Will consider ALL business services. Looking for marketing and business work. Contact [email protected] or 310-309-0782. Samples on cyberbear78.com/portfolio and https://www.linkedin.com/in/barbraellaongwico.

URL: https://www.insidehighered.com/news/2020/02/21/ucla-drops-plan-use-facial-recognition-security-surveillance-other-colleges-may-be
- By 

Lilah Burke
- You have /5 articles left.Sign up for a free account or log in.
- Smith Collection/Gado/Getty Images
- The University of California, Los Angeles, was the first university to openly propose using facial recognition software for security surveillance. Now it's the first to openly drop that plan. But whether other colleges are using the technology behind closed doors remains to be seen.
- UCLA first floated the plan last year as part of a larger policy about campus security. Students voiced concerns during a 30-day comment period in June and several town halls into this year.
- Fight for the Future, a national digital rights advocacy organization, launched its own public campaign against the UCLA administration's consideration early this year, in partnership with Students for Sensible Drug Policy.
- “This victory at UCLA will send a pretty strong message to any other administration who is considering doing this,” said Evan Greer, deputy director of the organization. “It’s not going to be worth the backlash.”
- As part of the effort, Fight for the Future ran its own experiment. The group ran over 400 photos of UCLA athletes and faculty members through Amazon’s facial recognition software. They found 58 of those photos were incorrectly matched with photos in a mug-shot database. The majority of those false positives, the organization said, were of people of color. Some images the software claimed were the same person with “100 percent confidence.”
- Fight for the Future had planned to release the results of the experiment to a news outlet, Greer said, but when that publication contacted the university, the response was swift. Within 24 hours a UCLA administrator wrote Greer to say the university was no longer considering using the software.
- The attention from outside the university had been mirrored by backlash from within. Several student groups came out against the technology. Student leaders from the Community Programs Office -- the campus multicultural center -- organized three town halls on campus surveillance and submitted op-eds against the policy.
- "As racially minoritized students at UCLA who have experienced over-surveillance and hyper-policing, it has been our responsibility to advocate and organize a space for students to learn about the policy and to engage the administration on voicing our collective concerns," said Oscar Macias and Salvador Martinez, student leaders from the multicultural center, via email. "For the past two years, students of color have worked tirelessly to achieve this historic victory."
- Ultimately, the potential benefits of the technology were limited, a spokesperson for UCLA said via email, "and vastly outweighed by the community’s concerns.”
- The university had not identified a specific software or made any concrete plans to deploy it, he said. The administration is now working to explicitly prohibit facial recognition software.
- The Problem With Facial Recognition
- The problems with the software are multifaceted, Greer said. It’s well documented that the current technology doesn’t always work as intended. It’s routinely bad at identifying women and nonwhite people.
- That means those groups are more likely to face both the annoying aspects of being misidentified (like being locked out of a dorm) and the dangerous ones (like being wrongly accosted by police).
- The technology is also susceptible to hacking.
- “The scan of your face is a unique identifier, like your Social Security number,” Greer said. “But if your Social Security number gets breached, you can get a new Social Security number. If a scan of your face gets breached, you can’t get a new face.”
- Students from the multicultural center said that in addition to putting people of color at risk, the technology could make vulnerable students less likely to access resources they need at the LGBT resource center or the Undocumented Students Program, for example.
- Amelia Vance, director of youth and education privacy at the Future of Privacy Forum, said concerns around facial recognition should be particularly troublesome for higher education institutions. The systems are often particularly bad at correctly identifying children and young adults, she said. The software can cost millions of dollars and -- given that many episodes of violence are committed by students who attend those colleges -- is ineffective against violence.
- “We just don’t have that much training data on children and on young adults,” Vance said. “This technology right now is not ready for prime time.”
- Her organization has proposed a moratorium on facial recognition in public schools.
- UCLA said it would consider using facial recognition in a “limited" capacity. One draft of the policy shared online by the student group Campus Safety Alliance said the technology would only be used “to locate a known individual for legitimate, safety or security purposes related to individuals who have been issued an official campus stay away order, court ordered restraining order, law enforcement bulletin or who pose a threat to one or more members of the campus community.”
- That draft said a human being would need to examine the match before an official determination of someone’s identity could be made.
- But Greer said that "limited" capacity -- security surveillance -- is one of the more concerning uses of the software.
- “We’ve seen a few other schools that were trying to dabble with this technology,” she said.
- Two other institutions in the state -- Stanford University and the University of Southern California -- had floated using facial recognition as part of their food service or dorm security. Students there would have been able to scan their faces to get into a dorm or pay for a meal.
- While those uses normalize facial recognition and should be stopped, Greer said, they don’t ring the same alarm bells that surveillance uses do.
- It’s possible that in the future the technology will improve, becoming more accurate and more secure.
- For Vance, that’s one reason why her organization has called for a moratorium instead of an outright ban.
- But to Greer, the possibility that the technology could become 100 percent accurate is even more frightening.
- “That’s a world where institutions of power have the ability to track and monitor their people everywhere they go, all the time. That is a world where there are zero spaces that are free from government or societal intrusion, which is basically a world where we can’t have new ideas,” she said. “We really need to think about this not just as an issue of privacy but as an issue of basic freedom.”
- If facial recognition software had been ubiquitous a few decades ago, she said, social movements like the LGBTQ rights movement may never have occurred.
- “In the end it’s not really about safety -- it’s about social control.”
- What’s Already Happening
- UCLA chose to be open about considering facial recognition and solicited comments from students. For that, the university should be applauded, Vance said.
- But that’s not necessarily happening everywhere.
- “I would be absolutely unsurprised if multiple universities had adopted it and we just don’t know about it,” Vance said. Safety and security offices often act independent of other university administrators and may not be transparent about a new security measure.
- Fight for the Future currently has a campus scorecard for facial recognition, keeping track of which colleges have pledged not to use the software. Though about 50 universities have told the organization they will not implement the technology, Greer said, many have said nothing at all.
- “It is absolutely possible that there are other schools in the country that are already using this technology, they just haven’t told anyone about it,” she said.
- The software is already in use by numerous municipal police departments and airports as well as at least one public school district. The Center on Privacy and Technology at Georgetown University Law Center found in 2016 that half of American adults are in a law enforcement facial recognition network.
- Facial recognition software companies already are marketing to universities and K-12 schools.
- “There are really no laws in place that would require private institutions, for example, to even disclose to their students that they’re doing this,” Greer said. “We really do need policies in place so that it’s not up to school administrators.”
- Vance pointed out that university leaders and policy makers often bemoan that a younger generation doesn’t care about privacy.
- “They clearly do care about privacy,” she said. “And this is a step too far.”
- (Note: This article has been changed from a previous version to include comments from student leaders.)
- As instructors, we are still examining how student engagement, which plummeted after the pandemic, remains in questio
- Education Department again delays controversial guidance on outside contractors and says it won’t affect many o
- The department’s guidance expanding the definition of third-party servicers has already been delayed until September
- Subscribe for free to Inside Higher Ed’s newsletters, featuring the latest news, opinion and great new careers in higher education — delivered to your inbox.
- View Newsletters
- Resources for faculty and staff from our partners at Times Higher Education.
- Copyright © 2023 Inside Higher Ed All rights reserved. | Website designed by nclud

URL: https://eu.usatoday.com/story/tech/2020/02/19/ucla-drops-face-recognition-plan/4810648002/
- A major California university has dropped plans to use facial recognition for the surveillance of the campus.
- The idea was to have the University of California Los Angeles use facial recognition as a way to gain access to buildings, to prove authenticity and to deny entry to people with restricted access to the campus, matching their faces against a database. Advocacy group Fight for the Future says UCLA was the first major university exploring using facial recognition to monitor students.
- The group had tested facial recognition software and found that "dozens" of student-athletes and professors were incorrectly matched with photos from a mug shot database, "and the overwhelming majority of those misidentified were people of color."
- Fallout: Facebook agrees to $550-million settlement in facial recognition class-action lawsuit
- Why your face is the key:  Do you really control how your face is being used?
- UCLA Vice Chancellor Michael Beck now says the school will not pursue the technology.
- "We have determined that the potential benefits are limited and are vastly outweighed by the concerns of our campus community," UCLA said in a statement to USA TODAY.
- Students were mobilizing and making their voices heard. At a public meeting to discuss the proposed system in January, student Madeleine Flores told the UCLA newspaper The Daily Bruin, “I don’t want (my family) to have the fear of having their face scanned because a lot of my family are already scared walking on the streets. Having (their information) put into a system," saying it would raise that fear "a thousand percent.”
- And in a blistering editorial in The Bruin, editors said the implementation of the technology "would present a major breach of students’ privacy and make students feel unsafe on a campus they are supposed to call home." It is one thing to monitor campus activity with security cameras, the paper said, "but it’s another entirely to automatically identify individuals and track their every move on campus."
- Fight for the Future says that some 40 plus students and activists are planning a national day of action March 2 to keep facial recognition off college campuses. Protests are expected to be held on several campuses, including Northeastern in Boston and George Washington in Washington, DC.
- On Fight for the Future's Ban Facial Recognition webpage, it asked prominent universities whether they planned to use facial recognition, and says several schools, including Columbia, Harvard and the Massachusetts Institute of Technology said they won't.
- In a Medium blog post, Fight for the Future deputy director Evan Greer says the test the non-profit ran with facial recognition software "shows how dangerous, and blatantly racist it would be if UCLA had gone ahead with their proposal to implement facial recognition on campus. And it should be a warning to other schools who are considering using this technology."
- In 2019, San Francisco became the first U.S. city to ban the use of facial recognition by local agencies, later followed by Oakland, California, and a Boston suburb.
- Follow USA TODAY's Jefferson Graham (@jeffersongraham) on Twitter

URL: https://www.theguardian.com/us-news/2020/mar/02/facial-recognition-us-colleges-ucla-ban
- Students staged protests on a dozen campuses while 36 schools saw online actions
- Students at universities across the United States participated in protests to demand their schools refrain from using facial recognition on campus.
- The protests on Monday came after pushback led by students and digital rights group Fight for The Future against a proposed facial recognition program at the University of California – Los Angeles (UCLA) led the school to reverse course and drop the technology. Students at around a dozen schools staged protests on campus in person this week while 36 schools saw online actions including petitions.
- “Colleges are becoming a flashpoint in the fight against facial recognition and we are really seeing a huge surge in students, professors, faculty and researchers organizing around this,” said Evan Greer, the deputy director of Fight for the Future.
- In 2019, UCLA administrators proposed using facial recognition software for security surveillance on campus. In a campaign against the program, Fight for the Future ran facial recognition technology on more than 400 photos of UCLA faculty members and athletes and found the software incorrectly matched 58 of those with photos in a mugshot database. The majority of those misidentified by the database were people of color.
- Following the changes from UCLA, students at a number of universities across the US sought to push back against proposed or actual programs at their own schools. On Monday, students from nearly a dozen schools including Kent State University, DePaul University, Yale Law School and University of Oregon sent letters and emails to administrators expressing opposition to facial recognition program.
- Dominique Coronel, a student at DePaul University who participated in the action said he was compelled as a first generation Mexican-American college student disturbed by deportations carried out by US Immigration and Customs Enforcement (Ice) to speak out against the technology.
- “Now that we know (Ice) is likely using facial recognition, I’m even more compelled to participate in campaigns to ban the technology from campuses,” he said. “Education should be a safe place, but this technology hurts the most vulnerable people in society”.
- Around 10 schools in the US are confirmed to be using facial recognition on campus, according to data from Fight for the Future, and even more have refused to say whether they are using it. About 50 schools, including Harvard, Columbia, University of Michigan, and – most recently – UCLA, have now committed to not using the technology after being pushed by Fight for the Future to take a stand publicly. Following Monday’s day of action, Oberlin College in Ohio also committed to not using facial recognition technology.
- At the heart of the campaign on Monday is an attempt to get more clarity around which schools use the technology, and which have pledged not to use it, Greer said, and ultimately action from legislators.
- “In the end, it shouldn’t be up to some campus safety officer or even a college president or administrator to make decisions like this without having all the facts or knowing all the potential risks of implementing such a system,” she said. “This underscores the broad need for lawmakers to get off their asses, and do their jobs, and pass legislation to ban the use of this technology.”

URL: https://deadline.com/2020/02/ucla-will-not-use-facial-recognition-technology-on-campus-1202865915/
- By Bruce Haring
- pmc-editorial-manager
- The UCLA administration has scrapped a plan to use facial recognition technology on campus after students and outside groups protested.
- A report by VICE News said UCLA was planning on implementing the system before complaints surfaced. Student groups said earlier this month that a  “National Day of Action” would be mounted against the technology.
- “Momentum is growing, as thousands of students, faculty, and alumni have signed a petition to ban the technology, 400 concerned community members have emailed UCLA over the past week, and a facial recognition vendor removed their page marketing to college campuses when questioned by a reporter,” a press release read.
- 
- The university reacted to the outcry.“We have determined that the potential benefits are limited and are vastly outweighed by the concerns of our campus community,” UCLA said in a statement to the press.
- Subscribe to Deadline Breaking News Alerts and keep your inbox happy.
- Signup for Breaking News Alerts & Newsletters
- By subscribing, I agree to the Terms of Use and Privacy Policy. This site is protected by reCAPTCHA Enterprise and the Google Privacy Policy and Terms of Service apply.
- Get our latest storiesin the feed of your favorite networks
- We want to hear from you! Send us a tip using our annonymous form.
- Sign up for our breaking news alerts
- By subscribing, I agree to the Terms of Use and Privacy Policy. This site is protected by reCAPTCHA Enterprise and the Google Privacy Policy and Terms of Service apply.
- Deadline is a part of Penske Media Corporation. © 2023 Deadline Hollywood, LLC. All Rights Reserved.
- By subscribing, I agree to the Terms of Use and Privacy Policy. This site is protected by reCAPTCHA Enterprise and the Google Privacy Policy and Terms of Service apply.

URL: https://www.latimes.com/business/story/2021-01-29/column-facial-recognition-privacy

URL: https://www.dailymail.co.uk/news/article-8025867/UCLA-cancels-facial-recognition-amid-backlash-privacy-likening-use-George-Orwells-1984.html
- By Ralph R. Ortega For Dailymail.com
- Published:  19:16, 20 February 2020   |  Updated:  20:01, 20 February 2020
- 
- 9
- View  comments
- 
- UCLA cancelled a plan to use facial recognition technology on campus after students protested over privacy concerns, including one critique that likened use of the digital surveillance to George Orwell's book, '1984.'
- The school issued a statement on Wednesday, saying that its plan for using facial recognition was scrapped due to the privacy concerns that were expressed.
- 'UCLA will not pursue the use of this technology,' wrote UCLA administrative vice chancellor Michael Beck in a statement released on Wednesday.
- UCLA cancelled a plan to use facial recognition technology on campus after students protested over privacy concerns
- One critique of UCLA's decision to use facial recognition, before scrapping the plan, likened use of the digital surveillance to the dystopian novel, '1984', by George Orwell (pictured)
- 'We have determined that the potential benefits are limited and vastly outweighed by the concerns of our campus community,' he explained in the statement, obtained by MailOnline.com.
- The Los-Angeles-based public university wanted to use facial recognition to raise an alarm if someone who was banned from campus suddenly showed up at the school.
- UCLA also had wanted to use the technology to recognize and authorize individuals seeking access into restricted areas.
- However the school wasn't prepared for backlash from students, as well as a national movement against such surveillance measures.
- The editorial board of the school's newspaper, 'The Daily Bruin', published a story last month that opens with, '2020 is looking more and more like '1984.' That is, UCLA is watching you', in a reference to Orwell's dystopian novel.
- The editorial board of 'The Daily Bruin,' in a story responding to UCLA's plan to use facial recognition, rapped the school for not heeding student concerns
- The book published in 1949 describes an imagined, future society ruled by an oppressive, totalitarian 'Big Brother', who employs government surveillance measures on every aspect of a citizen's life.
- The newspaper points out that UCLA had not learned its lesson after it had also scrapped a 2018 plan to centralize on-campus surveillance cameras and give campus police access to footage during emergencies, after students had also complained.
- 'Rather than learning from students' reactions to campus surveillance, UCLA seems to have jumped off the deep end by taking a page out of Big Brother's playbook,' the editorial board wrote.
- 'The implementation of facial recognition technology would present a major breach of students' privacy and make students feel unsafe on a campus they are supposed to call home,' explains the editorial board.
- 'It is one thing to monitor campus activity with security cameras, but it's another entirely to automatically identify individuals and track their every move on campus.'
- Fight for the Future, an advocacy group, issued a letter on Thursday in support of student protests against facial recognition across the country.
- 'Fight for the Future,' an advocacy group, issued a public letter on Thursday in support of students against campus surveillance across the US. Pictured is an image from the group's landing page, banfacialrecognition.com
- Fight for the Future's website links to a landing page, banfacialrecognition.com, which describes how the technology (pictured) is used
- Images showing how facial recognition works are included at banfacialrecognition.com
- The group's website includes links to the landing page, banfacialrecognition.com, which includes an interactive map of schools and other institutions that have chosen to pass on facial recognition, or which are considering its use.
- The site also points out schools in the states of Washington, Colorado and Texas that were using facial recognition.
- University of Colorado was cited by advocacy group Fight for the Future for using facial recognition
- The University of Texas uses facial recognition at its Memorial Stadium, according to advocacy group Fight for the Future's landing page, banfacialrecognition.com
- They include the University of Texas, which uses the technology at its Memorial Stadium, and University of Colorado, which is currently experimenting with facial recognition under a project funded by US military and intelligence agencies.
- The St. Therese Catholic Academy and University Child Development School, both in Seattle, Washington, are also using facial recognition, according to the website.
- Fight for the Future says it is in the process of testing Amazon's Rekognition algorithm on UCLA atheletes and faculty, complaining that the technology incorrectly had placed the faces of black people on to other people's mug shots.
- The findings expanded on previous concerns that the technology has a higher error rate for black people and women.
- Fight for the Future is partnering with students for a national day of protest on March 2.
- 
- Published by Associated Newspapers Ltd
- Part of the Daily Mail, The Mail on Sunday & Metro Media Group

- Lockport City School District facial recognition
- Anderstorp high school facial recognition
- Page infoType: IncidentPublished: March 2023
