- Occurred: October 2021
- Can you improve this page?Share your insights with us
- According to a new Forbes report, Dubai investigators have discovered an elaborate scam in which deepfake technology was used to clone the voice of a company director and defraud his company of USD 35 million.
- About to make an acquisition, the company needed its bank to authorise a series of transfers. A bank employee was fooled by the deepfaked voice into authorising the transfer of the cash, believing it was a legitimate business transaction.
- UAE authorities reckon the scheme involved at least 17 people. It is the second known case of fraudsters using deep voice tools to carry out a heist, and much the largest.
- Operator: Anonymous/pseudonymous Developer: Anonymous/pseudonymous Country: UAE/DubaiSector: Banking/financial services Purpose: Defraud Technology: Deepfake - audio; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning  Issue: Ethics; Security Transparency: Governance
URL: https://www.documentcloud.org/documents/21085009-hackers-use-deep-voice-tech-in-400k-theft

URL: https://www.forbes.com/sites/thomasbrewster/2021/10/14/huge-bank-fraud-uses-deep-fake-voice-tech-to-steal-millions/
- Cybercriminals cloned the voice of a company director in the U.A.E. to steal as much as $35 million in a huge and complex heist.
- In early 2020, a branch manager of a Japanese company in Hong Kong received a call from a man whose voice he recognized—the director of his parent business. The director had good news: the company was about to make an acquisition, so he needed to authorize some transfers to the tune of $35 million. A lawyer named Martin Zelner had been hired to coordinate the procedures and the branch manager could see in his inbox emails from the director and Zelner, confirming what money needed to move where. The manager, believing everything appeared legitimate, began making the transfers.
- What he didn’t know was that he’d been duped as part of an elaborate swindle, one in which fraudsters had used “deep voice” technology to clone the director’s speech, according to a court document unearthed by Forbes in which the U.A.E. has sought American investigators’ help in tracing $400,000 of stolen funds that went into U.S.-based accounts held by Centennial Bank. The U.A.E., which is investigating the heist as it affected entities within the country, believes it was an elaborate scheme, involving at least 17 individuals, which sent the pilfered money to bank accounts across the globe.
- Little more detail was given in the document, with none of the victims’ names provided. The Dubai Public Prosecution Office, which is leading the investigation, hadn’t responded to requests for comment at the time of publication. Martin Zelner, a U.S.-based lawyer, had also been contacted for comment, but had not responded at the time of publication.
- It’s only the second known case of fraudsters allegedly using voice-shaping tools to carry out a heist, but appears to have been far more successful than the first, in which fraudsters used the tech to impersonate a CEO of a U.K.-based energy firm in an attempt to steal $240,000 in 2019, according to the Wall Street Journal.
- The U.A.E. case shows how devastating such high-tech swindles can be and lands amidst warnings about the use of AI to create so-called deep fake images and voices in cybercrime.
- “Audio and visual deep fakes represent the fascinating development of 21st century technology yet they are also potentially incredibly dangerous posing a huge threat to data, money and businesses,” says Jake Moore, a former police officer with the Dorset Police Department in the U.K. and now a cybersecurity expert at security company ESET. “We are currently on the cusp of malicious actors shifting expertise and resources into using the latest technology to manipulate people who are innocently unaware of the realms of deep fake technology and even their existence.
- “Manipulating audio, which is easier to orchestrate than making deep fake videos, is only going to increase in volume and without the education and awareness of this new type of attack vector, along with better authentication methods, more businesses are likely to fall victim to very convincing conversations.”
- Once a technology confined to the realm of fictional capers like Mission: Impossible, voice cloning is now widely available. Various tech startups are working on increasingly sophisticated AI voice technologies, from London’s Aflorithmic to Ukraine’s Respeecher and Canada’s Resemble.AI. The technology caused a stir in recent months with the revelation that the late Anthony Bourdain had his voice synthesized for a documentary on his life. Meanwhile, recognizing the potential for malicious use of the AI, a handful of companies, such as $900 million-valued security firm Pindrop, now claim they can detect synthesized voices and thereby prevent frauds.
- If recordings of you speaking are available online, whether on social media, YouTube or on an employer’s website, there may well be a secret battle going on for control of your voice without you knowing.
- UPDATE: After publication, the U.A.E. Ministry of Foreign Affairs & International Cooperation contacted Forbes to note that the affected company was an unnamed Japanese business, though the Dubai investigators were leading the probe. The article was updated on 2 May 2023 to reflect that.
- In a statement, HE Hamid Al Zaabi, director general of the U.A.E. Executive Office of Anti-Money Laundering and Counter Terrorism Financing, added: “Even with incidents happening outside the U.A.E., we will work closely with law enforcement partners around the world to identify and detect those individuals who knowingly engage in deceptive practices such as imposter fraud. The U.A.E. will then pursue to the fullest extent of the law these individuals, ensuring they are held accountable and brought to justice quickly.”
- 
- 

URL: https://screenrant.com/ai-deepfake-cloned-voice-bank-scam-theft-millions/
- Police in the UAE are investigating a case where criminals allegedly used AI to clone a company director's voice and transfer funds.
- Police in the United Arab Emirates are investigating a case where AI was allegedly used to clone a company director's voice and steal $35 million in a massive heist. While it is a stunning and unusual crime, it is not the first time that fraudsters have resorted to AI-based voice-spoofing to carry off daring heists. A previous instance of such technology being used for a similar scam dates back to 2019, when criminals in the UK are said to have used deepfake software to impersonate the voice of the CEO of an energy firm to fraudulently transfer around $243,000.
- While artificial intelligence is expected to open up a wave of opportunities in the coming years, the threats posed by the technology are also very real. Automation-spurred job losses are often thought to be the most pressing issue with AI, but the technology also poses serious challenges in other areas, including privacy threats by the rampant use of facial recognition, as well as audio and video deepfakes created by manipulating voices and likeness. While the former tends to get attention in the mainstream media, the latter also poses a grave threat, as exhibited in these fraud cases.
- Related: Deepfake Technology May Be The Future Of Short-Term Weather Forecasting
- As reported by Forbes, the latest instance of manipulated voice being used for fraud happened in the UAE in early 2020, when criminals allegedly used AI to clone a company director's voice to ask a bank manager to transfer funds worth $35 million for an acquisition. The bank manager duly made the transfers believing everything to be legitimate, only to realize later that it was an elaborate scam designed by high-tech criminals. As it turned out, the scammers had used 'deep voice' technology to dupe the manager and swindle the bank out of the massive amount.
- According to a court document, the investigators in the UAE are now seeking help from US authorities to trace $400,000 of stolen funds that they believe are being held in US bank accounts. The rest of the funds are believed to be stored in many different banks under different names in various countries around the world. According to the UAE authorities, at least seventeen people are involved in the scheme, although their names and nationalities were not immediately clear.
- Talking to Forbes, Jake Moore, an expert at cyber-security firm ESET said that audio and video 'deepfake' technology can be a real issue in the hands of the wrong people, with deepfakes posing "a huge threat to data, money and businesses." Moore also added that an increased number of businesses are likely to fall victims to similar realistic deepfake audio scams in the future.
- Next: Scientists Team Up With AI To Develop Treatment For Childhood Brain Cancer
- Source: Forbes
- Kishalaya has almost a decade's worth of experience in tech journalism, having written thousands of news, guides, features, and reviews for multiple American, Canadian, and Indian blogs. As a senior writer at ScreenRant, he covers everything from consumer electronics to artificial intelligence, cryptocurrencies to virtual reality, and electric vehicles to space. Entertainment to him means 90s sitcoms, such as Fresh Prince, Home Improvement, Seinfeld, Friends, That 70s Show, Everybody Loves Raymond, etc. He loves dogs, sports, and pizza (in that order) and can listen to The Doors, Def Leppard, Metallica, and Guns N' Roses all day long. He also loves watching cheesy 90s sci-fi/disaster movies like Independence Day, Armageddon, Twister, Volcano, Dante's Peak, etc.

URL: https://www.unite.ai/deepfaked-voice-enabled-35-million-bank-heist-in-2020/
- By
- An investigation into the defrauding of $35 million USD from a bank in the United Arab Emirates in January of 2020 has found that deepfake voice technology was used to imitate a company director known to a bank branch manager, who then authorized the transactions.
- The crime took place on January 15th of last year, and is outlined in a request (PDF) by UAE to American state authorities for aid in tracking down a portion of the siphoned funds that were sent to the United States.
- The request states that the branch manager of an unnamed victim bank in UAE received a phone call from a familiar voice, which, together with accompanying emails from a lawyer named Martin Zelner, convinced the manager to disburse the funds, which were apparently intended for the acquisition of a company.
- The request states:
- ‘According to Emirati authorities, on January 15, 2020, the Victim Company’s branch manager received a phone call that claimed to be from the company headquarters. The caller sounded like the Director of the company, so the branch manager believed the call was legitimate.
- ‘The branch manager also received several emails that he believed were from the Director that were related to the phone call. The caller told the branch manager by phone and email that the Victim Company was about to acquire another company, and that a lawyer named Martin Zelner (Zelner) had been authorized to coordinate procedures for the acquisition.’
- The branch manager then received the emails from Zelner, together with a letter of authorization from the (supposed) Director, whose voice was familiar to the victim.
- Emirati investigators then established that deepfake voice cloning technology had been used to imitate the company director’s voice:
- ‘The Emirati investigation revealed that the defendants had used “deep voice” technology to simulate the voice of the Director. In January 2020, funds were transferred from the Victim Company to several bank accounts in other countries in a complex scheme involving at least 17 known and unknown defendants. Emirati authorities traced the movement of the money through numerous accounts and identified two transactions to the United States.
- ‘On January 22, 2020, two transfers of USD 199,987.75 and USD 215,985.75 were sent from two of the defendants to Centennial Bank account numbers, xxxxx7682 and xxxxx7885, respectively, located in the United States.’
- No further details are available regarding the crime, which is only the second known incidence of voice-based deepfake financial fraud. The first took place nine months earlier, in March of 2020, when an executive at a UK energy company was harangued on the phone by what sounded like the employee’s boss, demanding the urgent transfer of €220,000 ($243,000), which the employee then transacted.
- Deepfake voice cloning involves the training of a machine learning model on hundreds, or thousands of samples of the ‘target’ voice (the voice which will be imitated). The most accurate match can be obtained by training the target voice directly against the voice of the person who will be talking in the proposed scenario, though the model will be ‘overfitted’ to the person who be impersonating the target.
- The most active legitimate online community for voice cloning developers is the Audio Fakes Discord server, which features forums for many deepfake voice cloning algorithms such as Google’s Tacotron-2, Talknet, ForwardTacotron, Coqui-ai-TTS and Glow-TTS, among others.
- Since a phone conversation is necessarily interactive, voice cloning fraud cannot reasonably be effected by ‘baked’ high-quality voice clips, and in both cases of voice cloning fraud, we can reasonably assume that the speaker is using a live, real-time deepfake framework.
- Real-time deepfakes have come into focus lately due to the advent of DeepFaceLive, a real-time implementation of popular deepfake package DeepFaceLab, which can superimpose celebrity or other identities onto live webcam footage. Though users at the Audio Fakes Discord and the DeepFaceLab Discord are intensely interested in combining the two technologies into a single video+voice live deepfake architecture, no such product has publicly emerged as yet.
- 
- An AI Method to Reveal ‘Shielded’ PIN Entries at ATMs
- Fighting Adblock-Blocking With Machine Learning
- Writer on machine learning, artificial intelligence and big data.
Personal site:  martinanderson.ai Contact:  [email protected] Twitter: @manders_ai
- AI in Phishing: Do Attackers or Defenders Benefit More?
- NVIDIA’s eDiffi Diffusion Model Allows ‘Painting With Words’ and More
- GOTCHA– A CAPTCHA System for Live Deepfakes
- Deepfake Detectors Pursue New Ground: Latent Diffusion Models and GANs
- Creating Full Body Deepfakes by Combining Multiple NeRFs
- How Stable Diffusion Could Develop as a Mainstream Consumer Product
- Advertiser Disclosure: Unite.AI is committed to rigorous editorial standards to provide our readers with accurate information and news. We may receive compensation when you click on links to products we reviewed.
- Copyright © 2023 Unite.AI

URL: https://gizmodo.com/bank-robbers-in-the-middle-east-reportedly-cloned-someo-1847863805
- Criminals appear to have stolen some $35 million from a United Arab Emirates bank with the help of AI-enhanced voice simulation, according to a new report from Forbes. The “deepfaked” vocals were used to fool a bank employee into thinking he was handing over the cash on behalf of a legitimate business transaction associated with the bank.
- The robbery, which we know about thanks to a recently uncovered court document, took place last January, when the undisclosed bank’s branch manager  received a seemingly normal phone call. The person on the line claimed to be the director of a large company with whom the manager had previously spoken and they sounded just like them, the court document claims. This, paired with what appeared to be emails from the company and its lawyer, convinced the branch manager that the firm was in the midst of a large business deal worth $35 million. He subsequently followed the caller’s orders and began initiating a number of large money transfers from the company to new accounts. Unfortunately, it all turned out to be a sophisticated scam.
- Dubai investigators have revealed that the crooks “used ‘deep voice’ technology to simulate the voice of the director.” Authorities believe that the scheme involved as many as 17 different people and that the stolen cash was funneled to a number of bank accounts scattered throughout the globe. Two of those accounts were with Centennial Bank in the U.S. and received some $400,000 —which is why the case has now spilled into the American judicial system. UAE investigators have now reached out to American officials for help with their investigation.
- Believe it or not, this  is not the first time something like this has happened. In 2019, an energy company in the United Kingdom suffered a similar fate—with fraudsters managing to steal some $€220,000 (or $243,000 USD) by similarly impersonating the company’s CEO. And, according to people monitoring the AI market, it is unlikely to be the last time, either.
- “Audio and visual deep fakes represent the fascinating development of 21st century technology yet they are also potentially incredibly dangerous posing a huge threat to data, money and businesses,” Jake Moore, a cybersecurity expert with ESET, told Forbes. “We are currently on the cusp of malicious actors shifting expertise and resources into using the latest technology to manipulate people who are innocently unaware of the realms of deep fake technology and even their existence.”
- It’s clear that deepfake technology has been getting frighteningly good lately—just check out those Tom Cruise videos. Should we regulate them? Might be a good idea—though critics are split on what path new laws might take. Some people say such laws would create more problems than they solve, while others argue that they could impinge upon free speech and creative freedoms. Either way, it seems like we something we should all figure  out ASAP, before multi-million dollar deepfake bank heists become the new normal.

URL: https://gadgettendency.com/fraudsters-steal-35-million-from-a-bank-in-the-uae-with-the-help-of-a-diplomatic-voyage/
- The iPhone 15 is about to enter mass production, so Foxconn is actively recruiting and increasing bonuses. According to official...
- iPhone 16 Pro Max will get a 1.14-inch camera sensor Apple is expected to release the iPhone 15 series this...
- Microsoft President Brad Smith believes that the advent of artificial intelligence technologies is comparable to the invention of the printing...
- Well-known Bloomberg journalist and insider Mark Gurman confirmed the recently appeared information that in the iPhone 16 line, each model...
- The Chinese company Honor today introduced its new fully wireless headphones – Honor Earbuds X5. This is an inexpensive model with basic functionality and a low price. Honor Earbuds X5 are offered in two color options – coral and white. Chinese users will be able to buy them for $40...
- We have already written about the forthcoming flagship smartphones of the Xiaomi 14 series. They are likely to appear towards the end of this year – in November-December, but for now we have to be content with information from various leaks. Reliable insider Digital Chat Station again revealed some details...
- Today, Honor officially unveiled the Honor 90 smartphone. At a base price of $355, the device offers a lot of things, and most importantly, it finally has a completely new generation platform. The Honor 90 is based on the Qualcomm Snapdragon 7 Gen 1 SoC, a big step up from...
- Toyota is systematically working on expanding the Crown line – earlier in Japan, a flagship sedan was produced under this designation, and now Crown is a separate brand. It already includes a Crown cross-sedan and an interesting Crown Sport crossover, and now a regular Crown sedan has been declassified in...
- Fineday is currently raising funds on Kickstarter to launch a keyboard that can be connected wirelessly via Bluetooth 5.0 to a Windows or Mac computer, as well as an iOS or Android tablet or smartphone. Mobile devices can be fixed like a sheet of paper right on the keyboard, which...
- Rumors that MediaTek is going to release a single-chip system with Nvidia GPUs have been confirmed. Today, Nvidia announced a partnership with MediaTek, which will create the agreed platform. True, not yet for smartphones. Companies have teamed up to create solutions for cars. The combination of the industry-leading MediaTek system-on-a-chip,...
- The WhatsApp messenger development team has released update 2.23.11.19 for the Android operating system. It is already available to some beta testers through the Google Play Beta Program. The new version has the ability to share your screen with the interlocutor during a video call. To do this, you need...
- Nvidia has confirmed that its graphics accelerator, which it now calls Hopper Next, will be available next year. Nvidia hasn’t released any details yet, though we’ve heard before that the company’s next generation of dedicated accelerators will be called Blackwell. There is also data on two GPUs of this generation:...
- Bugatti has teamed up with real estate developer Binghatti to unveil the world’s first Bugatti Residences, located in Dubai’s prestigious Business Bay. This 46-story building with an unusual design will include 171 apartments and 11 Sky Mansion penthouses, each of which is completely unique and designed to order. There will...
- Nvidia introduced a product called Avatar Cloud Engine (ACE) for Games, which is needed, among other things, in order to create non-player characters (NPCs) based on artificial intelligence in video games. ACE is a suite of real-time AI solutions for end-to-end development and deployment of interactive avatars and digital people...
- Arm has unveiled the Cortex-X4 supercore, which will be used in the next generation of flagship single-chip systems. Arm is talking about a 15% performance boost, which is a lot for a single generation. In addition, Cortex-X4 is the most efficient Arm super-core ever. Interestingly, in the press release dedicated...
- Nvidia has introduced G-Sync Ultra Low Motion Blur 2 (ULMB 2) technology, which should make the image on the monitor even clearer. Nvidia itself speaks of an effective motion clarity frequency of over 1000 Hz, and this should not be confused with frame rate, since there are simply no panels...
- Apple has announced the imminent end of support for the service My Photo Stream (My photo stream). This means users will have to upgrade to iCloud Photos to store photos until the service’s shutdown date. Apple plans to end support for My Photo Stream on July 26, 2023. A month...
- The United States “will not tolerate” a de facto Chinese ban on the purchase of Micron Technology memory chips by Chinese companies and is working closely with allies to combat such “economic coercion,” U.S. Commerce Secretary Gina Raimondo said. Raimondo told a press conference following a meeting of trade ministers...
- Honor today introduced the Honor 90 Pro smartphone, the main feature of which was the screen. It supports 3840Hz PWM and has been certified by TUV Rheinland to be flicker-free, which even people with very sensitive eyes will not notice. Yesterday we clearly showed that in this regard, it turned...
- Nvidia today announced a new class of high-memory AI-based supercomputers, the Nvidia DGX supercomputer powered by Nvidia GH200 Grace Hopper superchips and Nvidia NVLink switching system, designed to develop new generative AI applications, recommender systems, and big data processing. The Nvidia DGX GH200 uses NVLink Switch System technology to combine...
- © 2023 Gadget Tendency. All Rights Reserved

URL: https://www.unite.ai/deepfaked-voice-enabled-35-million-bank-heist-in-2020/
- By
- An investigation into the defrauding of $35 million USD from a bank in the United Arab Emirates in January of 2020 has found that deepfake voice technology was used to imitate a company director known to a bank branch manager, who then authorized the transactions.
- The crime took place on January 15th of last year, and is outlined in a request (PDF) by UAE to American state authorities for aid in tracking down a portion of the siphoned funds that were sent to the United States.
- The request states that the branch manager of an unnamed victim bank in UAE received a phone call from a familiar voice, which, together with accompanying emails from a lawyer named Martin Zelner, convinced the manager to disburse the funds, which were apparently intended for the acquisition of a company.
- The request states:
- ‘According to Emirati authorities, on January 15, 2020, the Victim Company’s branch manager received a phone call that claimed to be from the company headquarters. The caller sounded like the Director of the company, so the branch manager believed the call was legitimate.
- ‘The branch manager also received several emails that he believed were from the Director that were related to the phone call. The caller told the branch manager by phone and email that the Victim Company was about to acquire another company, and that a lawyer named Martin Zelner (Zelner) had been authorized to coordinate procedures for the acquisition.’
- The branch manager then received the emails from Zelner, together with a letter of authorization from the (supposed) Director, whose voice was familiar to the victim.
- Emirati investigators then established that deepfake voice cloning technology had been used to imitate the company director’s voice:
- ‘The Emirati investigation revealed that the defendants had used “deep voice” technology to simulate the voice of the Director. In January 2020, funds were transferred from the Victim Company to several bank accounts in other countries in a complex scheme involving at least 17 known and unknown defendants. Emirati authorities traced the movement of the money through numerous accounts and identified two transactions to the United States.
- ‘On January 22, 2020, two transfers of USD 199,987.75 and USD 215,985.75 were sent from two of the defendants to Centennial Bank account numbers, xxxxx7682 and xxxxx7885, respectively, located in the United States.’
- No further details are available regarding the crime, which is only the second known incidence of voice-based deepfake financial fraud. The first took place nine months earlier, in March of 2020, when an executive at a UK energy company was harangued on the phone by what sounded like the employee’s boss, demanding the urgent transfer of €220,000 ($243,000), which the employee then transacted.
- Deepfake voice cloning involves the training of a machine learning model on hundreds, or thousands of samples of the ‘target’ voice (the voice which will be imitated). The most accurate match can be obtained by training the target voice directly against the voice of the person who will be talking in the proposed scenario, though the model will be ‘overfitted’ to the person who be impersonating the target.
- The most active legitimate online community for voice cloning developers is the Audio Fakes Discord server, which features forums for many deepfake voice cloning algorithms such as Google’s Tacotron-2, Talknet, ForwardTacotron, Coqui-ai-TTS and Glow-TTS, among others.
- Since a phone conversation is necessarily interactive, voice cloning fraud cannot reasonably be effected by ‘baked’ high-quality voice clips, and in both cases of voice cloning fraud, we can reasonably assume that the speaker is using a live, real-time deepfake framework.
- Real-time deepfakes have come into focus lately due to the advent of DeepFaceLive, a real-time implementation of popular deepfake package DeepFaceLab, which can superimpose celebrity or other identities onto live webcam footage. Though users at the Audio Fakes Discord and the DeepFaceLab Discord are intensely interested in combining the two technologies into a single video+voice live deepfake architecture, no such product has publicly emerged as yet.
- 
- An AI Method to Reveal ‘Shielded’ PIN Entries at ATMs
- Fighting Adblock-Blocking With Machine Learning
- Writer on machine learning, artificial intelligence and big data.
Personal site:  martinanderson.ai Contact:  [email protected] Twitter: @manders_ai
- AI in Phishing: Do Attackers or Defenders Benefit More?
- NVIDIA’s eDiffi Diffusion Model Allows ‘Painting With Words’ and More
- GOTCHA– A CAPTCHA System for Live Deepfakes
- Deepfake Detectors Pursue New Ground: Latent Diffusion Models and GANs
- Creating Full Body Deepfakes by Combining Multiple NeRFs
- How Stable Diffusion Could Develop as a Mainstream Consumer Product
- Advertiser Disclosure: Unite.AI is committed to rigorous editorial standards to provide our readers with accurate information and news. We may receive compensation when you click on links to products we reviewed.
- Copyright © 2023 Unite.AI

- Dubai deepfake court evidence
- China taxation department deepfake fraud
- Page infoType: IncidentPublished: October 2021
