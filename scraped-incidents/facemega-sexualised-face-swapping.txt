- FaceMega sexualised face swapping
- Occurred: March 2023
- Can you improve this page?Share your insights with us
- Adverts for FaceMega, an app that creates AI-generated deepfake videos of Hollywood stars in sexually suggestive poses, have been removed from Facebook and Instagram for violating their adult content policies.
- NBC News reported that 230 highly charged video ads promoting FaceMega were run across Facebook and Instagram, of which 127 featured Emma Watson and 74 videos featured Scarlett Johansson.
- Created by Chinese company Ufoto, FaceMega described itself as a tool for creating 'deepfake face swap videos', cost GBP 7.49 a week, and was rated as suitable for ages 'nine and up'.
- Users were never asked to verify their age, and the choice of videos on which users could attach their faces included scantily clad women in bikinis and a section named 'Hot'. the app has since been removed from the Android and Apple app stores.
- The discovery was first made by journalism student Lauren Barton, who posted one of the ads on Twitter, where it has received over 17 million views.
- Operator: Wondershare/Ufoto Developer: Wondershare/Ufoto Country: USA Sector: Media/entertainment/sports/arts Purpose: Swap faces Technology: Deepfake - video; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning Issue: Safety; Copyright Transparency: Governance
URL: https://twitter.com/laurenbarton03/status/1632769865122545664
- We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using twitter.com. You can see a list of supported browsers in our Help Center.
- Help Center
- Terms of Service
Privacy Policy
Cookie Policy
Imprint
Ads info
      © 2023 X Corp.

URL: https://www.nbcnews.com/tech/social-media/emma-watson-deep-fake-scarlett-johansson-face-swap-app-rcna73624
- 
- Profile
- Sections
- tv
- Featured
- More From NBC
- Follow NBC News
- In a Facebook ad, a woman with a face identical to actor Emma Watson’s face smiles coyly and bends down in front of the camera, appearing to initiate a sexual act. But the woman isn’t Watson, the “Harry Potter” star. The ad was part of a massive campaign this week for a deepfake app, which allows users to swap any face into any video of their choosing.
- Deepfakes are content where faces or sounds are switched out or manipulated. Commonly, deepfake creators make videos in which celebrities are made to look like they are willingly appearing in them, even though they are not.  Increasingly, the technology has been used to make nonconsensual pornography featuring the faces of celebrities, influencers or any person, including children.
- The ad campaign on Meta nods to the fact that this once-advanced technology has rapidly spread to readily available consumer applications being advertised on mainstream parts of the internet. Despite many platforms prohibiting manipulative and malicious deepfake content, apps like the ones reviewed by NBC News have been able to slip through the cracks.
- On Sunday and Monday, an app for creating “DeepFake FaceSwap” videos rolled out more than 230 ads on Meta’s services, including Facebook, Instagram and Messenger, according to a review of Meta’s ad library. Some of the ads showed what looked like the beginning of pornographic videos with the well-known sound of the porn platform Pornhub’s intro track playing. Seconds in, the women’s faces were swapped with those of famous actors.
- When Lauren Barton, a journalism student in Tennessee, saw the same ad on a separate application, she was shocked enough to screen-record it and tweet it out, where it received over 10 million views, according to Twitter’s views counter.
- “This could be used with high schoolers in public schools who are bullied,” Barton said. “It could ruin somebody’s life. They could get in trouble at their job. And this is extremely easy to do and free. All I had to do was upload a picture of my face and I had access to 50 free templates.”
- Of the Meta ads, 127 featured Watson’s likeness. Another 74 featured the actor Scarlett Johansson’s face swapped with those of women in similarly provocative videos. Neither actor responded to a request for comment.
- “Replace face with anyone,” the captions on 80 of the ads read. “Enjoy yourself with AI swap face technology.”
- On Tuesday, after NBC News asked Meta for comment, all of the app’s ads were removed from Meta’s services.
- While no sexual acts were shown in the videos, their suggestive nature illustrates how the application can potentially be used to generate faked sexual content. The app allows users to upload videos to manipulate and also includes dozens of video templates, many of which appear to be taken from TikTok and similar social media platforms.
- The preset categories include “Fashion,” “Bride,” “For Men,” “For Women,” and “TikTok,” while the category with the most options is called “Hot.” It features videos of scantily clad women and men dancing and posing. After selecting a video template or uploading their own, users can input a single photo of anyone’s face, and receive a face-swapped version of the video in seconds.
- The terms of service for the app, which costs $8 per week, say it does not allow users to impersonate others via their services or upload sexually explicit content. The app developer listed on the App Store is called Ufoto Limited, owned by a Chinese parent company, Wondershare. Neither company responded to a request for comment.
- Meta banned most deepfake content in 2020, and the company prohibits adult content in ads, including nudity, depictions of people in explicit or suggestive positions, or activities that are sexually provocative.
- “Our policies prohibit adult content regardless of whether it is generated by AI or not, and we have restricted this Page from advertising on our platform,” a Meta spokesperson said in a statement.
- The same ads were also spotted on free photo-editing and gaming apps downloaded from Apple’s App Store, where the app first appeared in 2022 for free for ages 9 and up.
- An Apple representative said that the company does not have specific rules about deepfakes but that it prohibits apps that include pornography and defamatory content. Apple said it removed the app from the App Store after having been contacted by NBC News.
- The app was also previously available to download for free on Google Play, where it was rated "Teen" for "suggestive themes." Google said Wednesday it removed the app from Google Play after having been contacted by NBC News.
- Apple and Google have taken action against similar AI face-swap apps, including a different app that was the subject of a Reuters investigation in December 2021. Reuters found that the app was advertising the creation of “deepfake porn” on pornographic websites. At the time, Apple said it didn’t have specific guidelines around deepfake apps but prohibited content that was defamatory, discriminatory or likely to intimidate, humiliate or harm anyone. While its ratings and ad campaigns have been adjusted, the app that Reuters reported on is still available to download free on Apple’s App Store and Google Play.
- The app NBC News reviewed is one of the latest in a boom of freely accessible consumer deepfake products.
- When searching “deepfake” on app stores, dozens of apps with similar technological capabilities appear, including ones that promote making “hot” content.
- Mainstream examples of the technology show celebrities and politicians doing and saying things they’ve never actually said or done. Sometimes the effects are comical.
- However, deepfake technology has overwhelmingly been used to make pornography with nonconsenting stars. As the technology has improved and become more widespread, the market for nonconsensual sexual imagery has ballooned. Some websites allow users to sell nonconsensual deepfake porn from behind a paywall.
- A 2019 report from DeepTrace, an Amsterdam-based company monitoring synthetic media online, found that 96% of deepfake material online is of a pornographic nature.
- In January, female Twitch streamers spoke out after a popular male streamer apologized for consuming deepfake porn of his peers.
- Livestreaming research conducted by the independent analyst Genevieve Oh found that the top website for consuming deepfake porn exploded in traffic following the Twitch streamer’s apology. Oh’s research also found that the number of deepfake pornographic videos has nearly doubled every year since 2018. February had the largest number of deepfake porn videos uploaded in a month ever, Oh said.
- While the nonconsensual sharing of sexually explicit photos and videos is illegal in most states, laws addressing deepfake media are in effect only in California, Georgia, New York and Virginia.
- Kat Tenbarge is a tech and culture reporter for NBC News Digital.
- © 2023 NBC UNIVERSAL

URL: https://www.insider.com/deepfake-app-removed-stores-suggestive-ads-emma-watsons-face-2023-3
- Jump to
- 
- 
- 
- Multiple online stores and Meta have removed a controversial face swap app that promoted a sexually suggestive ad featuring the face of the "Harry Potter" actor Emma Watson imposed onto someone else.
- The app for creating deepfakes, called Facemega, showed a woman with Watson's face smiling flirtatiously and then getting down on her knees for what appears to be a man. The caption read: "Swap any face into the video!" A screen recording of the ad posted to Twitter got 3.2 million views.
- Deepfakes use artificial intelligence to replace the likeness of one person with another in videos and other digital media, and its use has raised ethical and privacy concerns.
- An attorney told Insider that this is just one illustration of how emerging deepfake technology could be used as a "weapon" against women and girls.
- Michael Farhi, an attorney who has published material on the subject before, told Insider that the use of AI "is going to result in a huge jump in it being a weapon against women online all across the world." He added that women are the most popular demographic to target with such harassment.
- Deepfakes and revenge porn are already threats to women, and AI technology, which can make fake videos look convincingly real, is going to "quadruple" the negative impacts, Farhi said.
- The Facemega ad ran on Facebook until the site removed it following coverage by NBC News, who reported that the app also published advertisements with Scarlett Johansson's face in provocative videos. Facemega was listed for free on Apple and Google Play, who have both since removed it, but similar apps remain listed in both stores.
- A spokesperson for Apple told Insider that the company removed the app from the Apple Store and that the company does not allow apps that include defamatory, pornographic, or mean-spirited content intended to humiliate others. A spokesperson for Google said the company took "appropriate action" and removed the app for "violations of our policies."
- A Meta spokesperson told Insider that their "policies prohibit adult content regardless of whether it is generated by AI or not," and that FaceMega's page was restricted on Facebook.
- Watson's legal representation could not be reached for comment.
- The suggestive ad appeared to violate Facemega's own terms and conditions of service, which prohibit users from uploading content that is defamatory or sexually explicit.
- The Chinese software company Wondershare owns Facemega, a spokesperson for the company confirmed to Insider. When asked about the advertisement, the Wondershare spokesperson said: "Our legal department is already following up on this matter, and the advertising content has also been removed from the shelves."
- In the US, victims of deepfake porn "have potential claims like defamation, invasion of privacy, infliction of emotional distress," Farhi told Insider. But he also said that initiating legal action internationally against a Chinese company would be a "hurdle."
- "A lawyer wherever in the US sending a cease-and-desist type letter to an entity in China, even if it's translated appropriately, it's going to have little to no effect as a practical matter. So where do you go next? You go to Facebook, which has challenging rules and regulations of its own in terms of what it posts and what ads it puts up," Farhi said.
- Public pressure against companies who share the content may be more effective than legal actions, Farhi said. He added that "the advances in technology are happening too fast for it to be legislated." Deepfake technology, like all tech advancements, comes with "pluses and minuses," but Farhi said the potential damages are being "swept under the rug."
- "The advocates of AI are, of course, pushing the idea that you'll get instant research, instant assistance at work. For creators, it's a great asset and a great tool," Farhi said. "It's going to be a frigging nightmare, even more than what's out there now, as a tool or a weapon to harm women."
- Farhi said an especially vulnerable group is likely to be teen girls, whom revenge and deepfake porn already bombard on a regular basis.
- "This is going to have real harm to untold numbers of girls and women. Not just in high school, before high school at the elementary-school or middle-school level, all the way up to women in their twenties, thirties, and beyond," Farhi said. "And the easier it is to do, or the easier it is for a predator to do — and it's going to be a lot easier — the more it's going to be done."
- Read next

URL: https://gizmodo.com/deep-fake-ai-emma-watson-facemega-instagram-1850204168
- As the role of artificial intelligence appears to continue growing in our daily lives, it’s taking people’s likeness along with it. This week, hundreds of deepfaked videos featuring faces that looked exactly like Emma Watson and Scarlett Johansson ran across Facebook and Instagram as part of an apparent advertising campaign for an AI deepfake app called FaceMega.
- NBC News broke the story, and reported that 230 videos were run across Facebook and Instagram. 127 of the ad videos featured Watson while 74 videos featured Johansson, all of which showed the actresses in provocative situations and had sexually suggestive themes.
- The campaign was apparently an advertisement for FaceMega, and for $8 a week, users can swap out the faces of someone in a video with photos uploaded to the app. FaceMega has since been deleted from the Apple App store and the Google Play Store.
- “This could be used with high schoolers in public schools who are bullied,” Lauren Barton, who uploaded a screen recording of one of the videos to Twitter, said to NBC News. “It could ruin somebody’s life. They could get in trouble at their job. And this is extremely easy to do and free. All I had to do was upload a picture of my face and I had access to 50 free templates.”
- The ads seem to go against the app’s own Terms and Conditions, which say users are not allowed to “Act deceptively or impersonate any person or organization.”
- NBC News says the campaign comes from app developer Ufoto Limited, which is owned by Wondershare, its Chinese parent company.
- In a January 2020 press release, Meta claimed that it was tightening its grip on manipulated content—the company specifically referenced the growing popularity of deepfakes. Meta said it would remove manipulated videos and photos that are edited in ways to intentionally deceive the average person, or in instances where an AI superimposes content onto a video.
- “Our policies prohibit adult content regardless of whether it is generated by AI or not, and we have restricted this Page from advertising on our platform,” Meta told Gizmodo in an email.
- Update March 9, 2:30 p.m. EST: Google told Gizmodo via email that FaceMega has been removed from the Google Play Store. This article has been updated to reflect that.

URL: https://thred.com/tech/why-the-facemega-deepfake-app-is-a-slippery-slope/

URL: https://nypost.com/2023/03/09/facebook-removes-emma-watson-scarlett-johansson-deepfake-sex-ads/
- Submit
- Δ
- Thanks for contacting us. We've received your submission.
- Mark-Zuckerberg-owned Facebook and Instagram scrambled to remove hundreds of video clips touting an app that creates AI-generated deepfake videos of Hollywood stars in sexually suggestive poses.
- One ad that circulated on social media shows a deepfake of “Harry Potter” heroine Emma Watson gazing sensually into the camera while kneeling to the floor just moments before it appears she is about to perform a sex act.
- The ad then displays the name of the app, FaceMega, which touts itself as a tool for creating “deepfake face swap videos.”
- FaceMega circulated more than 230 ads on Meta’s social media platforms using deepfake videos depicting the likenesses of Watson and “Avengers” star Scarlett Johansson, according to NBC News.
- “Replace face with anyone,” the captions on 80 of the ads read. “Enjoy yourself with AI swap face technology.”
- “Deepfake” is the term used to describe a video in which a person’s face is digitally altered with the aid of artificial intelligence to the point where they resemble somebody else — most often a celebrity or well-known person.
- The offending ads were spotted by Lauren Barton, a journalism student based in Tennessee. She tweeted the video clip featuring the Watson deepfake on her Twitter feed Monday.
- Advertisement
- Meta, which owns Facebook and Instagram, sprang into action after the video went viral, having been viewed more than 16 million times, according to the Twitter view counter.
- “Our policies prohibit adult content regardless of whether it is generated by AI or not, and we have restricted this Page from advertising on our platform,” a spokesperson for Meta told The Post on Thursday.
- A spokesperson for Google told The Post that the company has removed the app from its Play Store.
- The Google spokesperson referred The Post to its policies regulating “inappropriate content,” including “sexual content and profanity.”
- “We don’t allow apps that contain or promote sexual content or profanity, including pornography, or any content or services intended to be sexually gratifying,” according to the Play Store terms of service.
- “We don’t allow apps or app content that appear to promote a sexual act in exchange for compensation.”
- An Apple spokesperson declined to comment, though a source within the company told The Post that the app has been removed from the App Store.
- Privacy advocates have grown alarmed at potential abuses of deepfake technology, particularly the practice of superimposing women’s likenesses into pornographic images to make it appear that they were willing participants.
- Last month, Sweet Anita, a 32-year-old British social media star, discovered that her face had been digitally pasted onto the body of a woman who was filmed in pornographic videos.
- It’s not just sex videos that pose a danger. Last year, social media platforms removed a deepfake video showing Ukrainian President Volodymyr Zelensky telling his countrymen to surrender to Russia.

URL: https://thred.com/tech/why-the-facemega-deepfake-app-is-a-slippery-slope/

URL: https://www.the-sun.com/tech/7608077/sick-sexualised-face-swap-apps-targeted-children/
- VIDEO apps that can instantly create sexualised fake likenesses are being targeted at children as young as nine, a Sun on Sunday investigation has found.
- Youngsters simply input a photo of a boy or girl’s face and within seconds it is transposed on to a scantily clad body in a provocative pose.
- One of the artificial intelligence-driven apps, Facemega, was removed from both the Apple App Store and Google Play this week following our probe.
- Yet online monitoring group App Magic estimates the app has already been downloaded more than a million times since its launch last year.
- Use of AI-driven fake videos and photos has increased by 900 per cent since 2019.
- Carolyn Bunting, CEO of child cyber safety organisation Internet Matters, told us: “The creation of sexualised, non-consensual deepfakes across these apps is incredibly disturbing, as is the impact this kind of content can have on children.
- “Using someone’s image in a sexual way without their consent will be extremely harmful for the child. It can lead to complex and lasting issues affecting their well-being.”
- Before Facemega was taken down from the app stores it had climbed to 77th place in the entertainment chart — above Lego. It cost £7.49 a week and was rated as suitable for ages “nine and up”.
- While putting young lives at risk, it has made millions of pounds for both the app stores and the developer, Ufoto Ltd, owned by China parent company Wondershare.
- Users are never asked to verify their age when accessing the image-altering tech, but the choice of videos to graft a face on to include scantily clad women in bikinis and a section entitled Hot.
- Within ten seconds of uploading your selected mug shot, AI wizardry matches it to a different body with often alarming results.
- Following our probe, the developer of Facemega removed the Hot and For Women categories — which contained sexually provocative videos — from its app.
- Similar apps to Facemega remain on mainstream platforms, weaving their worrying web of twisted reality.
- Face Swap Video, by Deep Fake, created by US firm Deepfaker LLC, was being advertised on the App Store this week as suitable for kids aged four and up. The ad shows a young woman having her face swapped on to another person’s social media picture — though not in a sexual way.
- A video then starts rolling, leaving it hard to tell the difference between what is real and what is fake.
- A three-day free trial leads to a £7.99 a week subscription.
- On Faceswap, also listed for ages nine-plus on the App Store, kids can access deepfakes for free before they are required to pay a £19.99 annual subscription.
- Our revelations come just months after ministers announced deep-fake pornography will be targeted, with the unauthorised creation and sharing of images made illegal under its Online Safety Bill, which has been passed but not yet enacted.
- Children’s charity the NSPCC called for the Government to put a legal duty on the major app distributors to help protect the targets of these apps, especially women and girls.
- Rani Govender of the NSPCC, added: “App stores have an important role to play in preventing the risks of deepfake technology at source. The Government can also act through its Online Safety Bill by adding a legal duty on companies to tackle violence against women and girls online.”
- Communications regulator Ofcom last year said fake or deceptive images and videos are ranked in the top 20 online potential harms faced by UK internet users.
- Teaching platform Safer Schools says the number of deepfakes online grew from roughly 14,000 to 145,000 between 2019 and 2021 — a 900 per cent increase. Of those, 96 per cent contained pornographic material while around 90 per cent involved indecent images of young women.
- The NSPCC’s Ms Govender added: “Deepfake technology is already having an insidious impact on children as it becomes increasingly easy to produce and share this degrading and damaging material.
- “This rapidly advancing technology is fast becoming a child abuse risk as it is rolled out without proper consideration of the way in which it fuels intimate image abuse.
- “Girls and women suffer the most from apps like this, which exist within a toxic online culture of misogyny that is growing at a disturbing rate.”
- Apple said it had removed Face Mega from the App Store and said it had no specific rules on deepfake apps. It claimed to prohibit apps that include pornography, defamatory or discriminatory content.
- A Google Play spokeswoman confirmed it had taken down Face Mega from it’s platform but did not comment on other apps.
- Tory MP Siobhan Baillie called deepfake technology terrifying and added: “Clearly age verific- ation and additional protections must be considered.
- “I salute The Sun on Sunday for getting this app removed from the Apple App Store and Google Play. Our children need to be protected from the deep fake menace.”
- CHILDLINE has shared details of three teenagers who have been threatened with fake videos and photos, as the charity shows how traumatic it can be.
- One 14-year-old told how she was threatened online with having a fake video of her made if she refused to send an abuser nude images.
- They said: “I was being friendly, just small-talking to someone on Snapchat. They asked what I looked like so I sent a picture of my face, then they kept asking me for nudes.
- “I told them no but they said if I don’t they will edit my face on to nudes and sell them. I know I should report them but it won’t change anything, as they will still have my photos on their camera roll. Please help, I’m really worried.”
- A terrified 13-year-old said: “Someone I know is threatening to post a fake nude and claim it’s me if I don’t send her actual nudes.
- “She says she will tag my friends and show them that ‘it’s me’. I haven’t ever sent nudes before and I worry my real friends will judge me if this happens.
- “I met this person online and we used to be friends, but we haven’t spoken for a while. I don’t understand why she’s doing this to me. I don’t know what to do.”
- A third teen told Childline they had got police investigators involved over fake porn pictures.
- He said: “I feel so embarrassed and angry. Someone has created a fake account on Instagram that is under my name and they’ve put inappropriate pictures (porn) with my face on them.
- “I’ve reported the account and the police are trying to track the person down. I feel a bit safer knowing that but I’m worried about my friends finding out and me getting bullied for it.”
- FBI warns social media users over mistake that's 'kiss of death' for accounts
- Best Buy shoppers rush to buy top brand $1,280 tablet scanning for under $1,000
- New WhatsApp feature is a godsend for helping mum and dad with iPhone problems
- Amazon shoppers rush to buy $500 Microsoft laptop appearing in basket for $260
- © 2020 THE SUN, US, INC. ALL RIGHTS RESERVED | TERMS OF USE | PRIVACY | YOUR AD CHOICES | SITEMAP

- ZAO face swapping
- FaceApp facial transformations
- Page infoType: IncidentPublished: March 2023
