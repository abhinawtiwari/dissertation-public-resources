{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a977af2",
   "metadata": {},
   "source": [
    "# Text similarity using below ref\n",
    "# https://www.youtube.com/watch?v=y-EjAuWdZdI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e7a2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46b869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68439f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8282848000526428"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 'red'\n",
    "w2 = 'yellow'\n",
    "\n",
    "w1 = nlp.vocab[w1]\n",
    "w2 = nlp.vocab[w2]\n",
    "\n",
    "w1.similarity(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "798994a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full similarity: 0.3540884077778206\n",
      "just nouns similarity:  0.5176537463277678\n"
     ]
    }
   ],
   "source": [
    "# text1 = \"I love coding in Python\"\n",
    "# text2 = \"Python programming is awesome\"\n",
    "\n",
    "text1 = \"Algorithmic bias and discrimination\"\n",
    "text2 = \"Accuracy/reliability\"\n",
    "\n",
    "# Process the texts using the spaCy model\n",
    "doc1 = nlp(text1)\n",
    "doc2 = nlp(text2)\n",
    "\n",
    "# Calculate the similarity between the texts\n",
    "similarity = doc1.similarity(doc2)\n",
    "\n",
    "# Print the similarity score\n",
    "print(\"full similarity:\", similarity)\n",
    "\n",
    "# checking noun similarity\n",
    "doc1_nouns = \" \".join([token.lemma_ for token in doc1 if token.pos_ == 'NOUN'])\n",
    "doc2_nouns = \" \".join([token.lemma_ for token in doc2 if token.pos_ == 'NOUN'])\n",
    "# print('doc1_nouns: ', doc1_nouns)\n",
    "# print('doc2_nouns: ', doc2_nouns)\n",
    "doc1 = nlp(doc1_nouns)\n",
    "doc2 = nlp(doc2_nouns)\n",
    "print('just nouns similarity: ', doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc833f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "\n",
    "def extract_data(input_file, output_file, columns):\n",
    "    # Read the Excel file into a pandas DataFrame\n",
    "    df = pd.read_excel(input_file)\n",
    "    \n",
    "    # Filter the DataFrame to keep only the specified columns\n",
    "    df_filtered = df[columns]\n",
    "    \n",
    "    # Replace NaN values with None\n",
    "    df_filtered = df_filtered.where(df_filtered.notna(), None)\n",
    "    \n",
    "    # Convert the filtered DataFrame to a list of dictionaries\n",
    "    data = df_filtered.to_dict('records')\n",
    "    \n",
    "    # Write the data to a JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "# Specify the input Excel file, output JSON file, and columns to extract\n",
    "input_file = 'aiaaic_repo.xlsx'\n",
    "output_file = 'aiaaic_filtered.json'\n",
    "columns = ['Risks', 'Source']  # Replace with the actual column names you want to extract\n",
    "\n",
    "# Call the function to extract and convert the data\n",
    "extract_data(input_file, output_file, columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa4500c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def update_property_names(json_file):\n",
    "    # Load the JSON file\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Iterate over the list of dictionaries\n",
    "    updated_data = []\n",
    "    for item in data:\n",
    "        # Create a new dictionary with updated property names\n",
    "        updated_item = {\n",
    "            'risks': item['Risks'],\n",
    "            'source': item['Source']\n",
    "        }\n",
    "        updated_data.append(updated_item)\n",
    "\n",
    "    # Write the updated data to a new JSON file\n",
    "    output_file = 'updated_aiaaic_filtered.json'\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(updated_data, f, indent=4)\n",
    "\n",
    "# Specify the JSON file to update\n",
    "json_file = 'files/aiaaic_filtered.json'\n",
    "\n",
    "# Call the function to update the property names\n",
    "update_property_names(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3103abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def merge_json_files(file1, file2, output_file):\n",
    "    # Read the contents of the first JSON file\n",
    "    with open(file1, 'r') as f1:\n",
    "        data1 = json.load(f1)\n",
    "\n",
    "    # Read the contents of the second JSON file\n",
    "    with open(file2, 'r') as f2:\n",
    "        data2 = json.load(f2)\n",
    "\n",
    "    # Create a set to store the common sources\n",
    "    common_sources = set(item['source'] for item in data1) & set(item['source'] for item in data2)\n",
    "\n",
    "    # Create a list to store the merged data\n",
    "    merged_data = []\n",
    "\n",
    "    # Iterate over the dictionaries in the first file\n",
    "    for item1 in data1:\n",
    "        source = item1.get('source')\n",
    "        if source in common_sources:\n",
    "            # Find the corresponding dictionary in the second file based on the source\n",
    "            item2 = next((item for item in data2 if item['source'] == source), None)\n",
    "            if item2 is not None:\n",
    "                # Merge the dictionaries and add to the merged data list\n",
    "                merged_item = {\n",
    "                    'source': source,\n",
    "                    'bard_impact_risk': item1.get('impact_risk'),\n",
    "                    'aiaaic_risks': item2.get('risks')\n",
    "                }\n",
    "                merged_data.append(merged_item)\n",
    "\n",
    "    # Write the merged data to a new JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(merged_data, f, indent=4)\n",
    "\n",
    "# Specify the paths to the input JSON files and the output file\n",
    "file1 = 'files/bard_filtered.json'\n",
    "file2 = 'files/aiaaic_filtered.json'\n",
    "output_file = 'files/merged.json'\n",
    "\n",
    "# Call the function to merge the JSON files\n",
    "merge_json_files(file1, file2, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5e08db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dictionaries: 103\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(\"files/merged.json\", \"r\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Check if the loaded data is a list of dictionaries\n",
    "if isinstance(json_data, list) and all(isinstance(item, dict) for item in json_data):\n",
    "    # Count the number of dictionaries in the list\n",
    "    count = len(json_data)\n",
    "    print(\"Number of dictionaries:\", count)\n",
    "else:\n",
    "    print(\"The JSON data is not in the expected format of a list of dictionaries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c06caaba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmerged_data\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'merged_data' is not defined"
     ]
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1416255",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.1263146087158642\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.13819929773426579\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0845798608014702\n",
      "Similarity Score: 0.1414305679255449\n",
      "Similarity Score: 0.10371551133313006\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.25213870694526264\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.22028815056182974\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.2605556710562624\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.26055567105626243\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 1.0\n",
      "Similarity Score: 0.24395572500006343\n",
      "Similarity Score: 0.11234277891542777\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.09349477497536716\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.05699752852140605\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.029032707475956265\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.08203264007347356\n",
      "Similarity Score: 0.05524402556623147\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.09339537641256736\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 0.0\n",
      "Similarity Score: 1.0\n",
      "Similarity Score: 0.5797386715376658\n",
      "Similarity Score: 0.14438355527738675\n",
      "Similarity Score: 0.5797386715376657\n",
      "Similarity Score: 0.22028815056182974\n",
      "Similarity Score: 0.44943641652398214\n",
      "Similarity Score: 0.10163066979112656\n",
      "Similarity Score: 0.5797386715376658\n",
      "Similarity Score: 0.12735952979479354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(text1, text2):\n",
    "    # Create a TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fit and transform the text data\n",
    "    tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
    "\n",
    "    # Calculate the cosine similarity\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "\n",
    "    # Extract the similarity score\n",
    "    similarity_score = similarity_matrix[0][0]\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "import json\n",
    "\n",
    "# Read the merged JSON file\n",
    "with open('files/merged.json', 'r') as f:\n",
    "    merged_data = json.load(f)\n",
    "\n",
    "# Assuming 'merged_data' is a list of dictionaries in the merged JSON file\n",
    "for item in merged_data:\n",
    "    risk1 = item['bard_impact_risk']\n",
    "    risk2 = item['aiaaic_risks']\n",
    "\n",
    "    similarity_score = calculate_similarity(risk1, risk2)\n",
    "    print(\"Similarity Score:\", similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f68f0c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0s/3kzr7mhx0n1bv8ms2vykptm40000gn/T/ipykernel_21268/3170586187.py:28: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  similarity_score = doc1.similarity(doc2)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to calculate cosine similarity between two strings\n",
    "def calculate_cosine_similarity(text1, text2):\n",
    "    # Create TfidfVectorizer object\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fit and transform the text data\n",
    "    tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity_score = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
    "    return similarity_score\n",
    "\n",
    "# Function to calculate spaCy similarity between two strings\n",
    "def calculate_spacy_similarity(text1, text2):\n",
    "    # Load the spaCy English model\n",
    "    # Create spaCy document for each text\n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "\n",
    "    # Calculate similarity between the documents\n",
    "    similarity_score = doc1.similarity(doc2)\n",
    "    return similarity_score\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Read the merged JSON file\n",
    "with open('files/merged.json', 'r') as f:\n",
    "    merged_data = json.load(f)\n",
    "\n",
    "# Iterate over each dictionary in merged_data\n",
    "for item in merged_data:\n",
    "    risk1 = item['bard_impact_risk']\n",
    "    risk2 = item['aiaaic_risks']\n",
    "\n",
    "    cosine_similarity_score = calculate_cosine_similarity(risk1, risk2)\n",
    "    spacy_similarity_score = calculate_spacy_similarity(risk1, risk2)\n",
    "\n",
    "    item['cosine_similarity_score'] = cosine_similarity_score\n",
    "    item['spacy_similarity_score'] = spacy_similarity_score\n",
    "\n",
    "# Save the updated merged_data to a new JSON file\n",
    "with open('files/two_similarity_results.json', 'w') as f:\n",
    "    json.dump(merged_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c06c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
